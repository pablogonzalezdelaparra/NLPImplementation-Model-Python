{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the training and testing data\n",
    "train_path = './train_data'\n",
    "test_path = './test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NLP model\n",
    "nlp = NLPModel(0.5, 3)\n",
    "train_data = nlp._NLPModel__load_folder(train_path),\n",
    "test_data = nlp._NLPModel__load_folder(test_path),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. Traditional cheating detection methods have many disadvantages, such as difficult to detect covert equipment cheating, multi-source cheating, difficult to distinguish plagiarists from plagiarists, difficult to distinguish plagiarists from victims, or plagiarism from coincidences. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. In this paper, the concept of knowledge point mastery Index is introduced to measure students’ mastery of a certain knowledge point, and a test method of cheating based on improved cognitive diagnostic model is proposed. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems. The experiments show that the precision and recall rate of this method are significantly higher than those of the method based on the false-same rate, the method based on the false-same rate and the right-same rate and the method based on the Person-Fit index.\\n',\n",
       " 'Machine learning (ML) is a form of artificial intelligence which is placed to transform the twenty-first century. Rapid, recent progress in its underlying architecture and algorithms and growth in the size of datasets have led to increasing computer competence across a range of fields. For these algorithms, choosing a proper fitness function plays an important role. These include driving a vehicle, language translation, chatbots and beyond human performance at complex board games such as Go. Here, we review the fundamentals and algorithms behind machine learning and highlight specific approaches to learning and optimisation. We then summarise the applications of ML to medicine. The fitness function orients the searching strategy of the algorithms to obtain best solutions. Feature selection (FS) is an optimisation problem that reduces the dimension of the dataset and increases the performance of the machine learning algorithms and classification through the selection of the optimal subset features and elimination of the redundant features. \\n',\n",
       " 'At present, the application of Artificial Intelligence (AI) in industrial control, smart home and other fields has received good response. However, AI technology has certain requirements for computer performance, and also faces problems in network security, data analysis, human-computer interaction, etc. At present, the visual platform of embedded system has achieved remarkable results in practical applications, but its development has been seriously hampered by problems such as low overall development efficiency and unstable system performance. The test results showed that when other conditions were the same, students and experts had 83.5% and 90% positive evaluations of System X, and 16.5% and 10% negative evaluations respectively. This paper designed an EP Vision System (VS) based on AI technology. The platform combined the embedded hardware design with the Support Vector Machine (SVM) algorithm to realize the intelligent robot interaction and target detection functions. It showed the positive relationship between AI technology and EP VS. The proportion of positive evaluation of System X was much higher than that of System Y, which indicated that System X can meet the actual application requirements and improve the system recognition efficiency to a certain extent. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. \\n',\n",
       " 'Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors. In the current state-of-the-art, there are no tools to do that. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. \\n',\n",
       " 'Internet of Things (IoT) based remote healthcare applications provided fast and preventative medical services to the patients at risk. However, predicting heart disease was a complex task and diagnosis results were rarely accurate. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed for providing prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, the physiological data were collected from the patient’s remotely by using the four bio sensors such as ECG sensor, Pressure sensor, Pulse sensor and Glucose sensor. An Arduino controller received the collected data from the IoT sensors to predict and diagnose the disease. A cardiovascular disease prediction model was implemented by using BiGRU (Bidirectional-Gated Recurrent Unit) attention model which diagnosed the cardiovascular disease and classified into five available cardiovascular classes. The recommendation system provided physical and dietary recommendations to cardiac patients based on the classified data, via user mobile application. The performance of the DEEP-CARDIO was validated by Cloud Simulator (CloudSim) using the real-time Framingham’s and Statlog heart disease dataset. The proposed DEEP CARDIO method achieved an overall accuracy of 99.90% whereas, the MABC-SVM, HCBDA and MLbPM method achieved 86.91%, 88.65% and 93.63% respectively.\\n']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first training and testing data\n",
    "test_data[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      0.90      0.95        10\n",
      "           3       1.00      1.00      1.00        10\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       0.91      1.00      0.95        10\n",
      "           6       1.00      1.00      1.00        10\n",
      "           7       1.00      1.00      1.00        10\n",
      "           8       1.00      1.00      1.00        10\n",
      "           9       1.00      1.00      1.00        10\n",
      "          10       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.99       110\n",
      "   macro avg       0.99      0.99      0.99       110\n",
      "weighted avg       0.99      0.99      0.99       110\n",
      "\n",
      "['This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. Traditional cheating detection methods have many disadvantages, such as difficult to detect covert equipment cheating, multi-source cheating, difficult to distinguish plagiarists from plagiarists, difficult to distinguish plagiarists from victims, or plagiarism from coincidences. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. In this paper, the concept of knowledge point mastery Index is introduced to measure students’ mastery of a certain knowledge point, and a test method of cheating based on improved cognitive diagnostic model is proposed. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems. The experiments show that the precision and recall rate of this method are significantly higher than those of the method based on the false-same rate, the method based on the false-same rate and the right-same rate and the method based on the Person-Fit index.\\n', 'Machine learning (ML) is a form of artificial intelligence which is placed to transform the twenty-first century. Rapid, recent progress in its underlying architecture and algorithms and growth in the size of datasets have led to increasing computer competence across a range of fields. For these algorithms, choosing a proper fitness function plays an important role. These include driving a vehicle, language translation, chatbots and beyond human performance at complex board games such as Go. Here, we review the fundamentals and algorithms behind machine learning and highlight specific approaches to learning and optimisation. We then summarise the applications of ML to medicine. The fitness function orients the searching strategy of the algorithms to obtain best solutions. Feature selection (FS) is an optimisation problem that reduces the dimension of the dataset and increases the performance of the machine learning algorithms and classification through the selection of the optimal subset features and elimination of the redundant features. \\n', 'At present, the application of Artificial Intelligence (AI) in industrial control, smart home and other fields has received good response. However, AI technology has certain requirements for computer performance, and also faces problems in network security, data analysis, human-computer interaction, etc. At present, the visual platform of embedded system has achieved remarkable results in practical applications, but its development has been seriously hampered by problems such as low overall development efficiency and unstable system performance. The test results showed that when other conditions were the same, students and experts had 83.5% and 90% positive evaluations of System X, and 16.5% and 10% negative evaluations respectively. This paper designed an EP Vision System (VS) based on AI technology. The platform combined the embedded hardware design with the Support Vector Machine (SVM) algorithm to realize the intelligent robot interaction and target detection functions. It showed the positive relationship between AI technology and EP VS. The proportion of positive evaluation of System X was much higher than that of System Y, which indicated that System X can meet the actual application requirements and improve the system recognition efficiency to a certain extent. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. \\n', 'Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors. In the current state-of-the-art, there are no tools to do that. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. \\n', 'Internet of Things (IoT) based remote healthcare applications provided fast and preventative medical services to the patients at risk. However, predicting heart disease was a complex task and diagnosis results were rarely accurate. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed for providing prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, the physiological data were collected from the patient’s remotely by using the four bio sensors such as ECG sensor, Pressure sensor, Pulse sensor and Glucose sensor. An Arduino controller received the collected data from the IoT sensors to predict and diagnose the disease. A cardiovascular disease prediction model was implemented by using BiGRU (Bidirectional-Gated Recurrent Unit) attention model which diagnosed the cardiovascular disease and classified into five available cardiovascular classes. The recommendation system provided physical and dietary recommendations to cardiac patients based on the classified data, via user mobile application. The performance of the DEEP-CARDIO was validated by Cloud Simulator (CloudSim) using the real-time Framingham’s and Statlog heart disease dataset. The proposed DEEP CARDIO method achieved an overall accuracy of 99.90% whereas, the MABC-SVM, HCBDA and MLbPM method achieved 86.91%, 88.65% and 93.63% respectively.\\n', 'This study is conducted to investigate the empathy between human-chatbot interactions among computer science students at Uppsala University, Sweden. This is done by exploring how participants perceived anthropomorphic chatbots as machines or humans, the existence of verbal abuse during human-chatbot interactions, and the expectation of chatbot helpfulness depending on gender dynamics. A semi-structured interview methodology with five students were conducted for qualitative data collection. The collected data is manually analyzed using thematic analysis. The results of this study find that there was empathy in human-chatbot interaction, regardless of whether participants perceive anthropomorphic chatbots as humans or machines. However, the level of empathy was generally low as participants become frustrated when they were dissatisfied with the response of chatbots and exit the chatbots without expressing their frustration. They usually forgot their frustration and came again with other questions another time. The study also showed that participants may expect more help and politeness if chatbots are more likely to be female.\\n', 'Human-AI interaction has become an important focus in developing technology that is more responsive and humane. In this context, the use of artificial empathy strategies is particularly interesting because of their potential to improve customer experiences affectively and socially. The aim of this research is to explore how artificial empathy strategies can optimize human-AI interactions and enhance affective and social customer experiences. The research approach is qualitative, involving a review of various studies and related literature. The data sources include journals, articles, and books relevant to the research topic. The research results indicate that implementing artificial empathy strategies in human-AI interactions has the potential to significantly improve the quality of interactions and customer experiences. Technologies such as natural language processing, emotion recognition, and sentiment analysis can enable AI to respond more precisely and sensitively to user needs and emotions.\\n', \"The main idea of this paper is the substantiation of the methodological approach to the assessment of personnel risks of enterprises based on the application of the fuzzy logic apparatus in order to identify the problems of personnel risk management and provide appropriate recommendations for their solution. The methodological basis of the study is the classic provisions and fundamental works of foreign and domestic scientists, statistical data, the results of our research into the problems of assessing personnel risks of enterprises. The methods of fuzzy set theory, comparative analysis, scientific abstraction, generalization of scientific experience of modern theoretical research, systemcomplex approach were used. The study proposed a methodological approach to assessing the level of personnel risks of an enterprise; numerical experiments were conducted on the basis of a group of construction equipment manufacturers. Analysis of the results of assessing the level of personnel risks of enterprises made it possible to identify the problems of managing personnel risks at enterprises Statement of a mathematical problem: the work considers hierarchical fuzzy data, namely: four groups of indicators for assessing the level of personnel risks (quantitative composition – F1, state of qualifications and intellectual potential – F2, staff turnover – F3, motivational system – F4), each of the indicators has a different number of fuzzy coefficients (there are twelve of them in the current work – vi , i=1÷12). Indicators are functions of fuzzy coefficients: F1 = r(v1, v2, v3); F2 = g(v4,v5, v6, v7); F3 = h(v8, v9, v10,); F4=q(v11, v12). As an output variable, there is a functional – an integrated indicator Int = f(F1, F2, F3, F4) of the personnel risk level, which, in turn, is also a fuzzy value. Here, the functions r, g, h, q, f are unknown functions of the given variables. We have expert evaluations of the change in all input data; as a rule, they vary within three terms: Low (I), Medium (G), High (E). Formalized information on each variable can be written as , then for a group of indicators we have: . Using a fuzzy system and performing calculations with its help requires the system to have the following structural elements: membership functions of input and output variables, a rule base, and an output mechanism. These structural elements are the components that will be built when designing a fuzzy system. The built mathematical model and the method of its formalization on the basis of FST make it possible to estimate the level of personnel risk at the enterprise, which enables further substantiation of a set of measures to increase the efficiency of its use. The constructed system of fuzzy logical inference can be considered intelligent as it uses elements of computational intelligence, in particular, the theory of fuzzy sets. The proposed methodological approach to assessing the level of personnel risks of enterprises based on the apparatus of fuzzy logic allows, in contrast to existing ones, to integrate the consideration of both qualitative and quantitative indicators when assessing the level of personnel risks and personnel movement indicators and to significantly increase the efficiency of decision-making under conditions of uncertainty and reduce costs in the event of adverse situations. This paper substantiates a methodological approach to assessing personnel risks in enterprises using fuzzy logic. The goal is to identify and provide recommendations for managing personnel risk problems. The study's foundation includes classic provisions of foreign and domestic scientists, statistical data, and the team's own research. Methods such as fuzzy set theory, comparative analysis, scientific abstraction, generalization of modern theoretical research, and a system-complex approach were employed. The study proposes a methodological approach to assessing personnel risk levels, exemplified by a group of construction equipment manufacturers. It considers hierarchical fuzzy data comprising four groups of indicators: quantitative composition (F1), state of qualifications and intellectual potential (F2), staff turnover (F3), and motivational system (F4). Each indicator has fuzzy coefficients (vi, i=1÷12), and the output variable is an integrated indicator Int, representing the personnel risk level. The paper introduces unknown functions r, g, h, q, f as functions of fuzzy coefficients, reflecting expert evaluations of input data changes (Low, Medium, High). The study utilizes a fuzzy system with structural elements including membership functions, a rule base, and an output mechanism. This system allows for estimating personnel risk levels and justifying measures to enhance efficiency. The fuzzy logical inference system is considered intelligent as it employs computational intelligence elements, particularly fuzzy set theory. This methodological approach integrates qualitative and quantitative indicators, enhancing decision-making efficiency under uncertainty and reducing costs during adverse situations, distinguishing it from existing methods.\\n\", 'Drug designing and development represent crucial areas of research for pharmaceutical companies and chemical scientists. However, challenges such as low efficacy, off-target delivery, time consumption, and high cost hinder progress in drug design and discovery. Additionally, the complexity and volume of data from genomics, proteomics, microarray data, and clinical trials pose significant obstacles in the drug discovery pipeline. Artificial intelligence (AI) and machine learning (ML) technologies have revolutionized drug discovery and development, particularly through the use of artificial neural networks and deep learning algorithms. These technologies have modernized various processes in drug discovery, including peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Historical evidence supports the implementation of AI and deep learning in drug discovery. Furthermore, novel data mining, curation, and management techniques have provided critical support to newly developed modeling algorithms. In summary, advancements in AI and deep learning offer significant opportunities for rational drug design and discovery, ultimately benefiting mankind. Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind. \\n', 'The utilization of Artificial Intelligence (AI) technologies in education has surged, leading to a rise in published studies. Despite this, comprehensive large-scale reviews in this field are lacking. This study aims to bridge this gap by analyzing 4,519 publications from 2000 to 2019, using topic-based bibliometrics to identify trends and topics related to AI applications in education (AIEd). Results indicate a growing interest in using AI for educational purposes within the academic community. The primary research topics include intelligent tutoring systems for special education, natural language processing for language education, educational robots for AI education, educational data mining for performance prediction, discourse analysis in computer-supported collaborative learning, neural networks for teaching evaluation, affective computing for learner emotion detection, and recommender systems for personalized learning. The study also addresses the challenges and future directions of AIEd.\\n', 'Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution.\\nIn the last decade, AI use in Orthopaedics increased approximately tenfold. Artifcial intelligence helps with tracking activities, evaluating diagnostic images, predicting injury risk, and several other uses. Chat Generated Pre-trained\\nTransformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics\\nand sports medicine literature. Additionally, the article will also evaluate the role of ChatGPT in scientifc research\\nand publications.', 'The sports industry is progressively embracing technological advancements, and artificial intelligence stands out as a prominent innovation. Basketball in particular, has captured the interest of the real-time analytics and data science community. With the development, deployment, and experience of AI models by both viewers and players, it is crucial to provide a comprehensive summary of AI applications in basketball. This review is performed based on literature sourced from Web of Science and Dimensions databases, where articles were thoroughly examined to identify AI use cases. The study was backed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework and furthermore utilized computational literature review as well as bibliometric analysis techniques for knowledge extraction purposes. Our results revealed that the area of sports analytics is gaining momentum and AI in the basketball world has more adoption in China, USA, Australia, Canada, Italy and Spain from a research perspective. Our study offers contributions to theory and practice in the sports science and applied AI domains.', 'This study explores the comprehensive understanding of taekwondo, the application of fourth industrial revolution technologies in various kinds of sports, the development of taekwondo through artificial intelligence (AI), and essential technology in the fourth industrial revolution while suggesting advanced science directions through a literature review. Literature was sourced from six internet search electronic databases, consisting of three English databases and three Korean databases, from January 2016 to August 2023. The literature indicated cases of sports convergence with the application of fourth industrial revolution technologies, such as the game of go, golf, table tennis, soccer, American football, skiing, archery, and fencing. These sports not only use big data but also virtual reality and augmented reality. Taekwondo is a traditional martial art that originated in Republic of Korea and gradually became a globally recognized sport. Since taekwondo’s competition analysis is an analysis in which researchers manually write events, it takes a very long time to analyze, and the scale of the analysis varies depending on the researcher’s tendencies. This study presented the development of an AI Taekwondo performance improvement analysis and evaluation system and a metaverse-based virtual Taekwondo pumsae/fighting coaching platform through an AI-based motion tracking analysis method.', 'With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning.', 'In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions. Five-elements music therapy—based on the five-element theory—is a unique non-pharmacological therapy of East Asian traditional medicine. It has the potential to effectively provide individualized music therapy to individuals with illness. However, one limitation of this music therapy is that the classification of the five elements and its application is mainly based on subjective judgment. The development of artificial intelligence (AI) has enabled the acoustic analysis of multi-factor sound sources. This can develop five-element music therapy. Here, we discussed the challenges proposed by the future combination of five-element music therapy and AI. Further, we hypothesized that AI may promote its use in the medical field.', 'With the continuous progress of art education and artificial intelligence technology, traditional music teaching models are facing transformation. This article aims to construct an art education and teaching system based on artificial intelligence, especially for teaching music sound recognition. Through in-depth research, we have designed a music sound recognition system that uses Mel frequency cepstral coefficient (MFCC) for feature parameter extraction, and combines BP neural network algorithm to construct a music sound learning model. The main purpose is to improve the efficiency and accuracy of music teaching through artificial intelligence technology. The main challenge we face in this process is how to effectively extract the features of music sounds and accurately identify different tones through algorithms. By using the MFCC algorithm, we have successfully solved this problem as it can effectively describe the time-frequency characteristics of music sound. Our proposed music sound learning model is based on a BP neural network, which trains the network to learn the mapping relationship between music sound and pitch. The experiment used piano sound as an example to verify the accuracy and reliability of the system. The simulation experiments conducted in MATLAB environment show that our system can accurately recognize and extract the main frequency of music, and has higher performance compared to traditional methods.', 'The fashion industry has shown increasing interest in applying artificial intelligence (AI), yet there is a significant gap in exploring the potential of emerging diffusion-modeling-based AI image-generation systems for fashion design and commerce. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. We employed the action research approach with the Functional, Expressive, and Aesthetic (FEA) Consumer Needs Model as the theoretical framework. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. Findings reveal that this AI tool can assist fashion designers in creating both visually expressive attire and ready-to-wear products, meeting defined design criteria and consumer needs. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers.', 'This paper presents the development of a comprehensive, on-site industrial Optical Character Recognition (OCR) system tailored for reading text on iron plates. Initially, the system utilizes a text region detection network to identify the text area, enabling camera adjustments along the x and y axes and zoom enhancements for clearer text imagery. Subsequently, the detected text region undergoes line-by-line division through a text segmentation network. Each line is then transformed into rectangular patches for character recognition by the text recognition network, comprising a vision-based text recognition model and a language network. The vision network performs preliminary recognition, followed by refinement through the language model. The OCR results are then converted into digital characters and recorded in the iron plate registration system. This paper’s contributions are threefold: (1) the design of a comprehensive, on-site industrial OCR system for autonomous registration of iron plates; (2) the development of a realistic synthetic image generation strategy and a robust data augmentation strategy to address data scarcity; and (3) demonstrated impressive experimental results, indicating potential for on-site industrial applications. The designed autonomous system enhances iron plate registration efficiency and significantly reduces factory time and labor costs.', 'Recently, artificial intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies, as well as increasing the effectiveness of the training process. In this context, AI may contribute to the automatization of the image scan segmentation process and increase the quality of the resulting 3D objects, which may lead to the generation of more realistic virtual objects. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. It concludes with possible developments and open challenges in AI applications in extended reality-based solutions. Finally, future lines of research and development directions of artificial intelligence applications, both in medical image segmentation and extended reality-based medical solutions, are discussed.', 'With the rapid development of artificial intelligence, intelligent auxiliary systems have been widely used in various fields. As a sport, volleyball has high technical requirements, and the traditional volleyball teaching method has certain limitations. Therefore, the purpose of this study is to design an intelligent auxiliary system using artificial muscle integrated optical equipment to realize real-time monitoring and accurate evaluation of volleyball teaching, so as to assist coaches to accurately guide students’ movement skills. The system uses artificial muscle integrated optical equipment, and collects the movement data of students in volleyball training in real time through optical sensors. Machine learning algorithms are used to analyze and identify the data to accurately assess the student’s movements. The system is equipped with an interactive interface that shows students correct demonstrations of movements and provides real-time feedback and guidance. Through experimental verification, the intelligent assistant system can monitor students’ movements in real time, accurately evaluate their technical level, and provide personalized guidance. With the aid of using the system, the volleyball technique level of students has been improved, and the teaching effect has been significantly enhanced.']\n",
      "Predicted Subjects for New Abstracts:\n",
      "[ 7 10  1  4  8  4  4  7 10  0  0  0  9  0  5  8  0  5  1  8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Data preparation\n",
    "abstracts = train_data[0]\n",
    "subjects = [[0]*10, [1]*10, [2]*10, [3]*10, [4]*10, [5]*10, [6]*10, [7]*10, [8]*10, [9]*10, [10]*10, [11]*10]\n",
    "\n",
    "# Split abstracts into groups of 10\n",
    "abstracts_groups = [abstracts[i:i+10] for i in range(0, len(abstracts), 10)]\n",
    "subjects_groups = [[i]*10 for i in range(len(abstracts_groups))]\n",
    "\n",
    "# Flatten the groups\n",
    "abstracts = [abstract for group in abstracts_groups for abstract in group]\n",
    "subjects = [subject for group in subjects_groups for subject in group]\n",
    "\n",
    "# Feature extraction and model selection\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Training\n",
    "pipeline.fit(abstracts, subjects)\n",
    "\n",
    "# Evaluation\n",
    "predicted_subjects = pipeline.predict(abstracts)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(subjects, predicted_subjects))\n",
    "\n",
    "# Prediction example\n",
    "print(test_data[0])\n",
    "\n",
    "predicted_new_subjects = pipeline.predict(test_data[0])\n",
    "print(\"Predicted Subjects for New Abstracts:\")\n",
    "print(predicted_new_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def train_model(sentence1, sentence2):\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer([sentence1, sentence2], return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "    # Get BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract the embeddings for the [CLS] token\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    # Reshape the embeddings\n",
    "    embeddings = embeddings.numpy()\n",
    "\n",
    "    # Compute similarity\n",
    "    similarity_score = cosine_similarity(embeddings[0].reshape(1, -1), embeddings[1].reshape(1, -1))[0][0]\n",
    "    print(\"Similarity score:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.9323094\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. Traditional cheating detection methods have many disadvantages, such as difficult to detect covert equipment cheating, multi-source cheating, difficult to distinguish plagiarists from plagiarists, difficult to distinguish plagiarists from victims, or plagiarism from coincidences. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. In this paper, the concept of knowledge point mastery Index is introduced to measure students’ mastery of a certain knowledge point, and a test method of cheating based on improved cognitive diagnostic model is proposed. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems. The experiments show that the precision and recall rate of this method are significantly higher than those of the method based on the false-same rate, the method based on the false-same rate and the right-same rate and the method based on the Person-Fit index.\"\n",
    "sentence2 = \"This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. In this regard, we introduce a general barrier function and prescribed performance methodology to tackle constrained range impediments effectively. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. With the aid of the dynamic surface technology, we propose a decentralized adaptive event-triggering fault-tolerant (ETFT) formation control strategy. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems.\"\n",
    "train_model(sentence1, sentence2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.9371376\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"The utilization of Artificial Intelligence (AI) technologies in education has surged, leading to a rise in published studies. Despite this, comprehensive large-scale reviews in this field are lacking. This study aims to bridge this gap by analyzing 4,519 publications from 2000 to 2019, using topic-based bibliometrics to identify trends and topics related to AI applications in education (AIEd). Results indicate a growing interest in using AI for educational purposes within the academic community. The primary research topics include intelligent tutoring systems for special education, natural language processing for language education, educational robots for AI education, educational data mining for performance prediction, discourse analysis in computer-supported collaborative learning, neural networks for teaching evaluation, affective computing for learner emotion detection, and recommender systems for personalized learning. The study also addresses the challenges and future directions of AIEd.\"\n",
    "sentence2 = \"With the increasing use of Artificial Intelligence (AI) technologies in education, the number of published studies in the field has increased. However, no large-scale reviews have been conducted to comprehensively investigate the various aspects of this field. Based on 4,519 publications from 2000 to 2019, we attempt to fill this gap and identify trends and topics related to AI applications in education (AIEd) using topicbased bibliometrics. Results of the review reveal an increasing interest in using AI for educational purposes from the academic community. The main research topics include intelligent tutoring systems for special education; natural language processing for language education; educational robots for AI education; educational data mining for performance prediction; discourse analysis in computer-supported collaborative learning; neural networks for teaching evaluation; affective computing for learner emotion detection; and recommender systems for personalized learning. We also discuss the challenges and future directions of AIEd.\"\n",
    "train_model(sentence1, sentence2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.85587454\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution. In the last decade, AI use in Orthopaedics increased approximately tenfold. Artifcial intelligence helps with tracking activities, evaluating diagnostic images, predicting injury risk, and several other uses. Chat Generated Pre-trained Transformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics and sports medicine literature. Additionally, the article will also evaluate the role of ChatGPT in scientifc research and publications.\"\n",
    "sentence2 = \"Accurately scientific disciplines, including biomechanics, genetics, ethology, and neurology, it is essential to accurately track the behavior of animals throughout studies, particularly without employing markers. However, it has proven difficult to extract precise stances from backgrounds that are always shifting. Recently, we unveiled an open-source toolset that makes use of a cutting-edge algorithm for estimating human position. With the help of this toolbox, users may train a deep neural network to accurately monitor user-defined features with tracking accuracy that rivals that of human labeling. We have added new features, including as graphical user interfaces (GUIs), efficiency improvements, and network refinement based on active learning, to this revised Python module. In order to help customers create a unique and repeatable analysis pipeline using a graphical processing unit (GPU).\"\n",
    "train_model(sentence1, sentence2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel #for embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity #for similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\",)\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\",output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings\n",
    "def get_embeddings(text,token_length):\n",
    "    tokens=tokenizer(text,max_length=token_length,padding='max_length',truncation=True)\n",
    "    output=model(torch.tensor(tokens.input_ids).unsqueeze(0),\n",
    "                 attention_mask=torch.tensor(tokens.attention_mask).unsqueeze(0)).hidden_states[-1]\n",
    "    return torch.mean(output,axis=1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate similarity\n",
    "def calculate_similarity(text1,text2,text3,token_length=20):\n",
    "    out1=get_embeddings(text1,token_length=token_length) #create embeddings of text\n",
    "    out2=get_embeddings(text2,token_length=token_length) #create embeddings of text\n",
    "    out3=get_embeddings(text3,token_length=token_length) #create embeddings of text\n",
    "    sim1= cosine_similarity(out1,out2)[0][0]\n",
    "    sim2= cosine_similarity(out1,out3)[0][0]\n",
    "    print(sim1,sim2)\n",
    "    if sim1>sim2:\n",
    "        print('sentence 1 is more similar to input sentence')\n",
    "    else:\n",
    "        print('sentence 2 is more similar to input sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87726504 0.7504591\n",
      "sentence 1 is more similar to input sentence\n"
     ]
    }
   ],
   "source": [
    "text1 = 'Despite this, comprehensive large-scale reviews in this field are lacking.'\n",
    "text2 = 'However, no large-scale reviews have been conducted to comprehensively investigate the various aspects of this field.'\n",
    "text3 = 'This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education.'\n",
    "\n",
    "calculate_similarity(text1,text2,text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate similarity\n",
    "def calculate_similarity(text1,text2,token_length=20):\n",
    "    out1=get_embeddings(text1,token_length=token_length) #create embeddings of text\n",
    "    out2=get_embeddings(text2,token_length=token_length) #create embeddings of text\n",
    "    sim1= cosine_similarity(out1,out2)[0][0]\n",
    "    return sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [75, 0.9999999], 1: [103, 1.0000002], 2: [15, 1.0], 3: [44, 0.99999994], 4: [84, 0.98278], 5: [42, 0.96550786], 6: [40, 0.97645795], 7: [78, 0.9999999], 8: [108, 0.9651437], 9: [6, 0.9385615], 10: [40, 0.8716743], 11: [61, 0.893425], 12: [65, 0.7716932], 13: [81, 0.830673], 14: [54, 0.7993957], 15: [50, 0.87251437], 16: [9, 0.89948297], 17: [82, 0.8024551], 18: [101, 0.88029784], 19: [105, 0.9011358]}\n"
     ]
    }
   ],
   "source": [
    "# compare each test sentence with all train sentences to obtain the most \n",
    "max_similarity = {}\n",
    "for index, sentence in enumerate(test_data[0]):\n",
    "    for train_index, train_sentence in enumerate(train_data[0]):\n",
    "        sim = calculate_similarity(sentence, train_sentence)\n",
    "        if index not in max_similarity:\n",
    "            max_similarity[index] = [train_index, sim]\n",
    "        else:\n",
    "            if sim > max_similarity[index][1]:\n",
    "                max_similarity[index] = [train_index, sim]\n",
    "    \n",
    "print(max_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

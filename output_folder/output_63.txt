Artificial neural networks have developed as computationally feasible models of human language processing. A key critique of these models is that the amount of training data they get far exceeds that of people during language learning. Here, we utilize two distinct approaches to examine how the models’ capacity to capture human fMRI responses to words is affected by the amount of training data. First, we test GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally reasonable in terms of the amount of training data given that this number is equivalent to what children are projected to be exposed to throughout the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to obtain state-of-the-art next-word prediction performance on the human benchmark at different phases of training. Across all approaches, we find that (i) the models trained on a developmentally reasonable quantity of data already attain near-maximal performance in capturing fMRI responses to phrases. Further, (ii) lower perplexity—a measure of next-word prediction performance—is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. In tandem, these findings indicate that although some training is necessary for the models’ predictive capacity, a developmentally realistic amount of training (~100 million words) may suffice.
The pursuit of biologically inspired cognitive architectures (BICA) drove significant advancements in artificial intelligence (AI) and artificial general intelligence (AGI). However, most existing BICA models lacked a critical aspect of human intelligence: emotions and feelings. This research explored the development and implementation of an emotion-integrated cognitive architecture that mimicked human emotional processing within a computational framework. Our proposed architecture, Emotion-Integrated Cognitive Architecture (EICA), was inspired by the latest findings in cognitive psychology, neurobiology, neuroscience, and affective computing. EICA aimed to integrate emotional processing into the core of the AI system, enabling robust, flexible, and adaptable AI agents that could respond to complex and dynamic environments with human-like emotional intelligence. The EICA model leveraged advances in brain imaging and recording techniques to draw insights from the neural basis of emotions in humans. The architecture incorporated emotion-generating, recognition, and regulation mechanisms, allowing AI agents to perceive, interpret, and respond to emotions in themselves and others. We presented the concept of EICA, including its modular structure and interaction with other cognitive components. We also provided case studies showcasing EICA's successful implementation in various AI applications, such as virtual assistants and adaptive robotics. This research represented a significant step towards achieving the BICA Challenge by advancing the computational replication of human emotional intelligence. By integrating emotions and feelings into AI systems, we moved closer to realizing the full potential of bi-directional understanding between artificial and biological intelligences.
As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. With the rapid development of artificial intelligence, intelligent auxiliary systems have been widely used in various fields. Chat Generated Pre-trained
Transformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. The OAHEGA and FER-2013 datasets were utilized for experimental study. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.
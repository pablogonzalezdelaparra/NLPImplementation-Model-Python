Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of the techniques and data resources used in FER. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) Here, we discussed the challenges proposed by the future combination of five-element music therapy and AI. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions. to the deep learning era. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Through in-depth research, we have designed a music sound recognition system that uses Mel frequency cepstral coefficient (MFCC) for feature parameter extraction, and combines BP neural network algorithm to construct a music sound learning model. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.
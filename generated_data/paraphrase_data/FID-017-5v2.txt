The use of AI and machine learning, namely the vision transformer approach, in bacterial detection offers a promising way to get beyond the drawbacks of conventional techniques and provide quicker and more accurate identification of bacteria that cause disease, such as E. Water containing E. Coli and Salmonella is essential for human existence, and studies are still being conducted to determine its efficacy in microbiology. In order to classify bacterial colonies, this study presents a novel positional self-attention transformer model. By adding a positional self-attention mechanism, we improved the model's performance by utilizing the transformer designs' shown effectiveness across a range of domains. We introduced a new method for classifying bacterial colonies using a positional self-attention transformer model. This contributes to extremely precise classification findings by enabling the algorithm to grasp spatial linkages and patterns within bacterial colonies. We ensured the model's resilience and its ability to generalize to different types of colonies by training it on a large dataset of bacterial pictures. More precise and reliable categorization was made possible by the suggested model's deft capturing of the spatial linkages and sequential patterns present in photos of bacterial colonies. The model that was suggested performed remarkably well, classifying bacterial colonies with an accuracy of 98.50%. This new method outperforms existing techniques by accurately capturing complex spatial interactions within microbial structures and provides previously unheard-of precision in identifying minute morphological differences. The model's capacity to adapt to various colony forms and arrangements is a noteworthy development that might revolutionize the field of bacterial colony categorization by utilizing cutting-edge deep learning approaches. The model's excellent classification accuracy indicates that it may find use in the early detection of infectious illnesses and the creation of focused therapies. The results of this work highlight how positional self-attention may be effectively included into transformer models for image-based classification tasks, especially in the field of bacterial colony analysis.
Artificial intelligence (AI) systems and robots are becoming more and more like human communicators as a result of advancements in AI. They pose the following queries:1. if it's feasible to interact with, comprehend, and even perceive artificial entities with empathy;2. if, after a given amount of simulation, we should grant them true subjectivity and, hence, quasi-personal status;3. what will happen if the line between simulated and real encounters becomes increasingly blurred? (1) To address these issues, the paper makes the case that shared emotions and a we-intentionality are made possible by the implicit assumption of our counterpart's subjectivity, which is a prerequisite for truly understanding others. This assumption ultimately rests on the presupposition of a shared form of life, here understood as conviviality. (2) Embodied and enactive cognition, which connects subjectivity and consciousness to the aliveness of an organism, disproves the theory that future artificial agents could meet these preconditions. (3) Even if subjectivity is theoretically impossible for artificial agents, the line between simulated and real subjectivity may nevertheless become increasingly blurred. Here, potential repercussions are spoken about, particularly with reference to online psychotherapy. Lastly, the study argues against a systematic illusion of subjectivity and advocates for a thoughtful approach to the terminology we use when discussing artificial systems.
Artificial neural networks are now seen as viable models for simulating human language processing due to their computational feasibility. One significant critique of these models is that they are trained on a far larger amount of data compared to what humans typically get during language acquisition. In this study, we employ two complimentary methodologies to investigate the impact of training data quantity on the models' capacity to accurately replicate human fMRI responses to phrases. Initially, we assess GPT-2 models that have been trained on varying amounts of words (1 million, 10 million, 100 million, or 1 billion) by comparing their performance against an fMRI benchmark. The 100-million-word model is considered developmentally credible because it is trained on a similar quantity of data that children are predicted to be exposed to throughout their first 10 years of life. Next, we evaluate the efficiency of a GPT-2 model that has been trained on a dataset containing 9 billion tokens. We want to achieve the best possible performance in predicting the next word in a sentence, as measured by a human benchmark. This evaluation is conducted at several phases throughout the training process. Both approaches demonstrate that models trained on a realistic quantity of data already attain almost optimal performance in capturing fMRI responses to phrases. In addition, a lower perplexity, which is a measure of how well a model can predict the next word, is linked to a stronger alignment with human data. This implies that models that have undergone extensive training and can accurately predict the next word also develop sentence representations that are predictive of human fMRI responses. These data demonstrate that the models' predictive power requires some training, but a realistic quantity of training, approximately 100 million words, may be sufficient.
Models of human language processing that are computationally feasible include artificial neural networks. The fact that computer programs are given significantly more training data than people do while learning a language is one of their main criticisms. Here, we explore how the amount of training data affects the models' capacity to capture human fMRI responses to words using two complimentary techniques. We first test GPT-2 models against an fMRI benchmark that were trained on one million, ten million, hundred million, or one billion words. Given that the quantity of training data in the 100 million word model is comparable to what infants are projected to be exposed to throughout their first ten years of life, we see this model as developmentally reasonable. Second, we evaluate the ability of a GPT-2 model trained on a dataset of nine billion tokens to achieve, at various points during training, state-of-the-art next-word prediction performance on the human benchmark. Using both methods, we discover that (i) the models trained on a reasonable quantity of data for development have already reached almost maximum performance in fMRI responses to phrases. Moreover, (ii) stronger alignment with human data is linked to lower perplexity, a measure of next-word prediction performance. This implies that models that have been sufficiently trained to attain high next-word prediction performance also learn sentence representations that are predictive of human fMRI responses. Together, these results show that while some training is required for the models to be predictive, a developmentally appropriate training set (~100 million words) could be adequate.
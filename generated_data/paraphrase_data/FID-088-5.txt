Facial Expression Recognition (FER) is employed in diverse domains, including education, gaming, robotics, healthcare, and other sectors. Facial expression techniques, such as an interactive robot equipped with Artificial Intelligence, have the ability to identify human faces, analyze the emotions of the individual it is engaging with, and subsequently utilize these emotions to select suitable responses. An application of face emotion detection is to select and play music that corresponds to the user's emotional state. In order to accomplish this, we can examine the user's facial expression to infer their emotions. Consequently, further research is needed to explore new emotion models, as current ones face difficulties in accurately assessing the relationship between music and facial emotions. This research employs a Convolution Neural Network (CNN) based deep learning approach to implement this type of task. Deep learning is superior than machine learning in its ability to evaluate unstructured data, movies, and other types of media with greater effectiveness. We have developed a live system in our research that is capable of accurately identifying human faces, evaluating human emotions, and providing music recommendations to users. The experimental investigation made use of the OAHEGA and FER-2013 datasets. We developed and instructed two emotion identification models by utilizing different mixes of these datasets. The accuracy of the proposed model is 73.02%. Our CNN algorithm has the capability to accurately forecast six distinct emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed technology can be employed in various locations where real-time facial identification is crucial.
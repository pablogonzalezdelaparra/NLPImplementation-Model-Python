Integrating empathy into healthcare chatbots is seen as a viable approach to evoke a feeling of human warmth. Nevertheless, current research often fails to consider the multifaceted nature of empathy, resulting in a limited comprehension of whether manufactured empathy is experienced in a similar manner to interpersonal empathy. This research contends that the implementation of experiential manifestations of empathy may result in unforeseen adverse effects due to their potential inauthenticity. Alternatively, offering instrumental assistance may be more appropriate for simulating artificial empathy, as it is more compatible with computer-based frameworks used in chatbots. Two empirical investigations utilizing healthcare chatbots investigate the impact of empathetic (experiencing with), sympathetic (experiencing for), and behavioral-empathetic (empathetic aiding) versus non-empathetic responses on the perception of warmth, perception of authenticity, and their subsequent effects on trust and behavioral intentions. The findings indicate that the presence of empathy, regardless of its type, increases the perception of warmth, leading to greater trust and intention to use. As predicted, the chatbot's perceived authenticity is diminished by compassionate and sympathetic reactions, hence negating the favorable impact shown in both tests. A third study fails to reproduce this counterproductive impact in interactions between humans. This research emphasizes that empathy is not evenly distributed in human-bot interactions. It also presents the idea of 'perceived authenticity' and shows that uniquely human characteristics can have a negative effect by seeming inauthentic while interacting with chatbots.
The endeavor to develop cognitive architectures influenced by biology, known as biologically inspired cognitive architectures (BICA), has led to substantial progress in the fields of artificial intelligence (AI) and artificial general intelligence (AGI). Nevertheless, the majority of current BICA models are deficient in incorporating a crucial element of human intelligence: emotions and feelings. This study investigates the creation and application of a cognitive architecture that incorporates emotions, replicating the way humans process emotions, within a computer framework. The Emotion-Integrated Cognitive Architecture (EICA) we propose draws inspiration from recent discoveries in cognitive psychology, neurobiology, neuroscience, and affective computing. The objective of EICA is to incorporate emotional processing into the heart of the AI system, allowing for the development of resilient, versatile, and adaptive AI agents capable of responding to intricate and ever-changing surroundings with emotional intelligence similar to that of humans. The EICA model utilizes advancements in brain imaging and recording methodologies to extract knowledge from the neurological foundation of emotions in humans. The architecture integrates systems for producing, recognizing, and regulating emotions, enabling AI entities to perceive, interpret, and react to emotions in themselves and others. We introduce the notion of EICA, outlining its modular framework and its interplay with other cognitive components. In addition, we offer case studies that demonstrate the successful integration of EICA in several AI applications, including virtual assistants and adaptive robotics. This research is a huge advancement in the computational replication of human emotional intelligence, bringing us closer to achieving the BICA Challenge. By incorporating emotions and sensations into AI systems, we come closer to fully fulfilling the potential of mutual comprehension between artificial and organic intelligences.
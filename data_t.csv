text,original,label
"This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research.","This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research.",0
"Artificial intelligence (AI) is developing and its application is spreading at an alarming rate, and AI has become part of our daily lives. As a matter of fact, AI has changed the way people learn. This paper’s contributions are threefold: (1) the design of a comprehensive, on-site industrial OCR system for autonomous registration of iron plates; (2) the development of a realistic synthetic image generation strategy and a robust data augmentation strategy to address data scarcity; and (3) demonstrated impressive experimental results, indicating potential for on-site industrial applications. However, its adoption in the educational sector has been saddled with challenges and ethical issues. The fashion industry has shown increasing interest in applying artificial intelligence (AI), yet there is a significant gap in exploring the potential of emerging diffusion-modeling-based AI image-generation systems for fashion design and commerce. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. The purpose of this study is to analyze the opportunities, benefits, and challenges of AI in education. A review of available and relevant literature was done using the systematic review method to identify the current research focus and provide an in-depth understanding of AI technology in education for educators and future research directions. Findings showed that AI's adoption in education has advanced in the developed countries and most research became popular within the Industry 4.0 era. Other challenges, as well as recommendations, are discussed in the study.","Artificial intelligence (AI) is developing and its application is spreading at an alarming rate, and AI has become part of our daily lives. As a matter of fact, AI has changed the way people learn. However, its adoption in the educational sector has been saddled with challenges and ethical issues. The purpose of this study is to analyze the opportunities, benefits, and challenges of AI in education. A review of available and relevant literature was done using the systematic review method to identify the current research focus and provide an in-depth understanding of AI technology in education for educators and future research directions. Findings showed that AI's adoption in education has advanced in the developed countries and most research became popular within the Industry 4.0 era. Other challenges, as well as recommendations, are discussed in the study.",0
"As of 2021, more than 30 countries have released national artificial intelligence (AI) policy strategies. These documents articulate plans and expectations regarding how AI will impact policy sectors, including education, and typically discuss the social and ethical implications of AI. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). This article engages in thematic analysis of 24 such national AI policy strategies, reviewing the role of education in global AI policy discourse. The study was backed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework and furthermore utilized computational literature review as well as bibliometric analysis techniques for knowledge extraction purposes. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). This suggests that AIED and its broader policy and ethical implications—good or bad—have failed to reach mainstream awareness and the agendas of key decision-makers, a concern given that effective policy and careful consideration of ethics are inextricably linked, as this article argues. In light of these findings, the article applies a framework of five AI ethics principles to consider ways in which policymakers can better incorporate AIED’s implications. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. Finally, the article offers recommendations for AIED scholars on strategies for engagement with the policymaking process, and for performing ethics and policy-oriented AIED research to that end, in order to shape policy deliberations on behalf of the public good.","As of 2021, more than 30 countries have released national artificial intelligence (AI) policy strategies. These documents articulate plans and expectations regarding how AI will impact policy sectors, including education, and typically discuss the social and ethical implications of AI. This article engages in thematic analysis of 24 such national AI policy strategies, reviewing the role of education in global AI policy discourse. It finds that the use of AI in education (AIED) is largely absent from policy conversations, while the instrumental value of education in supporting an AI-ready workforce and training more AI experts is overwhelmingly prioritized. Further, the ethical implications of AIED receive scant attention despite the prominence of AI ethics discussion generally in these documents. This suggests that AIED and its broader policy and ethical implications—good or bad—have failed to reach mainstream awareness and the agendas of key decision-makers, a concern given that effective policy and careful consideration of ethics are inextricably linked, as this article argues. In light of these findings, the article applies a framework of five AI ethics principles to consider ways in which policymakers can better incorporate AIED’s implications. Finally, the article offers recommendations for AIED scholars on strategies for engagement with the policymaking process, and for performing ethics and policy-oriented AIED research to that end, in order to shape policy deliberations on behalf of the public good.",0
"Initially, the system utilizes a text region detection network to identify the text area, enabling camera adjustments along the x and y axes and zoom enhancements for clearer text imagery. We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. The literature and information were obtained from various books and research articles on EBSCO, Google Scholar, Scopus, Web of Science, and ScienceDirect. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. Five independent reviewers assessed search results, extracted data, and set the studies’ quality to summarise and report the findings. This paper’s contributions are threefold: (1) the design of a comprehensive, on-site industrial OCR system for autonomous registration of iron plates; (2) the development of a realistic synthetic image generation strategy and a robust data augmentation strategy to address data scarcity; and (3) demonstrated impressive experimental results, indicating potential for on-site industrial applications. Implementing artificial intelligence is a strategic and critical factor in educational development. We employed the action research approach with the Functional, Expressive, and Aesthetic (FEA) Consumer Needs Model as the theoretical framework. They assist teachers and students in various ways, including giving students access to a wide range of learning materials based on their specific learning needs and subjects. However, some risks are associated with artificial intelligence advancements, such as safety, security, and privacy concerns. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. Conclusion: Artificial intelligence technologies have positive and negative effects on education. Thus, it is critical to prioritise artificial intelligence in education and implement appropriate strategies to meet teachers' and students' needs and expectations through AI technologies. As a result, academic performance will be excellent. Recommendation & Implication: Qualitative research, such as interviews, or quantitative analysis, such as online questionnaires, may be developed in the future to provide more explanations and explicit findings. The implications could be applied to school administrators, teachers, and students to understand better and implement appropriate strategies to improve educational performance through AI.","Method: A narrative synthesis and a systematic literature review were conducted in this review article. The literature and information were obtained from various books and research articles on EBSCO, Google Scholar, Scopus, Web of Science, and ScienceDirect. The inclusion criteria were studies that clearly defined artificial intelligence in the education sector, were published and written in English and were peer-reviewed. Five independent reviewers assessed search results, extracted data, and set the studies’ quality to summarise and report the findings.

Result: Artificial intelligence has already entered the education sector. Implementing artificial intelligence is a strategic and critical factor in educational development. Furthermore, artificial intelligence is increasingly being used as a digital assistant. They assist teachers and students in various ways, including giving students access to a wide range of learning materials based on their specific learning needs and subjects. However, some risks are associated with artificial intelligence advancements, such as safety, security, and privacy concerns. As a result, artificial intelligence technologies positively and negatively affect the education sector.

Conclusion: Artificial intelligence technologies have positive and negative effects on education. Thus, it is critical to prioritise artificial intelligence in education and implement appropriate strategies to meet teachers' and students' needs and expectations through AI technologies. As a result, academic performance will be excellent.

Recommendation & Implication: Qualitative research, such as interviews, or quantitative analysis, such as online questionnaires, may be developed in the future to provide more explanations and explicit findings. The implications could be applied to school administrators, teachers, and students to understand better and implement appropriate strategies to improve educational performance through AI.",0
"Artificial Intelligence (AI) is reshaping the world in profound ways; some of its impacts are certainly beneficial but widespread and lasting harms can result from the technology as well. The integration of AI into various aspects of human life is underway, and the complex ethical concerns emerging from the design, deployment, and use of the technology serves as a reminder that it is time to revisit what future developers and designers, along with professionals, are learning when it comes to AI. Further, we hypothesized that AI may promote its use in the medical field. It is of paramount importance to train future members of the AI community, and other stakeholders as well, to reflect on the ways in which AI might impact people’s lives and to embrace their responsibilities to enhance its benefits while mitigating its potential harms. Through experimental verification, the intelligent assistant system can monitor students’ movements in real time, accurately evaluate their technical level, and provide personalized guidance. This could occur in part through the fuller and more systematic inclusion of AI ethics into the curriculum. In this paper, we briefly describe different approaches to AI ethics and offer a set of recommendations related to AI ethics pedagogy.","Artificial Intelligence (AI) is reshaping the world in profound ways; some of its impacts are certainly beneficial but widespread and lasting harms can result from the technology as well. The integration of AI into various aspects of human life is underway, and the complex ethical concerns emerging from the design, deployment, and use of the technology serves as a reminder that it is time to revisit what future developers and designers, along with professionals, are learning when it comes to AI. It is of paramount importance to train future members of the AI community, and other stakeholders as well, to reflect on the ways in which AI might impact people’s lives and to embrace their responsibilities to enhance its benefits while mitigating its potential harms. This could occur in part through the fuller and more systematic inclusion of AI ethics into the curriculum. In this paper, we briefly describe different approaches to AI ethics and offer a set of recommendations related to AI ethics pedagogy.",0
"As addressed by Stephen Yang in his ICCE 2019 keynote speech (Yang, 2019), precision
education is a new challenge when applying artificial intelligence (AI), machine learning, and learning analytics
to improve teaching quality and learning performance. The goal of precision education is to identify at-risk
students as early as possible and provide timely intervention on the basis of teaching and learning experiences
(Lu et al., 2018). Additionally, the article will also evaluate the role of ChatGPT in scientifc research
and publications. This study presented the development of an AI Taekwondo performance improvement analysis and evaluation system and a metaverse-based virtual Taekwondo pumsae/fighting coaching platform through an AI-based motion tracking analysis method. Drawing from this main theme of precision education, this special issue advocates an in-depth
dialogue between cold technology and warm humanity, in turn offering greater understanding of precision
education. For this special issue, thirteen research papers that specialize in precision education, AI, machine
learning, and learning analytics to engage in an in-depth research experiences concerning various applications,
methods, pedagogical models, and environments were exchanged to achieve better understanding of the
application of AI in education","As addressed by Stephen Yang in his ICCE 2019 keynote speech (Yang, 2019), precision
education is a new challenge when applying artificial intelligence (AI), machine learning, and learning analytics
to improve teaching quality and learning performance. The goal of precision education is to identify at-risk
students as early as possible and provide timely intervention on the basis of teaching and learning experiences
(Lu et al., 2018). Drawing from this main theme of precision education, this special issue advocates an in-depth
dialogue between cold technology and warm humanity, in turn offering greater understanding of precision
education. For this special issue, thirteen research papers that specialize in precision education, AI, machine
learning, and learning analytics to engage in an in-depth research experiences concerning various applications,
methods, pedagogical models, and environments were exchanged to achieve better understanding of the
application of AI in education",0
"With the increasing use of Artificial Intelligence (AI) technologies in education, the number of published studies in the field has increased. The study was backed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework and furthermore utilized computational literature review as well as bibliometric analysis techniques for knowledge extraction purposes. However, no large-scale reviews have been conducted to comprehensively investigate the various aspects of this field. Based on 4,519 publications from 2000 to 2019, we attempt to fill this gap and identify trends and topics related to AI applications in education (AIEd) using topicbased bibliometrics. Results of the review reveal an increasing interest in using AI for educational purposes from the academic community. This study presented the development of an AI Taekwondo performance improvement analysis and evaluation system and a metaverse-based virtual Taekwondo pumsae/fighting coaching platform through an AI-based motion tracking analysis method. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. We also discuss the challenges and future directions of AIEd.","With the increasing use of Artificial Intelligence (AI) technologies in education, the number of published studies in the field has increased. However, no large-scale reviews have been conducted to comprehensively investigate the various aspects of this field. Based on 4,519 publications from 2000 to 2019, we attempt to fill this gap and identify trends and topics related to AI applications in education (AIEd) using topicbased bibliometrics. Results of the review reveal an increasing interest in using AI for educational purposes from the academic community. The main research topics include intelligent tutoring systems for special education; natural language processing for language education; educational robots for AI education; educational data mining for performance prediction; discourse analysis in computer-supported collaborative learning; neural networks for teaching evaluation; affective computing for learner emotion detection; and recommender systems for personalized learning. We also discuss the challenges and future directions of AIEd.",0
"With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. These include: (1) taking care to focus on issues relating to 'actually existing' AI rather than the overselling of speculative AI technologies; (2) clearly foregrounding the limitations of AI in terms of modelling social contexts, and simulating human intelligence, reckoning, autonomy and emotions; (3) foregrounding the social harms associated with AI use; (4) acknowledging the value-driven nature of claims around AI; and (5) paying closer attention to the environmental and ecological sustainability of continued AI development and implementation. Thus, in contrast to popular notions of AI as a neutral tool, the argument is made for engaging with the ongoing use of AI in education as a political action that has varying impacts on different groups of people in various educational contexts.","In light of fast-growing popular, political and professional discourses around AI in education, this article outlines five broad areas of contention that merit closer attention in future discussion and decision-making. These include: (1) taking care to focus on issues relating to 'actually existing' AI rather than the overselling of speculative AI technologies; (2) clearly foregrounding the limitations of AI in terms of modelling social contexts, and simulating human intelligence, reckoning, autonomy and emotions; (3) foregrounding the social harms associated with AI use; (4) acknowledging the value-driven nature of claims around AI; and (5) paying closer attention to the environmental and ecological sustainability of continued AI development and implementation. Thus, in contrast to popular notions of AI as a neutral tool, the argument is made for engaging with the ongoing use of AI in education as a political action that has varying impacts on different groups of people in various educational contexts.",0
"Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. With the aid of using the system, the volleyball technique level of students has been improved, and the teaching effect has been significantly enhanced. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies, as well as increasing the effectiveness of the training process. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.","Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.",0
"The experiment used piano sound as an example to verify the accuracy and reliability of the system. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Artificial intelligence (AI) is rapidly transforming various industries, including education. AI is being used in educational management
to enhance the learning process, improve student outcomes, and streamline administrative tasks. This research work aims to explore the
application of AI in educational management, including its benefits and challenges. Recently, artificial intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. The study finds that AI has several advantages, including
improving student engagement, personalization of learning, and cost-effectiveness. However, AI also poses several challenges, such as
ethical concerns, potential biases, and the need for re-skilling the workforce. The research concludes that AI has an enormous capacity
to improve educational management, but it must be deployed with care and caution.","Artificial intelligence (AI) is rapidly transforming various industries, including education. AI is being used in educational management
to enhance the learning process, improve student outcomes, and streamline administrative tasks. This research work aims to explore the
application of AI in educational management, including its benefits and challenges. The research work employs a systematic review
methodology, examining the literature on AI in educational management. The study finds that AI has several advantages, including
improving student engagement, personalization of learning, and cost-effectiveness. However, AI also poses several challenges, such as
ethical concerns, potential biases, and the need for re-skilling the workforce. The research concludes that AI has an enormous capacity
to improve educational management, but it must be deployed with care and caution.",0
"The development of artificial intelligence (AI) has enabled the acoustic analysis of multi-factor sound sources. Using artificial intelligence (AI) to its transformative advantage, the smart vision initiative represents a paradigm shift in the diagnostics and treatment of diabetic retinopathy. The primary aim of this initiative is to address all forms of diabetic retinopathy using cutting-edge AI techniques, including deep neural networks and machine learning. These advanced algorithms are designed for rapid and precise diagnosis, enabling swift interventions to prevent visual impairment by identifying intricate patterns that are invisible to the human eye. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. This early detection is crucial as it allows for immediate care, significantly reducing the risk of irreversible vision loss. The smart vision initiative sets the stage for a future where diabetic retinopathy no longer leads to blindness, offering a brighter, clearer, and safer optical future for those affected by the condition.","Using artificial intelligence (AI) to its transformative advantage, the smart vision initiative represents a paradigm shift in the diagnostics and treatment of diabetic retinopathy. The primary aim of this initiative is to address all forms of diabetic retinopathy using cutting-edge AI techniques, including deep neural networks and machine learning. These advanced algorithms are designed for rapid and precise diagnosis, enabling swift interventions to prevent visual impairment by identifying intricate patterns that are invisible to the human eye. Through the identification of complex patterns that are invisible to the human eye, these algorithms guarantee quick and accurate diagnosis. This early detection is crucial as it allows for immediate care, significantly reducing the risk of irreversible vision loss. The smart vision initiative sets the stage for a future where diabetic retinopathy no longer leads to blindness, offering a brighter, clearer, and safer optical future for those affected by the condition.",0
"The way healthcare is provided could be completely changed by the application of artificial intelligence (AI) and computer vision (CV). AI-enhanced computer vision can be applied to medical picture analysis, disease detection, patient health monitoring, surgical assistance, drug discovery acceleration, and the creation of individualized treatment programs. Improved diagnosis, lower costs, personalized treatment, better patient outcomes, and quicker drug discovery are all advantages of employing AI-assisted computer vision in healthcare. We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. The sorts of computer vision utilized in healthcare systems are discussed in this chapter, including medical image analysis, disease diagnosis, movement and gait analysis, surgical support, behavioral analysis, and medication discovery. Each line is then transformed into rectangular patches for character recognition by the text recognition network, comprising a vision-based text recognition model and a language network. Overall, AI-assisted computer vision holds immense promise for revolutionizing healthcare systems by enabling quicker and more accurate diagnosis, enhancing patient outcomes, and cutting costs. This review is performed based on literature sourced from Web of Science and Dimensions databases, where articles were thoroughly examined to identify AI use cases.","The way healthcare is provided could be completely changed by the application of artificial intelligence (AI) and computer vision (CV). AI-enhanced computer vision can be applied to medical picture analysis, disease detection, patient health monitoring, surgical assistance, drug discovery acceleration, and the creation of individualized treatment programs. Improved diagnosis, lower costs, personalized treatment, better patient outcomes, and quicker drug discovery are all advantages of employing AI-assisted computer vision in healthcare. However, the application of these technologies also presents difficulties in terms of data privacy, bias, and legal matters. The sorts of computer vision utilized in healthcare systems are discussed in this chapter, including medical image analysis, disease diagnosis, movement and gait analysis, surgical support, behavioral analysis, and medication discovery. The difficulties of employing computer vision in healthcare are also covered in the chapter, including data privacy concerns, bias, legal concerns, a lack of accessibility, and the complexity of biological systems. Overall, AI-assisted computer vision holds immense promise for revolutionizing healthcare systems by enabling quicker and more accurate diagnosis, enhancing patient outcomes, and cutting costs. To make sure that these technologies are used in an ethical and responsible manner, it is crucial to address the issues related to them.",0
"By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. The literature indicated cases of sports convergence with the application of fourth industrial revolution technologies, such as the game of go, golf, table tennis, soccer, American football, skiing, archery, and fencing. Agriculture is the ultimate imperative and primary source of origin to furnish domestic income for multifarious countries. This paper’s contributions are threefold: (1) the design of a comprehensive, on-site industrial OCR system for autonomous registration of iron plates; (2) the development of a realistic synthetic image generation strategy and a robust data augmentation strategy to address data scarcity; and (3) demonstrated impressive experimental results, indicating potential for on-site industrial applications. The disease caused in plants due to various pathogens like viruses, fungi, and bacteria is liable for considerable monetary losses in the agriculture corporation across the world. The security of crops concerning quality and quantity is crucial to monitor disease in plants. The vision network performs preliminary recognition, followed by refinement through the language model. The plant disease syndrome is noticeable in distinct parts of plants. Nonetheless, commonly the infection is detected in distinct leaves of plants. Computer vision, deep learning, few-shot learning, and soft computing techniques are utilized by various investigators to automatically identify the disease in plants via leaf images. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. Also, certain molecular techniques have been established to prevent and mitigate the pathogenic threat. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies, as well as increasing the effectiveness of the training process. Hence, this review helps the investigator to automatically detect disease in plants using machine learning, deep learning and few shot learning and provide certain diagnosis techniques to prevent disease. Moreover, some of the future works in the classification of disease are also discussed.","Agriculture is the ultimate imperative and primary source of origin to furnish domestic income for multifarious countries. The disease caused in plants due to various pathogens like viruses, fungi, and bacteria is liable for considerable monetary losses in the agriculture corporation across the world. The security of crops concerning quality and quantity is crucial to monitor disease in plants. Thus, recognition of plant disease is essential. The plant disease syndrome is noticeable in distinct parts of plants. Nonetheless, commonly the infection is detected in distinct leaves of plants. Computer vision, deep learning, few-shot learning, and soft computing techniques are utilized by various investigators to automatically identify the disease in plants via leaf images. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. Also, certain molecular techniques have been established to prevent and mitigate the pathogenic threat. Hence, this review helps the investigator to automatically detect disease in plants using machine learning, deep learning and few shot learning and provide certain diagnosis techniques to prevent disease. Moreover, some of the future works in the classification of disease are also discussed.",0
"The sphere of artificial intelligence (AI) technology is quite wide. With the rapid development of artificial intelligence, intelligent auxiliary systems have been widely used in various fields. This paper presents the development of a comprehensive, on-site industrial Optical Character Recognition (OCR) system tailored for reading text on iron plates. In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions. Computer vision is also related to other technologies: Machine learning (ML), deep learning (DL), artificial neural networks, etc. Computer vision is applied in many different areas. Through experimental verification, the intelligent assistant system can monitor students’ movements in real time, accurately evaluate their technical level, and provide personalized guidance. One of the areas where it has been widely applied in recent times is healthcare. In healthcare, various algorithms in the aforementioned technologies are used to obtain meaningful information from medical images. In this chapter, the concept of computer vision, its fields of application, and its application in healthcare are reviewed. Also, the example of tumor detection by computer vision in a MATLAB environment is considered.","The sphere of artificial intelligence (AI) technology is quite wide. There are many individual and collaborative AI-based technologies available. One of them is computer vision technology. Computer vision is also related to other technologies: Machine learning (ML), deep learning (DL), artificial neural networks, etc. Computer vision is applied in many different areas. One of the areas where it has been widely applied in recent times is healthcare. In healthcare, various algorithms in the aforementioned technologies are used to obtain meaningful information from medical images. In this chapter, the concept of computer vision, its fields of application, and its application in healthcare are reviewed. Also, the example of tumor detection by computer vision in a MATLAB environment is considered.",0
"Inverse gas chromatography (IGC) has emerged as a highly sensitive, adaptable, and effective technology for material analysis. Therefore, the purpose of this study is to design an intelligent auxiliary system using artificial muscle integrated optical equipment to realize real-time monitoring and accurate evaluation of volleyball teaching, so as to assist coaches to accurately guide students’ movement skills. In this comprehensive review, we delve into the historical background, instrumentation, and diverse applications of IGC. Researchers and practitioners will find valuable information on the selection and description of numerous models used in IGC experiments. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics
and sports medicine literature. Furthermore, IGC facilitates the measurement of important parameters such as sorption enthalpy and entropy, surface energy components (dispersive and specific), co/adhesion work, glass transition temperature, surface heterogeneity, miscibility, solubility parameters, and specific surface area. These insights contribute to a deeper understanding of material behavior and aid in the design and optimization of advanced materials. Moreover, the integration of computer vision and image processing techniques with IGC has enhanced our understanding of materials intricate surface texture, roughness, and related properties. Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution. This paper not only provides a comprehensive overview of IGC, its techniques, and applications but also highlights the synergistic potential of combining IGC with AI and computer vision. The informative content and insights presented here will benefit researchers, scientists, and professionals in the field of advanced materials, enabling them to leverage IGC and AI for innovative materials discovery and development.","Inverse gas chromatography (IGC) has emerged as a highly sensitive, adaptable, and effective technology for material analysis. Through employing thermochemical approaches, IGC provides crucial insight into physicochemical information of materials such as dispersive surface free energy, Gibbs surface energy components and Guttamann Lewis acid-base parameters. In this comprehensive review, we delve into the historical background, instrumentation, and diverse applications of IGC. Researchers and practitioners will find valuable information on the selection and description of numerous models used in IGC experiments. The applications of IGC span various domains, including polymers, medicines, minerals, surfactants, and nanomaterials. Furthermore, IGC facilitates the measurement of important parameters such as sorption enthalpy and entropy, surface energy components (dispersive and specific), co/adhesion work, glass transition temperature, surface heterogeneity, miscibility, solubility parameters, and specific surface area. These insights contribute to a deeper understanding of material behavior and aid in the design and optimization of advanced materials. Moreover, the integration of computer vision and image processing techniques with IGC has enhanced our understanding of materials intricate surface texture, roughness, and related properties. This convergence of IGC with computer vision and artificial intelligence (AI) presents exciting opportunities for future exploration of chemical materials, opening new avenues for research and discovery. This paper not only provides a comprehensive overview of IGC, its techniques, and applications but also highlights the synergistic potential of combining IGC with AI and computer vision. The informative content and insights presented here will benefit researchers, scientists, and professionals in the field of advanced materials, enabling them to leverage IGC and AI for innovative materials discovery and development.",0
"At present, the application of Artificial Intelligence (AI) in industrial control, smart home and other fields has received good response. However, AI technology has certain requirements for computer performance, and also faces problems in network security, data analysis, human-computer interaction, etc. At present, the visual platform of embedded system has achieved remarkable results in practical applications, but its development has been seriously hampered by problems such as low overall development efficiency and unstable system performance. This paper designed an EP Vision System (VS) based on AI technology. The platform combined the embedded hardware design with the Support Vector Machine (SVM) algorithm to realize the intelligent robot interaction and target detection functions. Chat Generated Pre-trained
Transformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. This can develop five-element music therapy. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. The proportion of positive evaluation of System X was much higher than that of System Y, which indicated that System X can meet the actual application requirements and improve the system recognition efficiency to a certain extent. It showed the positive relationship between AI technology and EP VS.","At present, the application of Artificial Intelligence (AI) in industrial control, smart home and other fields has received good response. However, AI technology has certain requirements for computer performance, and also faces problems in network security, data analysis, human-computer interaction, etc. At present, the visual platform of embedded system has achieved remarkable results in practical applications, but its development has been seriously hampered by problems such as low overall development efficiency and unstable system performance. This paper designed an EP Vision System (VS) based on AI technology. The platform combined the embedded hardware design with the Support Vector Machine (SVM) algorithm to realize the intelligent robot interaction and target detection functions. The test results showed that when other conditions were the same, students and experts had 83.5% and 90% positive evaluations of System X, and 16.5% and 10% negative evaluations respectively. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. The proportion of positive evaluation of System X was much higher than that of System Y, which indicated that System X can meet the actual application requirements and improve the system recognition efficiency to a certain extent. It showed the positive relationship between AI technology and EP VS.",0
"installed on the modern intelligent vehicles. Many Artificial Intelligence based foundation models have been proposed for smart sensing to recognize the known object classes in the new but similar scenarios. Artifcial intelligence helps with tracking activities, evaluating diagnostic images, predicting injury risk, and several other uses. However, it is still challenging for the foundation models of smart sensing to detect all the object classes in both seen and unseen scenarios. Our study offers contributions to theory and practice in the sports science and applied AI domains. This letter aims at pushing the boundary of smart sensing research for intelligent vehicles. We first summarize the current widely-used foundation models and the foundation intelligence needed for smart sensing of intelligent vehicles. We then explain Sora-based Parallel Vision to boost the foundation models of smart sensing from basic intelligence (1.0) to enhanced intelligence (2.0) and final generalized intelligence (3.0). Several representative case studies are discussed to show the potential usages of Sora-based Parallel Vision, followed by its future research direction.","installed on the modern intelligent vehicles. Many Artificial Intelligence based foundation models have been proposed for smart sensing to recognize the known object classes in the new but similar scenarios. However, it is still challenging for the foundation models of smart sensing to detect all the object classes in both seen and unseen scenarios. This letter aims at pushing the boundary of smart sensing research for intelligent vehicles. We first summarize the current widely-used foundation models and the foundation intelligence needed for smart sensing of intelligent vehicles. We then explain Sora-based Parallel Vision to boost the foundation models of smart sensing from basic intelligence (1.0) to enhanced intelligence (2.0) and final generalized intelligence (3.0). Several representative case studies are discussed to show the potential usages of Sora-based Parallel Vision, followed by its future research direction.",0
"The application of AI and machine learning, particularly the vision transformer method, in bacterial detection presents a promising solution to overcome limitations of traditional methods, offering faster and more accurate detection of disease-causing bacteria like E. coli and salmonella in water, crucial for human survival, with ongoing research to further assess its effectiveness in microbiology. Taekwondo is a traditional martial art that originated in Republic of Korea and gradually became a globally recognized sport. Leveraging the proven success of transformer architectures in various domains, we enhanced the model's performance by integrating a positional self-attention mechanism. We presented a novel approach for bacterial colony classification utilizing a positional self-attention transformer model. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. This allows the model to effectively capture spatial relationships and patterns within bacterial colonies, contributing to highly accurate classification results. Since taekwondo’s competition analysis is an analysis in which researchers manually write events, it takes a very long time to analyze, and the scale of the analysis varies depending on the researcher’s tendencies. We trained the model on a substantial dataset of bacterial images, which ensures its robustness and generalization to diverse colony types. The proposed model adeptly captured the spatial relationships and sequential patterns inherent in bacterial colony images, allowing for more accurate and robust classification. The proposed model demonstrated remarkable performance, achieving an accuracy of 98.50% in the classification of bacterial colonies. This novel approach surpasses traditional methods by effectively capturing intricate spatial relationships within microbial structures, offering unprecedented accuracy in discerning subtle morphological variations. The model's adaptability to diverse colony shapes and arrangements marks a significant advancement, promising to redefine the landscape of bacterial colony classification through the lens of state-of-the-art deep learning techniques. The high classification accuracy attained by the model, suggests its potential for practical applications in the early diagnosis of infectious diseases and the development of targeted treatments. The findings of this study underscore the effectiveness of incorporating positional self-attention in transformer models for image-based classification tasks, particularly in the domain of bacterial colony analysis.","The application of AI and machine learning, particularly the vision transformer method, in bacterial detection presents a promising solution to overcome limitations of traditional methods, offering faster and more accurate detection of disease-causing bacteria like E. coli and salmonella in water, crucial for human survival, with ongoing research to further assess its effectiveness in microbiology. This research introduces a revolutionary positional self-attention transformer model for the classification of bacterial colonies. Leveraging the proven success of transformer architectures in various domains, we enhanced the model's performance by integrating a positional self-attention mechanism. We presented a novel approach for bacterial colony classification utilizing a positional self-attention transformer model. This allows the model to effectively capture spatial relationships and patterns within bacterial colonies, contributing to highly accurate classification results. We trained the model on a substantial dataset of bacterial images, which ensures its robustness and generalization to diverse colony types. The proposed model adeptly captured the spatial relationships and sequential patterns inherent in bacterial colony images, allowing for more accurate and robust classification. The proposed model demonstrated remarkable performance, achieving an accuracy of 98.50% in the classification of bacterial colonies. This novel approach surpasses traditional methods by effectively capturing intricate spatial relationships within microbial structures, offering unprecedented accuracy in discerning subtle morphological variations. The model's adaptability to diverse colony shapes and arrangements marks a significant advancement, promising to redefine the landscape of bacterial colony classification through the lens of state-of-the-art deep learning techniques. The high classification accuracy attained by the model, suggests its potential for practical applications in the early diagnosis of infectious diseases and the development of targeted treatments. The findings of this study underscore the effectiveness of incorporating positional self-attention in transformer models for image-based classification tasks, particularly in the domain of bacterial colony analysis.",0
"The system is equipped with an interactive interface that shows students correct demonstrations of movements and provides real-time feedback and guidance. We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. Therefore, the purpose of this study is to design an intelligent auxiliary system using artificial muscle integrated optical equipment to realize real-time monitoring and accurate evaluation of volleyball teaching, so as to assist coaches to accurately guide students’ movement skills. Secondly, it brings revolutionary changes to the future transportation system. The application of image processing and computer vision in autonomous driving plays a key role in enabling vehicles to perceive and understand the surrounding environment and achieve intelligent decision-making and control. Therefore, in combination with the application of computer vision and artificial intelligence in automatic driving, this paper expounds the image processing technology in automatic driving, including camera and sensor technology, image acquisition and preprocessing, feature extraction and object detection, so as to discuss the application of computer vision algorithm in automatic driving. The research on lane keeping and recognition, obstacle detection and avoidance, traffic signal and sign recognition is of great practical significance.","Autonomous vehicle is a typical high-tech comprehensive application, including scene perception, optimization calculation, multi-level assisted driving and other functions, using computer vision, sensors, information fusion, information communication, high-performance computing, artificial intelligence and automatic control and other technologies. In these technologies, computer vision, as a direct entry point to data processing, is an integral part of autonomous driving. Secondly, it brings revolutionary changes to the future transportation system. The application of image processing and computer vision in autonomous driving plays a key role in enabling vehicles to perceive and understand the surrounding environment and achieve intelligent decision-making and control. Therefore, in combination with the application of computer vision and artificial intelligence in automatic driving, this paper expounds the image processing technology in automatic driving, including camera and sensor technology, image acquisition and preprocessing, feature extraction and object detection, so as to discuss the application of computer vision algorithm in automatic driving. The research on lane keeping and recognition, obstacle detection and avoidance, traffic signal and sign recognition is of great practical significance.",0
"Medical image segmentation is a crucial task in computer vision, playing a pivotal role in applications such as diagnostics, treatment planning, and medical research. The present study explores a wide range of methodologies employed in the field of medical research to achieve image segmentation. The main challenge we face in this process is how to effectively extract the features of music sounds and accurately identify different tones through algorithms. The strengths and limitations of each method are thoroughly examined. This paper focuses on analyzing various architectures used for medical image segmentation, specifically evaluating their performance. Further, we hypothesized that AI may promote its use in the medical field. This can develop five-element music therapy. As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. This research enhances the comprehension of how these methods can be applied within the medical sector, especially in the area of computer vision.","Medical image segmentation is a crucial task in computer vision, playing a pivotal role in applications such as diagnostics, treatment planning, and medical research. The present study explores a wide range of methodologies employed in the field of medical research to achieve image segmentation. These techniques range from traditional approaches based on thresholding, edge detection, region-based and clustering, to modern artificial intelligence methods, particularly deep learning techniques. The strengths and limitations of each method are thoroughly examined. This paper focuses on analyzing various architectures used for medical image segmentation, specifically evaluating their performance. It aims to delve deeply into the different segmentation methods, offering a comparative perspective on their effectiveness. Furthermore, This document delves into the most recent technological progress in segmentation, emphasizing major breakthroughs capable of transforming the precision and productivity of analyzing medical images. Through an exhaustive compilation and detailed critique of the results obtained by employing a range of segmentation strategies, the study presents the outcomes of multiple approaches, accompanied by an in-depth analysis of the strengths and weaknesses inherent to the various techniques applied to medical image segmentation. This research enhances the comprehension of how these methods can be applied within the medical sector, especially in the area of computer vision.",0
"Five-elements music therapy—based on the five-element theory—is a unique non-pharmacological therapy of East Asian traditional medicine. This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. Machine learning algorithms are used to analyze and identify the data to accurately assess the student’s movements. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. The discussion and conclusions emphasize the potential of A.I. and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy.","This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. The discussion and conclusions emphasize the potential of A.I. and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy.",0
"The face is the most essential part of the human body, and because of its distinctive traits, it is crucial for recognizing people. Facial recognition technology (FRT) is one of the most successful and fascinating technologies of the modern times. It has the potential to effectively provide individualized music therapy to individuals with illness. The world is moving towards contactless FRT after the COVID-19 pandemic. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. Due to its contactless biometric characteristics, FRT is becoming quite popular worldwide. Businesses are replacing conventional fingerprint scanners with artificial intelligence—based FRT, opening up enormous commercial prospects. Security and surveillance, authentication/access control systems, digital healthcare, photo retrieval, etc., are some sectors where its use has become essential. In the present communication, we presented the global adoption of FRT, its rising trend in the market, utilization of the technology in various sectors, its challenges and rising concerns with special reference to India and worldwide.","The face is the most essential part of the human body, and because of its distinctive traits, it is crucial for recognizing people. Facial recognition technology (FRT) is one of the most successful and fascinating technologies of the modern times. The world is moving towards contactless FRT after the COVID-19 pandemic. Due to its contactless biometric characteristics, FRT is becoming quite popular worldwide. Businesses are replacing conventional fingerprint scanners with artificial intelligence—based FRT, opening up enormous commercial prospects. Security and surveillance, authentication/access control systems, digital healthcare, photo retrieval, etc., are some sectors where its use has become essential. In the present communication, we presented the global adoption of FRT, its rising trend in the market, utilization of the technology in various sectors, its challenges and rising concerns with special reference to India and worldwide.",0
"Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies, as well as increasing the effectiveness of the training process. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of the techniques and data resources used in FER. The system is equipped with an interactive interface that shows students correct demonstrations of movements and provides real-time feedback and guidance. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) Finally, future lines of research and development directions of artificial intelligence applications, both in medical image segmentation and extended reality-based medical solutions, are discussed. Therefore, the purpose of this study is to design an intelligent auxiliary system using artificial muscle integrated optical equipment to realize real-time monitoring and accurate evaluation of volleyball teaching, so as to assist coaches to accurately guide students’ movement skills. This can develop five-element music therapy. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.","Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of the techniques and data resources used in FER. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) to the deep learning era. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.",0
"Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). With the development, deployment, and experience of AI models by both viewers and players, it is crucial to provide a comprehensive summary of AI applications in basketball. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) This paper presents the development of a comprehensive, on-site industrial Optical Character Recognition (OCR) system tailored for reading text on iron plates. Additionally, the article will also evaluate the role of ChatGPT in scientifc research
and publications. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.","Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of the techniques and data resources used in FER. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) to the deep learning era. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.",0
"With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. Chat Generated Pre-trained
Transformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. The experiment used piano sound as an example to verify the accuracy and reliability of the system. Deep facial recognition has made significant progress and is widely applied in real-world scenarios. A complete facial recognition system involves three main components: facial recognition, orientation, and representation. This system detects faces, aligns them to a standard view, and extracts features for recognition using deep convolutional neural networks. This article provides a detailed overview of the latest advancements in these areas, showing how deep learning has greatly enhanced their abilities. Object detection in machine vision is a challenging area that requires significant improvements. While image classification accuracy is nearing 2.25%, surpassing human performance, object detection algorithms are still in the early stages. Current algorithms achieve only 40.8 MAPS on modern objects, so careful dataset selection is crucial for optimal results.","Facial recognition is a well-established and popular field in Computer Vision, especially with advancements in deep learning and data sets. Deep facial recognition has made significant progress and is widely applied in real-world scenarios. A complete facial recognition system involves three main components: facial recognition, orientation, and representation. This system detects faces, aligns them to a standard view, and extracts features for recognition using deep convolutional neural networks. This article provides a detailed overview of the latest advancements in these areas, showing how deep learning has greatly enhanced their abilities. Object detection in machine vision is a challenging area that requires significant improvements. While image classification accuracy is nearing 2.25%, surpassing human performance, object detection algorithms are still in the early stages. Current algorithms achieve only 40.8 MAPS on modern objects, so careful dataset selection is crucial for optimal results.",0
"Facial recognition technology (FRT) is one of several artificial intelligence (AI)-based technologies used during the COVID-19 pandemic to control the spread of the virus. As planning for future pandemics is currently underway, this technology is envisioned as an efficient tool to track infected individuals and collect real-time surveillance data. With the continuous progress of art education and artificial intelligence technology, traditional music teaching models are facing transformation. Through in-depth research, we have designed a music sound recognition system that uses Mel frequency cepstral coefficient (MFCC) for feature parameter extraction, and combines BP neural network algorithm to construct a music sound learning model. Nonetheless, FRT presents some ethical and legal challenges, such as its use without ensuring consent from the individuals under surveillance, the protection of biometric data collected through surveillance, and the risk of using this information for other purposes besides public health. Despite being widely deployed in countries such as Russia and China, for pandemic purposes and beyond, western jurisdictions are much more reluctant to adopt it.","Facial recognition technology (FRT) is one of several artificial intelligence (AI)-based technologies used during the COVID-19 pandemic to control the spread of the virus. As planning for future pandemics is currently underway, this technology is envisioned as an efficient tool to track infected individuals and collect real-time surveillance data. When properly used, FRT can support governments’ strategies to implement public health surveillance, which is defined in the literature as ‘the systematic collection, storage, usage, and dissemination of personal information to identify an outbreak and mitigate the spread of disease’.
Nonetheless, FRT presents some ethical and legal challenges, such as its use without ensuring consent from the individuals under surveillance, the protection of biometric data collected through surveillance, and the risk of using this information for other purposes besides public health. Despite being widely deployed in countries such as Russia and China, for pandemic purposes and beyond, western jurisdictions are much more reluctant to adopt it.",0
"During the COVID-19 pandemic, Delhi, India, faced a pressing issue where approximately 1,500 COVID-19-positive patients went missing. In public health emergencies, such as pandemics, natural disasters, or other calamities, hospitals, and medical centres experience a sudden influx of patients, and hospital management faces difficulties in keeping track of patients, especially when they need to be moved between facilities or when new temporary healthcare facilities are set up. As a consequence of these challenges, there can be an increase in missing person cases. Recently, artificial intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. Patients may be inadvertently separated from their families. The human face is a unique biometric system that can determine the age, gender, mood, of an individual, and even identity for verification purposes. Harbouring the power of deep learning and artificial intelligence, one of the most important applications of computer vision is Patient Identification. Findings reveal that this AI tool can assist fashion designers in creating both visually expressive attire and ready-to-wear products, meeting defined design criteria and consumer needs. In this study, we have proposed a state-of-the-art patient face detection model using a twofold model that uses MTCNN short for “multi-task cascaded convolution neural network” for face detection and alignment purposes with a FaceNet Convolutional Neural Network (CNN) a renowned face embedding algorithm finally with KNN algorithm as a classifier to get an accuracy of 97.1%. Also, to ensure public safety during the pandemic we have constituted a Resnet34 model for mask detection trained on the Face Mask Detection dataset with an accuracy of 97%. This study not only addresses the immediate challenges of patient identification and safety during crises but also carries implications for broader healthcare applications. The proposed models offer promising avenues for enhancing patient care and security.","During the COVID-19 pandemic, Delhi, India, faced a pressing issue where approximately 1,500 COVID-19-positive patients went missing. In public health emergencies, such as pandemics, natural disasters, or other calamities, hospitals, and medical centres experience a sudden influx of patients, and hospital management faces difficulties in keeping track of patients, especially when they need to be moved between facilities or when new temporary healthcare facilities are set up. As a consequence of these challenges, there can be an increase in missing person cases. Patients may be inadvertently separated from their families. The human face is a unique biometric system that can determine the age, gender, mood, of an individual, and even identity for verification purposes. Harbouring the power of deep learning and artificial intelligence, one of the most important applications of computer vision is Patient Identification. In this study, we have proposed a state-of-the-art patient face detection model using a twofold model that uses MTCNN short for “multi-task cascaded convolution neural network” for face detection and alignment purposes with a FaceNet Convolutional Neural Network (CNN) a renowned face embedding algorithm finally with KNN algorithm as a classifier to get an accuracy of 97.1%. Also, to ensure public safety during the pandemic we have constituted a Resnet34 model for mask detection trained on the Face Mask Detection dataset with an accuracy of 97%. This study not only addresses the immediate challenges of patient identification and safety during crises but also carries implications for broader healthcare applications. The proposed models offer promising avenues for enhancing patient care and security.",0
"Well-being is one of the pillars of positive psychology, which is known to have positive effects not only on the personal and professional lives of individuals but also on teams and organizations. Understanding and promoting individual well-being is essential for staff health and long-term success, but current tools for assessing subjective well-being rely on time-consuming surveys and questionnaires, which limit the possibility of providing the real-time feedback needed to raise awareness and change individual behavior. Our study offers contributions to theory and practice in the sports science and applied AI domains. This paper proposes a framework for understanding the process of non-verbal communication in teamwork, using video data to identify significant predictors of individual well-being in teamwork. It relies on video acquisition technologies and state-of-the-art artificial intelligence tools to extract individual, relative, and environmental characteristics from panoramic video. Our study offers contributions to theory and practice in the sports science and applied AI domains. Statistical analysis is applied to each time series, leading to the generation of a dataset of 125 features, which are then linked to PERMA (Positive Emotion, Engagement, Relationships, Meaning, and Accomplishments) surveys developed in the context of positive psychology. Each pillar of the PERMA model is evaluated as a regression or classification problem using machine learning algorithms. Our approach was applied to a case study, where 80 students collaborated in 20 teams for a week on a team task in a face-to-face setting. This enabled us to formulate several hypotheses identifying factors influencing individual well-being in teamwork. These promising results point to interesting avenues for research, for instance fusing different media for the analysis of individual well-being in teamwork.","Well-being is one of the pillars of positive psychology, which is known to have positive effects not only on the personal and professional lives of individuals but also on teams and organizations. Understanding and promoting individual well-being is essential for staff health and long-term success, but current tools for assessing subjective well-being rely on time-consuming surveys and questionnaires, which limit the possibility of providing the real-time feedback needed to raise awareness and change individual behavior. This paper proposes a framework for understanding the process of non-verbal communication in teamwork, using video data to identify significant predictors of individual well-being in teamwork. It relies on video acquisition technologies and state-of-the-art artificial intelligence tools to extract individual, relative, and environmental characteristics from panoramic video. Statistical analysis is applied to each time series, leading to the generation of a dataset of 125 features, which are then linked to PERMA (Positive Emotion, Engagement, Relationships, Meaning, and Accomplishments) surveys developed in the context of positive psychology. Each pillar of the PERMA model is evaluated as a regression or classification problem using machine learning algorithms. Our approach was applied to a case study, where 80 students collaborated in 20 teams for a week on a team task in a face-to-face setting. This enabled us to formulate several hypotheses identifying factors influencing individual well-being in teamwork. These promising results point to interesting avenues for research, for instance fusing different media for the analysis of individual well-being in teamwork.",0
"Face recognition has a very important role in various applications, from security, surveillance to authentication. The system is equipped with an interactive interface that shows students correct demonstrations of movements and provides real-time feedback and guidance. For safety most of the household is having CC cameras such that they could recognize the persons from it. It has the potential to effectively provide individualized music therapy to individuals with illness. In few highly secured places where allowance to any unknown intruder is strictly prohibited. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Thereby, this paper deals with a system which could recognize the face of the intruder through surveillance camera using ML and AI based algorithms. The design specified is successfully implemented using HOG feature extraction and SVM classification algorithms and it classifies the faces for a video stream given as input. The major objective entitled to this paper is to recognize the faces of people from the video by HOG feature extractor and classify them using SVM and train the machine to tell who is the person working for the organization and who are the intruder.","Face recognition has a very important role in various applications, from security, surveillance to authentication. For safety most of the household is having CC cameras such that they could recognize the persons from it. These CCTV are allocated for having safety and to know who visited their houses. In few highly secured places where allowance to any unknown intruder is strictly prohibited. Thereby, this paper deals with a system which could recognize the face of the intruder through surveillance camera using ML and AI based algorithms. The design specified is successfully implemented using HOG feature extraction and SVM classification algorithms and it classifies the faces for a video stream given as input. The major objective entitled to this paper is to recognize the faces of people from the video by HOG feature extractor and classify them using SVM and train the machine to tell who is the person working for the organization and who are the intruder.",0
"The simulation experiments conducted in MATLAB environment show that our system can accurately recognize and extract the main frequency of music, and has higher performance compared to traditional methods. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. Just as technology is being used to solve all the problems so why not this one. The idea is to make a more convenient and advanced super market experience, where there are no cashiers or lines so that we can shop hassle free. This project implements Artificial Intelligence and Internet of Things to automate a supermarket for better efficiency. A person just needs to walk in after scanning their QR code through the app with their unique ID on it. In the last decade, AI use in Orthopaedics increased approximately tenfold. It will record the customer's presence in the shop. The shopping carts and baskets have sensors on them, which can detect the product entering or being taken out. The products are placed on shelves which have pressure sensors to detect if any product is picked up. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. These shelves are closed and they only open with your shopping cards. When you reach the counter, you only have swipe your card again and money will be deducted from your account according to your purchase and a receipt will be given. As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education.","The growing population also leads to a growing consumer base which increases the load and resources to cater the needs of the day-by-day increasing consumers. Just as technology is being used to solve all the problems so why not this one. The idea is to make a more convenient and advanced super market experience, where there are no cashiers or lines so that we can shop hassle free. This project implements Artificial Intelligence and Internet of Things to automate a supermarket for better efficiency. A person just needs to walk in after scanning their QR code through the app with their unique ID on it. It will record the customer's presence in the shop. The shopping carts and baskets have sensors on them, which can detect the product entering or being taken out. The products are placed on shelves which have pressure sensors to detect if any product is picked up. These shelves are closed and they only open with your shopping cards. When you reach the counter, you only have swipe your card again and money will be deducted from your account according to your purchase and a receipt will be given. We look forward to provide this technology to various super market chains in the country and abroad and help them implement it with a nominal one time investment.",0
"Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more focus. The datasets to be used in developing data-driven methods dramatically influence the performance of decision making; hence, it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle-, environment-, and driver-related data. This study compares the state-of-the-art datasets of these three categories and summarizes their features, including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also discusses potential applications of datasets on various aspects of AV decision making, assisting researchers in finding appropriate ones to support their own research. The future trends of AV dataset development are summarized.","Autonomous vehicles (AVs) are expected to reshape future transportation systems, and decision making is one of the critical modules toward high-level automated driving. To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more focus. The datasets to be used in developing data-driven methods dramatically influence the performance of decision making; hence, it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle-, environment-, and driver-related data. This study compares the state-of-the-art datasets of these three categories and summarizes their features, including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also discusses potential applications of datasets on various aspects of AV decision making, assisting researchers in finding appropriate ones to support their own research. The future trends of AV dataset development are summarized.",0
"With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. In this paper, a safe and reliable motion planning and control framework is proposed to handle the tracking errors caused by inaccurate tracking by coordinating the motion planning layer and controller. Specifically, motion space is divided into safe regions and risky regions by designing the movement restraint size dependent on tracking error to construct the repulsive potential field. The collision-free waypoint set can then be obtained by combining global search and the proposed waypoint set filtering method. The planned trajectory is fitted by an optimization-based approach which minimizes the acceleration of the reference trajectory. Then, the planned trajectory is checked and modified by the designed anti-collision modification to ensure safety. Using invertible transformation and adaptive compensation allows the transient trajectory tracking errors to be limited within the designed region even with actuator faults. Because tracking error is considered and margined at the planning level, safety and reliability can be guaranteed by the coordination between the planning and control levels under inaccurate tracking and actuator faults. Basketball in particular, has captured the interest of the real-time analytics and data science community. The advantages and effectiveness of the proposed motion planning and control method are verified by simulation and experimental results.","Accurate trajectory tracking is unrealistic in real-world scenarios, however, which is commonly assumed to facilitate motion planning algorithm design. In this paper, a safe and reliable motion planning and control framework is proposed to handle the tracking errors caused by inaccurate tracking by coordinating the motion planning layer and controller. Specifically, motion space is divided into safe regions and risky regions by designing the movement restraint size dependent on tracking error to construct the repulsive potential field. The collision-free waypoint set can then be obtained by combining global search and the proposed waypoint set filtering method. The planned trajectory is fitted by an optimization-based approach which minimizes the acceleration of the reference trajectory. Then, the planned trajectory is checked and modified by the designed anti-collision modification to ensure safety. Using invertible transformation and adaptive compensation allows the transient trajectory tracking errors to be limited within the designed region even with actuator faults. Because tracking error is considered and margined at the planning level, safety and reliability can be guaranteed by the coordination between the planning and control levels under inaccurate tracking and actuator faults. The advantages and effectiveness of the proposed motion planning and control method are verified by simulation and experimental results.",0
"How would people distribute risks of autonomous vehicles (AVs) in everyday road traffic? The rich literature on the ethics of autonomous vehicles (AVs) revolves around moral judgments in unavoidable collision scenarios. We argue for extending the debate to driving behaviors in everyday road traffic where ubiquitous ethical questions arise due to the permanent redistribution of risk among road users. Our study offers contributions to theory and practice in the sports science and applied AI domains. This distribution of risks raises ethically relevant questions that cannot be evaded by simple heuristics such as “hitting the brakes.” Using an interactive, graphical representation of different traffic situations, we measured participants’ preferences on driving maneuvers of AVs in a representative survey in Germany. Our participants’ preferences deviated significantly from mere collision avoidance. The main challenge we face in this process is how to effectively extract the features of music sounds and accurately identify different tones through algorithms. With the development, deployment, and experience of AI models by both viewers and players, it is crucial to provide a comprehensive summary of AI applications in basketball.","How would people distribute risks of autonomous vehicles (AVs) in everyday road traffic? The rich literature on the ethics of autonomous vehicles (AVs) revolves around moral judgments in unavoidable collision scenarios. We argue for extending the debate to driving behaviors in everyday road traffic where ubiquitous ethical questions arise due to the permanent redistribution of risk among road users. This distribution of risks raises ethically relevant questions that cannot be evaded by simple heuristics such as “hitting the brakes.” Using an interactive, graphical representation of different traffic situations, we measured participants’ preferences on driving maneuvers of AVs in a representative survey in Germany. Our participants’ preferences deviated significantly from mere collision avoidance. Interestingly, our participants were willing to take risks themselves for the benefit of other road users, suggesting that the social dilemma of AVs may be mitigated in risky environments. Our research might build a bridge between engineers and philosophers to discuss the ethics of AVs more constructively.",0
"Artificial intelligence is one of the emerging technologies that simulate human intelligence in machines by programming it to think like human beings and mimic their actions. An autonomous vehicle can function itself and carry out necessary functions without any human involvement. This innovative technology may provide increased passenger safety, less congested roads, congestion reduction, optimum traffic, lower fuel consumption, less pollution, and better travel experiences. The development of artificial intelligence (AI) has enabled the acoustic analysis of multi-factor sound sources. Autonomous vehicles play a vital role in industry, agriculture, transportation, and military applications. The autonomous vehicle's activities are supported by sensor data and a few artificial intelligence systems. Artificial intelligence is the collection of data, path planning, and execution in autonomous vehicles that require some machine learning techniques that are a part of artificial intelligence. But this comes with some privacy issues and security concerns. Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution. The issues of cybersecurity while incorporating artificial intelligence in autonomous vehicles will be covered in this article, along with the growing technology of self-driving automobiles.","Artificial intelligence is one of the emerging technologies that simulate human intelligence in machines by programming it to think like human beings and mimic their actions. An autonomous vehicle can function itself and carry out necessary functions without any human involvement. This innovative technology may provide increased passenger safety, less congested roads, congestion reduction, optimum traffic, lower fuel consumption, less pollution, and better travel experiences. Autonomous vehicles play a vital role in industry, agriculture, transportation, and military applications. The autonomous vehicle's activities are supported by sensor data and a few artificial intelligence systems. Artificial intelligence is the collection of data, path planning, and execution in autonomous vehicles that require some machine learning techniques that are a part of artificial intelligence. But this comes with some privacy issues and security concerns. Security is an important concern for autonomous vehicles. The issues of cybersecurity while incorporating artificial intelligence in autonomous vehicles will be covered in this article, along with the growing technology of self-driving automobiles.",0
"Throughout the last decades, the number of vehicles on the road has steadily increased due to the rising demand for urban mobility and contemporary logistics. Two of the many detrimental effects of more vehicles on the road, which also impede economic development, are increased traffic congestion and traffic accidents. The issues mentioned above can be significantly resolved by making vehicles smarter by reducing their reliance on humans. Over the past century, various nations have conducted extensive research that has fueled the automation of road vehicles. Recently, artificial intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. Our results revealed that the area of sports analytics is gaining momentum and AI in the basketball world has more adoption in China, USA, Australia, Canada, Italy and Spain from a research perspective. In order for AVs to perceive their surroundings and make the right decisions in real time, AI has emerged as a crucial component. This development of AI is being driven by the growth of big data from numerous sensing devices and cutting-edge computing resources. Through in-depth research, we have designed a music sound recognition system that uses Mel frequency cepstral coefficient (MFCC) for feature parameter extraction, and combines BP neural network algorithm to construct a music sound learning model.","Throughout the last decades, the number of vehicles on the road has steadily increased due to the rising demand for urban mobility and contemporary logistics. Two of the many detrimental effects of more vehicles on the road, which also impede economic development, are increased traffic congestion and traffic accidents. The issues mentioned above can be significantly resolved by making vehicles smarter by reducing their reliance on humans. Over the past century, various nations have conducted extensive research that has fueled the automation of road vehicles. The development of autonomous vehicle (AV) technologies is currently being pursued by all significant motor manufacturers worldwide. Undoubtedly, the widespread use of autonomous cars is more imminent than we realize given the development of artificial intelligence (AI). In order for AVs to perceive their surroundings and make the right decisions in real time, AI has emerged as a crucial component. This development of AI is being driven by the growth of big data from numerous sensing devices and cutting-edge computing resources. We must first examine AI's development and history in order to comprehend its functions in AV systems.",0
"The future sustainability of the global automotive industry will be greatly affected by the fourth industrial revolution and the evolution of artificial intelligence (AI). Finally, future lines of research and development directions of artificial intelligence applications, both in medical image segmentation and extended reality-based medical solutions, are discussed. In this chapter, the key factors of the autonomous vehicles (AVs) are analyzed using AI developments in radar and laser technology, commercial risk factors, self-driving consumer behavior, city infrastructure constraints, and social adaptations to new technology. Literature was sourced from six internet search electronic databases, consisting of three English databases and three Korean databases, from January 2016 to August 2023. The future trajectory of the AV industry is expected to be an interplay between commercial, social, risk, infrastructure, and regulatory mechanisms with various impacts on the industry’s stakeholders. This study predicts that the most likely sustainable scenario for the AV industry is that it will be driven by: (1) AI’s pulsed laser LiDAR (Light Detection and Ranging) with a sufficient loop frequency and GPS bi-directional cloud technology requirement, (2) pooled insurance in contrast to individual liability, (3) smart city infrastructure with expected sharp digital divide across transport regions leading to more regional inequality, and (4) customers who strongly prefer a human controlled semi-autonomous vehicle rather than complete machine autonomy.","The future sustainability of the global automotive industry will be greatly affected by the fourth industrial revolution and the evolution of artificial intelligence (AI). The “new normal” is projected to be driven by new industry standards including an increasingly autonomous self-driving technology, amended safety standards, more complex insurance regulations, adaptive social resistance to technological change, city infrastructure requirements with a digital divide, and disruptive business innovation based on strategic input supply partnerships with open-source AI. In this chapter, the key factors of the autonomous vehicles (AVs) are analyzed using AI developments in radar and laser technology, commercial risk factors, self-driving consumer behavior, city infrastructure constraints, and social adaptations to new technology. The future trajectory of the AV industry is expected to be an interplay between commercial, social, risk, infrastructure, and regulatory mechanisms with various impacts on the industry’s stakeholders. This study predicts that the most likely sustainable scenario for the AV industry is that it will be driven by: (1) AI’s pulsed laser LiDAR (Light Detection and Ranging) with a sufficient loop frequency and GPS bi-directional cloud technology requirement, (2) pooled insurance in contrast to individual liability, (3) smart city infrastructure with expected sharp digital divide across transport regions leading to more regional inequality, and (4) customers who strongly prefer a human controlled semi-autonomous vehicle rather than complete machine autonomy.",0
"The future of autonomous vehicles lies in the convergence of human-centric design and advanced AI capabilities. However, one limitation of this music therapy is that the classification of the five elements and its application is mainly based on subjective judgment. Autonomous vehicles of the future will not only transport passengers but also interact and adapt to their desires, making the journey comfortable, efficient, and pleasant. In this paper, we present a novel framework that leverages Large Language Models (LLMs) to enhance autonomous vehicles' decision-making processes. This study explores the comprehensive understanding of taekwondo, the application of fourth industrial revolution technologies in various kinds of sports, the development of taekwondo through artificial intelligence (AI), and essential technology in the fourth industrial revolution while suggesting advanced science directions through a literature review. By integrating LLMs' natural language capabilities and contextual understanding, specialized tools usage, synergizing reasoning, and acting with various modules on autonomous vehicles, this framework aims to seamlessly integrate the advanced language and reasoning capabilities of LLMs into autonomous vehicles. The proposed framework holds the potential to revolutionize the way autonomous vehicles operate, offering personalized assistance, continuous learning, and transparent decision-making, ultimately contributing to safer and more efficient autonomous driving technologies.","The future of autonomous vehicles lies in the convergence of human-centric design and advanced AI capabilities. Autonomous vehicles of the future will not only transport passengers but also interact and adapt to their desires, making the journey comfortable, efficient, and pleasant. In this paper, we present a novel framework that leverages Large Language Models (LLMs) to enhance autonomous vehicles' decision-making processes. By integrating LLMs' natural language capabilities and contextual understanding, specialized tools usage, synergizing reasoning, and acting with various modules on autonomous vehicles, this framework aims to seamlessly integrate the advanced language and reasoning capabilities of LLMs into autonomous vehicles. The proposed framework holds the potential to revolutionize the way autonomous vehicles operate, offering personalized assistance, continuous learning, and transparent decision-making, ultimately contributing to safer and more efficient autonomous driving technologies.",0
"The potential for connected automated vehicles is multifaceted, and automated advancement deals with more of Internet of Things (IoTs) development enabling artificial intelligence (AI). Early advancements in engineering, electronics, and many other fields have inspired AI. Further, we hypothesized that AI may promote its use in the medical field. There are several proposals of technologies used in automated vehicles. Automated vehicles contribute greatly toward traffic optimization and casualty reduction. In studying vehicle autonomy, there are two categories of development available: high-level system integrations like new-energy vehicles and intelligent transportation systems and the other involves backward subsystem advancement like sensor and information processing systems. The Advanced Driver Assistance System shows results that meet the expectations of real-world problems in vehicle autonomy. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). The system is equipped with an interactive interface that shows students correct demonstrations of movements and provides real-time feedback and guidance. This chapter discusses the history of autonomous vehicles (AV), trending research areas of artificial intelligence technology in AV, state-of-the-art datasets used for AV research, and several Machine Learning (ML)/Deep Learning (DL) algorithms constituting the functioning of AV as a system, concluding with the challenges and opportunities of AI in AV.","The potential for connected automated vehicles is multifaceted, and automated advancement deals with more of Internet of Things (IoTs) development enabling artificial intelligence (AI). Early advancements in engineering, electronics, and many other fields have inspired AI. There are several proposals of technologies used in automated vehicles. Automated vehicles contribute greatly toward traffic optimization and casualty reduction. In studying vehicle autonomy, there are two categories of development available: high-level system integrations like new-energy vehicles and intelligent transportation systems and the other involves backward subsystem advancement like sensor and information processing systems. The Advanced Driver Assistance System shows results that meet the expectations of real-world problems in vehicle autonomy. Situational intelligence that collects enormous amounts of data is considered for high-definition creation of city maps, land surveying, and quality checking of roads as well. The infotainment system of the transport covers the driver's gesture recognition, language transaction, and perception of the surroundings with the assistance of a camera, Light Detection and Ranging (LiDAR), and Radio Detection And Ranging (RADAR) along with localization of the objects in the scene. This chapter discusses the history of autonomous vehicles (AV), trending research areas of artificial intelligence technology in AV, state-of-the-art datasets used for AV research, and several Machine Learning (ML)/Deep Learning (DL) algorithms constituting the functioning of AV as a system, concluding with the challenges and opportunities of AI in AV.",0
"As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. Automated driving vehicles operate autonomously, also known as driverless cars that can operate without a human driver. Research on autonomous vehicles has substantially advanced in recent years. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). Although some people might be apprehensive to give a computer control of their vehicle, automated driving technologies have the potential to make roads safer. It has the potential to effectively provide individualized music therapy to individuals with illness. Unlike humans, computers do not really have difficulty keeping attention when driving. Additionally, by responding appropriately, an automated car can prevent accidents to potentially dangerous events on the road. The system uses artificial muscle integrated optical equipment, and collects the movement data of students in volleyball training in real time through optical sensors. For a variety of reasons, such as inexperience, incapacity, or age, many people are unable to operate a vehicle. With the rapid development of artificial intelligence, intelligent auxiliary systems have been widely used in various fields. Therefore, we will explore the architectures of both software and hardware of autonomous cars in this chapter, as well as their parts, benefits, and future developments.","Artificial intelligence is now a necessary component for both production and service systems in recent years, as technology has become a vital aspect of daily life. Automated driving vehicles operate autonomously, also known as driverless cars that can operate without a human driver. Research on autonomous vehicles has substantially advanced in recent years. Artificially intelligent autonomous vehicles are the current need of the society. Although some people might be apprehensive to give a computer control of their vehicle, automated driving technologies have the potential to make roads safer. Self-driving automobiles can address environmental issues as well as safety-related ones. Unlike humans, computers do not really have difficulty keeping attention when driving. Additionally, by responding appropriately, an automated car can prevent accidents to potentially dangerous events on the road. Self-driving technology has many advantages, one of which will make more easily accessible means of transport to people who are unable to drive. For a variety of reasons, such as inexperience, incapacity, or age, many people are unable to operate a vehicle. These individuals can travel considerably more safely and independently. Therefore, we will explore the architectures of both software and hardware of autonomous cars in this chapter, as well as their parts, benefits, and future developments.",0
"The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolution is the integration of Artificial Intelligence (AI) and learning algorithms, propelling vehicles into realms of unprecedented autonomy. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. Commencing with a current landscape overview, the paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. The study presents statistical insights into the usage and types of AI/learning algorithms over the years, showcasing the evolving research landscape within the automotive industry. Chat Generated Pre-trained
Transformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. It has the potential to effectively provide individualized music therapy to individuals with illness. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI and learning algorithms, and automating key tasks at each level. Additionally, the document discusses the variation in software package sizes across different autonomy levels","The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolution is the integration of Artificial Intelligence (AI) and learning algorithms, propelling vehicles into realms of unprecedented autonomy. This paper provides a comprehensive exploration of the evolutionary trajectory of AI within autonomous vehicles, tracing the journey from foundational principles to the most recent advancements. Commencing with a current landscape overview, the paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. The study presents statistical insights into the usage and types of AI/learning algorithms over the years, showcasing the evolving research landscape within the automotive industry. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI and learning algorithms, and automating key tasks at each level. Additionally, the document discusses the variation in software package sizes across different autonomy levels",0
"Human-AI interaction has become an important focus in the development of more responsive and humane technology. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. In this context, the use of artificial empathy strategies is of particular interest due to its potential in improving customer experiences affectively and socially. This research aims to explore the optimization of human-AI interactions through the application of artificial empathy strategies in improving affective and social customer experiences. Literature was sourced from six internet search electronic databases, consisting of three English databases and three Korean databases, from January 2016 to August 2023. The OCR results are then converted into digital characters and recorded in the iron plate registration system. The research approach used is qualitative by reviewing various studies and related literature. The data sources used are journals, articles and books that are relevant to the research topic. From the research results, it was found that the implementation of artificial empathy strategies in human-AI interactions has great potential to improve the quality of interactions and customer experiences. The use of technologies such as natural language processing, emotion recognition, and sentiment analysis can enable AI to respond more precisely and sensitively to user needs and emotions.","Human-AI interaction has become an important focus in the development of more responsive and humane technology. In this context, the use of artificial empathy strategies is of particular interest due to its potential in improving customer experiences affectively and socially. This research aims to explore the optimization of human-AI interactions through the application of artificial empathy strategies in improving affective and social customer experiences. The research approach used is qualitative by reviewing various studies and related literature. The data sources used are journals, articles and books that are relevant to the research topic. From the research results, it was found that the implementation of artificial empathy strategies in human-AI interactions has great potential to improve the quality of interactions and customer experiences. The use of technologies such as natural language processing, emotion recognition, and sentiment analysis can enable AI to respond more precisely and sensitively to user needs and emotions.",0
"Empathy computing is an emerging research field that integrates artificial intelligence (AI) and big data technology to predict, identify, simulate, and generate human empathy. This field builds upon psychological studies in terms of concepts, measurements, neural foundations, and applications of empathy, and employs innovative computing approaches for analyzing and simulating empathy. This article critically reviews current research on empathy computing and discusses its future directions from a psychological perspective, with the aim of facilitating foundational research and practical applications in this field. In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). On one hand, empathy computing primarily aims to analyze and comprehend empathy using computers. This endeavor can be further divided into two categories: (1) individual empathy assessment, which focuses on analyzing individual empathetic traits, and (2) empathetic content classification, which focuses on analyzing empathetic features in texts rather than individuals. On the other hand, research also focuses on simulating and expressing empathy through computing, which includes (3) the design of empathetic response systems and (4) the development of generative empathetic dialogue systems. The former provides users with a limited number of predefined rule-based responses and feedback to express empathy, while the latter utilizes AI to automatically generate a wide range of empathetic dialogues without relying on predefined rules. These four research streams are relatively independent yet complementary. Moreover, as research progresses, new directions will continue to emerge, such as improving the empathic capabilities of computers through brain-computer interface technology. Although research on empathy computing is still in its early stages, it has shown potential for innovative applications in scenarios such as mental health, education, business services, and public management. With the increasing prevalence of artificial intelligence, these fields, which involve substantial interpersonal interactions, are positioned to become the primary domains for human-computer interaction. As a result, they emerge as the key application scenarios for empathy computing. In the realm of mental health, empathy computing can assist in automatically evaluating and enhancing therapists' empathetic abilities. The OCR results are then converted into digital characters and recorded in the iron plate registration system. Additionally, it can provide personalized empathetic support and guidance through AI-driven chatbots. In the field of education, empathy computing can facilitate the learning process by employing empathetic AI tutors. Within the business sector, it enables organizations to deliver tailored customer experiences, thereby enhancing satisfaction and fostering loyalty through the generation of empathic dialogues. In public management, empathy computing can be used to generate empathetic discourse to counteract negative speech. Additionally, it facilitates policymakers to respond empathetically to citizens' needs and inquiries, thereby fostering trust between the government and the public. The vision network performs preliminary recognition, followed by refinement through the language model. These four scenarios illustrate the vast potential applications of empathy computing. However, due to concerns related to safety and ethics, complete reliance on computers to perform empathetic tasks is currently not feasible. Our study offers contributions to theory and practice in the sports science and applied AI domains. Empathy computing represents a transformative frontier, not only providing methods to measure and analyze empathy automatically on a larger scale but also enriching the theoretical landscape of empathy research. In the last decade, AI use in Orthopaedics increased approximately tenfold. This expansion raises novel questions about the universality of empathy and its potential evolution in human-computer interaction. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics
and sports medicine literature. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. It is beneficial for comprehensively understanding empathy and effectively promoting it in the context of an intelligent society. Future research should focus on developing integrated theoretical models of empathy computing, establishing reliable psychological and behavioral datasets of empathy-related characteristics, and validating and refining empathy computing research through a human-centered approach. Psychologists play indispensable roles in leading, evaluating, and optimizing research and practice in this field. The collaboration of scholars in psychology and computer science is imperative to ensure that AI learns empathy effectively and ethically, thereby fostering people’s wellbeing in the forthcoming intelligent society.","Empathy computing is an emerging research field that integrates artificial intelligence (AI) and big data technology to predict, identify, simulate, and generate human empathy. This field builds upon psychological studies in terms of concepts, measurements, neural foundations, and applications of empathy, and employs innovative computing approaches for analyzing and simulating empathy. This article critically reviews current research on empathy computing and discusses its future directions from a psychological perspective, with the aim of facilitating foundational research and practical applications in this field.
The current research on empathy computing can be categorized into four themes based on different purposes and methods. On one hand, empathy computing primarily aims to analyze and comprehend empathy using computers. This endeavor can be further divided into two categories: (1) individual empathy assessment, which focuses on analyzing individual empathetic traits, and (2) empathetic content classification, which focuses on analyzing empathetic features in texts rather than individuals. On the other hand, research also focuses on simulating and expressing empathy through computing, which includes (3) the design of empathetic response systems and (4) the development of generative empathetic dialogue systems. The former provides users with a limited number of predefined rule-based responses and feedback to express empathy, while the latter utilizes AI to automatically generate a wide range of empathetic dialogues without relying on predefined rules. These four research streams are relatively independent yet complementary. Moreover, as research progresses, new directions will continue to emerge, such as improving the empathic capabilities of computers through brain-computer interface technology.
Although research on empathy computing is still in its early stages, it has shown potential for innovative applications in scenarios such as mental health, education, business services, and public management. With the increasing prevalence of artificial intelligence, these fields, which involve substantial interpersonal interactions, are positioned to become the primary domains for human-computer interaction. As a result, they emerge as the key application scenarios for empathy computing. In the realm of mental health, empathy computing can assist in automatically evaluating and enhancing therapists' empathetic abilities. Additionally, it can provide personalized empathetic support and guidance through AI-driven chatbots. In the field of education, empathy computing can facilitate the learning process by employing empathetic AI tutors. Within the business sector, it enables organizations to deliver tailored customer experiences, thereby enhancing satisfaction and fostering loyalty through the generation of empathic dialogues. In public management, empathy computing can be used to generate empathetic discourse to counteract negative speech. Additionally, it facilitates policymakers to respond empathetically to citizens' needs and inquiries, thereby fostering trust between the government and the public. These four scenarios illustrate the vast potential applications of empathy computing. However, due to concerns related to safety and ethics, complete reliance on computers to perform empathetic tasks is currently not feasible. Instead, a collaboration between humans and computers is necessary.
Empathy computing represents a transformative frontier, not only providing methods to measure and analyze empathy automatically on a larger scale but also enriching the theoretical landscape of empathy research. It extends traditional studies on empathy in interpersonal relationships to explore its emerging manifestations in human-AI relationships. This expansion raises novel questions about the universality of empathy and its potential evolution in human-computer interaction. Empathy computing holds the promise of serving as a cornerstone for a unified theory of empathy that encompasses diverse relationship dynamics, ranging from human-human to human-machine interactions and beyond. It is beneficial for comprehensively understanding empathy and effectively promoting it in the context of an intelligent society.
Future research should focus on developing integrated theoretical models of empathy computing, establishing reliable psychological and behavioral datasets of empathy-related characteristics, and validating and refining empathy computing research through a human-centered approach. Psychologists play indispensable roles in leading, evaluating, and optimizing research and practice in this field. The collaboration of scholars in psychology and computer science is imperative to ensure that AI learns empathy effectively and ethically, thereby fostering people’s wellbeing in the forthcoming intelligent society.",0
"Recently, artificial intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. This was done by exploring how participants perceive anthropomorphic chatbots as machines or humans, the existence of verbal abuse during human chatbot interactions, and the expectation of chatbot helpfulness depending on gender dynamics. A semi-structured interview methodology with five students was conducted for qualitative data collection. The collected data was manually analyzed using thematic analysis. The results of this study found that there is empathy in human chatbot interaction, regardless of whether participants perceive anthropomorphic chatbots as humans or machines. However, the level of empathy is generally low as participants frustrate when they are dissatisfied with the response of chatbots and exit the chatbots without expressing their frustration, and they usually forget their frustration and come again with other questions another time. Literature was sourced from six internet search electronic databases, consisting of three English databases and three Korean databases, from January 2016 to August 2023. The study also shows that participants might expect more help and politeness if chatbots are more likely to be female.","This study was conducted to investigate the empathy between human chatbot interactions among computer science students at Uppsala University, Sweden. This was done by exploring how participants perceive anthropomorphic chatbots as machines or humans, the existence of verbal abuse during human chatbot interactions, and the expectation of chatbot helpfulness depending on gender dynamics. A semi-structured interview methodology with five students was conducted for qualitative data collection. The collected data was manually analyzed using thematic analysis. The results of this study found that there is empathy in human chatbot interaction, regardless of whether participants perceive anthropomorphic chatbots as humans or machines. However, the level of empathy is generally low as participants frustrate when they are dissatisfied with the response of chatbots and exit the chatbots without expressing their frustration, and they usually forget their frustration and come again with other questions another time. The study also shows that participants might expect more help and politeness if chatbots are more likely to be female.",0
"From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. This review is performed based on literature sourced from Web of Science and Dimensions databases, where articles were thoroughly examined to identify AI use cases. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.","From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.",0
"Literature was sourced from six internet search electronic databases, consisting of three English databases and three Korean databases, from January 2016 to August 2023. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. Five-elements music therapy—based on the five-element theory—is a unique non-pharmacological therapy of East Asian traditional medicine. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors.","Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors.",0
"In this context, AI may contribute to the automatization of the image scan segmentation process and increase the quality of the resulting 3D objects, which may lead to the generation of more realistic virtual objects. Advances in the performance of large language models (LLMs) have led some researchers to propose the emergence of theory of mind (ToM) in artificial intelligence (AI). LLMs can attribute beliefs, desires, intentions, and emotions, and they will improve in their accuracy. Rather than employing the characteristically human method of empathy, they learn to attribute mental states by recognizing linguistic patterns in a dataset that typically do not include that individual. Chat Generated Pre-trained
Transformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. We ask whether LLMs' inability to empathize precludes them from honoring an individual's right to be an exception, that is, from making assessments of character and predictions of behavior that reflect appropriate sensitivity to a person's individuality. Can LLMs seriously consider an individual's claim that their case is different based on internal mental states like beliefs, desires, and intentions, or are they limited to judging that case based on its similarities to others? We propose that the method of empathy has special significance for honoring the right to be an exception that is distinct from the value of predictive accuracy, at which LLMs excel. We conclude by considering whether using empathy to consider exceptional cases has intrinsic or merely practical value and we introduce conceptual and empirical avenues for advancing this investigation.","Advances in the performance of large language models (LLMs) have led some researchers to propose the emergence of theory of mind (ToM) in artificial intelligence (AI). LLMs can attribute beliefs, desires, intentions, and emotions, and they will improve in their accuracy. Rather than employing the characteristically human method of empathy, they learn to attribute mental states by recognizing linguistic patterns in a dataset that typically do not include that individual. We ask whether LLMs' inability to empathize precludes them from honoring an individual's right to be an exception, that is, from making assessments of character and predictions of behavior that reflect appropriate sensitivity to a person's individuality. Can LLMs seriously consider an individual's claim that their case is different based on internal mental states like beliefs, desires, and intentions, or are they limited to judging that case based on its similarities to others? We propose that the method of empathy has special significance for honoring the right to be an exception that is distinct from the value of predictive accuracy, at which LLMs excel. We conclude by considering whether using empathy to consider exceptional cases has intrinsic or merely practical value and we introduce conceptual and empirical avenues for advancing this investigation.",0
"In a world increasingly driven by AI systems, controversial use cases for AI that significantly affect people’s lives become more likely scenarios. Hence, increasing awareness of AI bias that might affect underprivileged groups becomes an increasing challenge. Our proposed music sound learning model is based on a BP neural network, which trains the network to learn the mapping relationship between music sound and pitch. The OCR results are then converted into digital characters and recorded in the iron plate registration system. We found that participants embodying personas in VR felt significantly more empathy toward the characters they embodied and rated the AI as significantly less fair compared to a baseline condition in which they imagined to be these characters. Furthermore, we investigate differences between embodied personas and discuss qualitative results to gain insight into the participant’s mental model creation.","In a world increasingly driven by AI systems, controversial use cases for AI that significantly affect people’s lives become more likely scenarios. Hence, increasing awareness of AI bias that might affect underprivileged groups becomes an increasing challenge. As Virtual Reality has previously been shown to increase empathy through immersive perspective-taking, we conducted a laboratory study in which participants were confronted with a biased Wizard of Oz AI while embodying personas that varied widely in their ability to achieve high financial credit scores due to their age and gender. We found that participants embodying personas in VR felt significantly more empathy toward the characters they embodied and rated the AI as significantly less fair compared to a baseline condition in which they imagined to be these characters. Furthermore, we investigate differences between embodied personas and discuss qualitative results to gain insight into the participant’s mental model creation.",0
"In the evolving landscape of financial decision-making, this study delves into the intricate relationships among Emotional Intelligence (EI), Artificial Intelligence (AI), and Investment Decisions (ID). It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers. Through empirical analysis, we reveal that EI not only directly impacts ID but also exerts its influence indirectly through AI-mediated pathways. Machine learning algorithms are used to analyze and identify the data to accurately assess the student’s movements. It suggests that most investors are influenced by the identified emotional intelligence when making investment decisions. This paper’s contributions are threefold: (1) the design of a comprehensive, on-site industrial OCR system for autonomous registration of iron plates; (2) the development of a realistic synthetic image generation strategy and a robust data augmentation strategy to address data scarcity; and (3) demonstrated impressive experimental results, indicating potential for on-site industrial applications. This nuanced understanding provides valuable insights for financial practitioners, policymakers, and researchers, emphasizing the need for holistic strategies that integrate emotional and technological dimensions in navigating the intricacies of modern investment landscapes. As the synergy between human intuition and artificial intelligence becomes increasingly integral to financial decision-making, this study contributes to the ongoing discourse on the symbiotic relationship between minds and machines in investments","In the evolving landscape of financial decision-making, this study delves into the intricate relationships among Emotional Intelligence (EI), Artificial Intelligence (AI), and Investment Decisions (ID). By scrutinizing the direct influence of human emotional intelligence on investment choices and elucidating the mediating role of AI in this process, our research seeks to unravel the complex interplay between minds and machines. Through empirical analysis, we reveal that EI not only directly impacts ID but also exerts its influence indirectly through AI-mediated pathways. The findings underscore the pivotal role of emotional awareness in investor decision-making, augmented by the technological capabilities of AI. It suggests that most investors are influenced by the identified emotional intelligence when making investment decisions. Furthermore, AI substantially impacts investors' decision-making process when it comes to investing; nevertheless, AI partially mediates the relationship between emotional intelligence and investment decisions. This nuanced understanding provides valuable insights for financial practitioners, policymakers, and researchers, emphasizing the need for holistic strategies that integrate emotional and technological dimensions in navigating the intricacies of modern investment landscapes. As the synergy between human intuition and artificial intelligence becomes increasingly integral to financial decision-making, this study contributes to the ongoing discourse on the symbiotic relationship between minds and machines in investments",0
"Subsequently, the detected text region undergoes line-by-line division through a text segmentation network. Empathy is a specific moral aspect of human behavior. The global workplace, and thereby a consideration of employee stakeholders, includes unique behavioral and ethical considerations, including a consideration of human empathy. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. Since taekwondo’s competition analysis is an analysis in which researchers manually write events, it takes a very long time to analyze, and the scale of the analysis varies depending on the researcher’s tendencies. As such, human emotions and interactions are complicated by daily work related expectations, employee/employer interactions and work practices, and the outcomes of employees’ work routines. Business ethics, human resources, and risk management practices are endemic aspects within workplaces. Therefore, the purpose of this study is to design an intelligent auxiliary system using artificial muscle integrated optical equipment to realize real-time monitoring and accurate evaluation of volleyball teaching, so as to assist coaches to accurately guide students’ movement skills. This paper explores a systematic ethical lens of the opportunities and the risks of AI ideation, development, and deployment in business-employee relations practices beyond a compliance mindset, and that introduces a further set of workplace considerations. Empathy is concerned with human intentions. The study was backed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework and furthermore utilized computational literature review as well as bibliometric analysis techniques for knowledge extraction purposes. As such, attributive ethical indications of the role of AI in the workplace and its impacts on employees is necessary. Moreover, this paper uses a cognitive lens of empathy and focuses on artificial morality related to the ethical concerns, implications, and practices of AI development, deployment, and workplace practices that may impact employees in a variety of business aspects.","Empathy is a specific moral aspect of human behavior. The global workplace, and thereby a consideration of employee stakeholders, includes unique behavioral and ethical considerations, including a consideration of human empathy. Further, the human aspects of workplaces are within the domain of human resources and managerial oversight in business organizations. As such, human emotions and interactions are complicated by daily work related expectations, employee/employer interactions and work practices, and the outcomes of employees’ work routines. Business ethics, human resources, and risk management practices are endemic aspects within workplaces. Increasingly, the understanding of models of AI-reliant business practices underscores the need for the consideration of the ethical aspects of AI impacts on employees in the workplace. This paper explores a systematic ethical lens of the opportunities and the risks of AI ideation, development, and deployment in business-employee relations practices beyond a compliance mindset, and that introduces a further set of workplace considerations. Empathy is concerned with human intentions. As such, attributive ethical indications of the role of AI in the workplace and its impacts on employees is necessary. Moreover, this paper uses a cognitive lens of empathy and focuses on artificial morality related to the ethical concerns, implications, and practices of AI development, deployment, and workplace practices that may impact employees in a variety of business aspects.",0
"Implementing empathy to healthcare chatbots is considered promising to create a sense of human warmth. However, existing research frequently overlooks the multidimensionality of empathy, leading to an insufficient understanding if artificial empathy is perceived similarly to interpersonal empathy. Additionally, the article will also evaluate the role of ChatGPT in scientifc research
and publications. This paper argues that implementing experiential expressions of empathy may have unintended negative consequences as they might feel inauthentic. In the last decade, AI use in Orthopaedics increased approximately tenfold. Instead, providing instrumental support could be more suitable for modeling artificial empathy as it aligns better with computer-like schemas towards chatbots. Two experimental studies using healthcare chatbots examine the effect of empathetic (feeling with), sympathetic (feeling for), and behavioral-empathetic (empathetic helping) vs. non-empathetic responses on perceived warmth, perceived authenticity, and their consequences on trust and using intentions. Results reveal that any kind of empathy (vs. no empathy) enhances perceived warmth resulting in higher trust and using intentions. This review is performed based on literature sourced from Web of Science and Dimensions databases, where articles were thoroughly examined to identify AI use cases. As hypothesized, empathetic, and sympathetic responses reduce the chatbot's perceived authenticity suppressing this positive effect in both studies. A third study does not replicate this backfiring effect in human-human interactions. This research thus highlights that empathy does not equally apply to human-bot interactions. It further introduces the concept of ‘perceived authenticity’ and demonstrates that distinctively human attributes might backfire by feeling inauthentic in interactions with chatbots.","Implementing empathy to healthcare chatbots is considered promising to create a sense of human warmth. However, existing research frequently overlooks the multidimensionality of empathy, leading to an insufficient understanding if artificial empathy is perceived similarly to interpersonal empathy. This paper argues that implementing experiential expressions of empathy may have unintended negative consequences as they might feel inauthentic. Instead, providing instrumental support could be more suitable for modeling artificial empathy as it aligns better with computer-like schemas towards chatbots. Two experimental studies using healthcare chatbots examine the effect of empathetic (feeling with), sympathetic (feeling for), and behavioral-empathetic (empathetic helping) vs. non-empathetic responses on perceived warmth, perceived authenticity, and their consequences on trust and using intentions. Results reveal that any kind of empathy (vs. no empathy) enhances perceived warmth resulting in higher trust and using intentions. As hypothesized, empathetic, and sympathetic responses reduce the chatbot's perceived authenticity suppressing this positive effect in both studies. A third study does not replicate this backfiring effect in human-human interactions. This research thus highlights that empathy does not equally apply to human-bot interactions. It further introduces the concept of ‘perceived authenticity’ and demonstrates that distinctively human attributes might backfire by feeling inauthentic in interactions with chatbots.",0
"The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics
and sports medicine literature. The development of artificial intelligence (AI) has enabled the acoustic analysis of multi-factor sound sources. But due to the inexplicability and black box effect of deep neural networks, we can only obtain results without knowing the applied reasoning behind them. That engenders scepticism and resistance from some quarters of deep learning-based technologies. In the context of emotion analysis used in business and public opinion monitoring, it is sometimes difficult for decision-makers to trust the outcome without explanation from the supposedly emotionless machines. There are mathematical-based explanation methods, and they often generalise emotion analysis as a classification task. Still, emotion should be different from other task categories because the generation of emotion involves human-specific factors and logic. Since taekwondo’s competition analysis is an analysis in which researchers manually write events, it takes a very long time to analyze, and the scale of the analysis varies depending on the researcher’s tendencies. The sports industry is progressively embracing technological advancements, and artificial intelligence stands out as a prominent innovation. This proposed framework emphasises considering the cause and trigger of emotions as the explanation for the deep learning-based emotion analysis, and it includes two main components: the extraction of the emotion cause and the visualisation of emotion-triggering words.","With the rapid development of artificial intelligence, there is an increasing number of industries relying on the accuracy and efficiency of deep learning algorithms. But due to the inexplicability and black box effect of deep neural networks, we can only obtain results without knowing the applied reasoning behind them. That engenders scepticism and resistance from some quarters of deep learning-based technologies. In the context of emotion analysis used in business and public opinion monitoring, it is sometimes difficult for decision-makers to trust the outcome without explanation from the supposedly emotionless machines. There are mathematical-based explanation methods, and they often generalise emotion analysis as a classification task. Still, emotion should be different from other task categories because the generation of emotion involves human-specific factors and logic. This paper proposes an emotion analysis explanation framework that is grounded in psychological theories focusing on the stimulus from classic emotion theories. This proposed framework emphasises considering the cause and trigger of emotions as the explanation for the deep learning-based emotion analysis, and it includes two main components: the extraction of the emotion cause and the visualisation of emotion-triggering words.",0
"Artificial intelligence chatbots have invaded the tourism industry owing to their low cost and high efficiency. However, the influence of emotional expressions of chatbots on service outcomes has not received much attention from researchers. It has the potential to effectively provide individualized music therapy to individuals with illness. Chatbots' expressions of concern for customers can improve customer satisfaction by reducing expectancy violations. Our study offers contributions to theory and practice in the sports science and applied AI domains. Artifcial intelligence helps with tracking activities, evaluating diagnostic images, predicting injury risk, and several other uses. These findings advance research on the emotional expressions of chatbots and provide critical insights for deploying chatbots in customer service in the tourism industry.","Artificial intelligence chatbots have invaded the tourism industry owing to their low cost and high efficiency. However, the influence of emotional expressions of chatbots on service outcomes has not received much attention from researchers. Drawing upon expectancy violations theory, we explored how emotional expressions of chatbots affect customer satisfaction using three experiments in the context of tourist attraction recommendations. Chatbots' expressions of concern for customers can improve customer satisfaction by reducing expectancy violations. In particular, customer's goal orientation, the human-likeness of chatbot's avatars, and the relationship type between customers and chatbots can moderate the negative relationship between emotional expression and expectancy violation. These findings advance research on the emotional expressions of chatbots and provide critical insights for deploying chatbots in customer service in the tourism industry.",0
"Our results revealed that the area of sports analytics is gaining momentum and AI in the basketball world has more adoption in China, USA, Australia, Canada, Italy and Spain from a research perspective. This chapter presents a systematic review on the relationship between artificial intelligence and emotions in education in Latin America and the Caribbean. The PRISMA systematic review methodology was used to describe the state of the situation of research on this topic, taking into account theories, methodologies, countries, and educational levels. Fifteen published articles were finally selected, focusing on Brazil and Colombia, university level, students as unit of analysis, methodologies based on facial recognition, psychology and software combined. Findings reveal that this AI tool can assist fashion designers in creating both visually expressive attire and ready-to-wear products, meeting defined design criteria and consumer needs.","This chapter presents a systematic review on the relationship between artificial intelligence and emotions in education in Latin America and the Caribbean. The PRISMA systematic review methodology was used to describe the state of the situation of research on this topic, taking into account theories, methodologies, countries, and educational levels. Fifteen published articles were finally selected, focusing on Brazil and Colombia, university level, students as unit of analysis, methodologies based on facial recognition, psychology and software combined. It is hoped to deepen the research in other disciplines, with other theories and methodologies.",0
"This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. The discussion and conclusions emphasize the potential of A.I. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy.","This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. The discussion and conclusions emphasize the potential of A.I. and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy.",0
"Initially, the system utilizes a text region detection network to identify the text area, enabling camera adjustments along the x and y axes and zoom enhancements for clearer text imagery. Since the 1950s, a significant number of clinical cases have confirmed the effectiveness of art in rehabilitation therapy and psychological interventions. With the advancement of artificial intelligence technology, AI painting software based on the Stable Diffusion algorithm model enables image creation through prompts and feedback. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics
and sports medicine literature. Therefore, whether AI painting software can positively impact human emotions becomes a critical factor for its application in art therapy. This study tracks and measures the emotional changes in patients before and after using the AI painting software Stable Diffusion WebUI using emotional vocabulary measurement methods. According to the experimental data of this project, artificial intelligence painting can leave a positive impression on human emotions. This result opens a new window for the integration of artificial intelligence with art therapy research. On one hand, it allows for the in-depth development of guided artificial intelligence painting software specifically designed as a dedicated tool for art therapy a form of AI software for artistic healing. On the other hand, it encourages further research into the effectiveness of traditional painting versus AI-assisted painting in art therapy, aiming to explore the underlying principles and mechanisms of art therapy.","Since the 1950s, a significant number of clinical cases have confirmed the effectiveness of art in rehabilitation therapy and psychological interventions. With the advancement of artificial intelligence technology, AI painting software based on the Stable Diffusion algorithm model enables image creation through prompts and feedback. Therefore, whether AI painting software can positively impact human emotions becomes a critical factor for its application in art therapy. This study tracks and measures the emotional changes in patients before and after using the AI painting software Stable Diffusion WebUI using emotional vocabulary measurement methods. According to the experimental data of this project, artificial intelligence painting can leave a positive impression on human emotions. This result opens a new window for the integration of artificial intelligence with art therapy research. On one hand, it allows for the in-depth development of guided artificial intelligence painting software specifically designed as a dedicated tool for art therapy a form of AI software for artistic healing. On the other hand, it encourages further research into the effectiveness of traditional painting versus AI-assisted painting in art therapy, aiming to explore the underlying principles and mechanisms of art therapy.",0
"INTRODUCTION: In recent years, there has been a convergence between Artificial Intelligence and neuroscience, particularly in studying the brain and developing treatments for neurological disorders. Artificial neural networks and deep learning provide valuable insights into neural processing and brain functioning. As a sport, volleyball has high technical requirements, and the traditional volleyball teaching method has certain limitations. OBJECTIVES: To evaluate the interaction between neuroscience and happiness based on the advances in Artificial Intelligence. METHODS: A bibliometric analysis was performed with articles from the Scopus database in 2013-2023; likewise, the VOSviewer was used for information processing. RESULTS A total of 603 articles were obtained, and it is evident that the most significant scientific production is centered in the United States (184), United Kingdom (74), and China (73). Three clusters are generated from the Co-occurrence - Author Keywords analysis. The first cluster, red, is related to Artificial Intelligence applications for predicting happiness; the second cluster, green, is associated with Artificial Intelligence tools in neuroscience; and the third cluster, blue, is related to neuroscience in psychology. The simulation experiments conducted in MATLAB environment show that our system can accurately recognize and extract the main frequency of music, and has higher performance compared to traditional methods. CONCLUSION: Neuroscience research has made significant leaps in understanding mental processes such as emotions and consciousness. Neuroscience has encountered happiness and is opening up to an approach that seeks evidence to understand people's well-being supported by Artificial Intelligence.","INTRODUCTION: In recent years, there has been a convergence between Artificial Intelligence and neuroscience, particularly in studying the brain and developing treatments for neurological disorders. Artificial neural networks and deep learning provide valuable insights into neural processing and brain functioning. Recent research tries to explain how neural processes influence an individual's happiness. OBJECTIVES: To evaluate the interaction between neuroscience and happiness based on the advances in Artificial Intelligence. METHODS: A bibliometric analysis was performed with articles from the Scopus database in 2013-2023; likewise, the VOSviewer was used for information processing. RESULTS A total of 603 articles were obtained, and it is evident that the most significant scientific production is centered in the United States (184), United Kingdom (74), and China (73). Three clusters are generated from the Co-occurrence - Author Keywords analysis. The first cluster, red, is related to Artificial Intelligence applications for predicting happiness; the second cluster, green, is associated with Artificial Intelligence tools in neuroscience; and the third cluster, blue, is related to neuroscience in psychology. CONCLUSION: Neuroscience research has made significant leaps in understanding mental processes such as emotions and consciousness. Neuroscience has encountered happiness and is opening up to an approach that seeks evidence to understand people's well-being supported by Artificial Intelligence.",0
"The pursuit of biologically inspired cognitive architectures (BICA) has driven significant advancements in artificial intelligence (AI) and artificial general intelligence (AGI). However, most existing BICA models lack a critical aspect of human intelligence: emotions and feelings. Machine learning algorithms are used to analyze and identify the data to accurately assess the student’s movements. This research explores the development and implementation of an emotion-integrated cognitive architecture that mimics human emotional processing within a computational framework. Our proposed architecture, Emotion-Integrated Cognitive Architecture (EICA), is inspired by the latest findings in cognitive psychology, neurobiology, neuroscience and affective computing. EICA aims to integrate emotional processing into the core of the AI system, enabling robust, flexible, and adaptable AI agents that can respond to complex and dynamic environments with human-like emotional intelligence. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics
and sports medicine literature. The architecture incorporates emotion-generating, recognition, and regulation mechanisms, allowing AI agents to perceive, interpret, and respond to emotions in themselves and others. We present the concept of EICA, including its modular structure and interaction with other cognitive components. We also provide case studies showcasing EICA's successful implementation in various AI applications, such as virtual assistants and adaptive robotics. The OCR results are then converted into digital characters and recorded in the iron plate registration system. This research represents a significant step towards achieving the BICA Challenge by advancing the computational replication of human emotional intelligence. By integrating emotions and feelings into AI systems, we move closer to realizing the full potential of bi-directional understanding between artificial and biological intelligences.","The pursuit of biologically inspired cognitive architectures (BICA) has driven significant advancements in artificial intelligence (AI) and artificial general intelligence (AGI). However, most existing BICA models lack a critical aspect of human intelligence: emotions and feelings. This research explores the development and implementation of an emotion-integrated cognitive architecture that mimics human emotional processing within a computational framework. Our proposed architecture, Emotion-Integrated Cognitive Architecture (EICA), is inspired by the latest findings in cognitive psychology, neurobiology, neuroscience and affective computing. EICA aims to integrate emotional processing into the core of the AI system, enabling robust, flexible, and adaptable AI agents that can respond to complex and dynamic environments with human-like emotional intelligence. The EICA model leverages advances in brain imaging and recording techniques to draw insights from the neural basis of emotions in humans. The architecture incorporates emotion-generating, recognition, and regulation mechanisms, allowing AI agents to perceive, interpret, and respond to emotions in themselves and others. We present the concept of EICA, including its modular structure and interaction with other cognitive components. We also provide case studies showcasing EICA's successful implementation in various AI applications, such as virtual assistants and adaptive robotics. This research represents a significant step towards achieving the BICA Challenge by advancing the computational replication of human emotional intelligence. By integrating emotions and feelings into AI systems, we move closer to realizing the full potential of bi-directional understanding between artificial and biological intelligences.",0
"Network news is an important way for netizens to get social information. Massive news information hinders netizens to get key information. Named entity recognition technology under artificial background can realize the classification of place, date and other information in text information. This article combines named entity recognition and deep learning technology. In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. The method jointly trains sentence and trigger vectors through a trigger-matching network, utilizing the trigger vectors as attention queries for subsequent sequence annotation models. Furthermore, the proposed method employs entity labels to effectively recognize neologisms in web news, enabling the customization of the set of sensitive words and the number of words within the set to be detected, as well as extending the web news word sentiment lexicon for sentiment observation. Through experimental verification, the intelligent assistant system can monitor students’ movements in real time, accurately evaluate their technical level, and provide personalized guidance. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies, as well as increasing the effectiveness of the training process. Moreover, the loss function curve shows that my model exhibits better accuracy and faster convergence speed than the compared model. Finally, my model achieves an average accuracy rate of 97.88% in sentiment viewpoint detection.","Network news is an important way for netizens to get social information. Massive news information hinders netizens to get key information. Named entity recognition technology under artificial background can realize the classification of place, date and other information in text information. This article combines named entity recognition and deep learning technology. Specifically, the proposed method introduces an automatic annotation approach for Chinese entity triggers and a Named Entity Recognition (NER) model that can achieve high accuracy with a small number of training data sets. The method jointly trains sentence and trigger vectors through a trigger-matching network, utilizing the trigger vectors as attention queries for subsequent sequence annotation models. Furthermore, the proposed method employs entity labels to effectively recognize neologisms in web news, enabling the customization of the set of sensitive words and the number of words within the set to be detected, as well as extending the web news word sentiment lexicon for sentiment observation. Experimental results demonstrate that the proposed model outperforms the traditional BiLSTM-CRF model, achieving superior performance with only a 20% proportional training data set compared to the 40% proportional training data set required by the conventional model. Moreover, the loss function curve shows that my model exhibits better accuracy and faster convergence speed than the compared model. Finally, my model achieves an average accuracy rate of 97.88% in sentiment viewpoint detection.",0
"This paper firstly researches English text emotion expression and information communication, classifies English text emotion expression and information communication according to the human emotion-value relationship, and summarizes the characteristics of English emotion expression and information communication. The vision network performs preliminary recognition, followed by refinement through the language model. Subsequently, the detected text region undergoes line-by-line division through a text segmentation network. To deal with the characteristics of English text quickly and efficiently, it is necessary to encode the emotional information of English text, and based on encoding, the BiLSTM neural network is applied to extract the emotional features of English text and solve the problem of the loss of emotional features through the loss function. With the aid of using the system, the volleyball technique level of students has been improved, and the teaching effect has been significantly enhanced. Then, the crawler tool is used to obtain the dataset from the Chinese English module under the MOOC of Chinese universities, and the evaluation indexes are set according to the model’s performance, followed by the experimental analysis of the English text emotion expression and information conveyance. The results show that compared with the original CNN, LSTM, and T-LSTM, the BiLSTM-based neural network performs better in the task of text emotion expression and information conveyance, with the accuracy rate staying above 0.925, and the effect on the English dataset is a bit better than that on the Chinese dataset. This study aims to enhance English teaching and communication between Chinese and foreign cultures.","This paper firstly researches English text emotion expression and information communication, classifies English text emotion expression and information communication according to the human emotion-value relationship, and summarizes the characteristics of English emotion expression and information communication. Secondly, using artificial intelligence technology, it is proposed to construct an analysis model for English text emotion and information communication using the BiLSTM neural network. To deal with the characteristics of English text quickly and efficiently, it is necessary to encode the emotional information of English text, and based on encoding, the BiLSTM neural network is applied to extract the emotional features of English text and solve the problem of the loss of emotional features through the loss function. Then, the crawler tool is used to obtain the dataset from the Chinese English module under the MOOC of Chinese universities, and the evaluation indexes are set according to the model’s performance, followed by the experimental analysis of the English text emotion expression and information conveyance. The results show that compared with the original CNN, LSTM, and T-LSTM, the BiLSTM-based neural network performs better in the task of text emotion expression and information conveyance, with the accuracy rate staying above 0.925, and the effect on the English dataset is a bit better than that on the Chinese dataset. This study aims to enhance English teaching and communication between Chinese and foreign cultures.",0
"The study was backed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework and furthermore utilized computational literature review as well as bibliometric analysis techniques for knowledge extraction purposes. Current efforts encounter challenges in balancing intra- and inter-speaker context dependencies when tackling intra-modal interactions. This balance is vital as it encompasses modeling self-dependency (emotional inertia) where speakers' own emotions affect them and modeling interpersonal dependencies (empathy) where counterparts' emotions influence a speaker. Furthermore, challenges arise in addressing cross-modal interactions that involve content with conflicting emotions across different modalities. To address this issue, we introduce an adaptive interactive graph network (IGN) called AdaIGN that employs the Gumbel Softmax trick to adaptively select nodes and edges, enhancing intra- and cross-modal interactions. Unlike undirected graphs, we use a directed IGN to prevent future utterances from impacting the current one. Next, we propose Node- and Edge-level Selection Policies (NESP) to guide node and edge selection, along with a Graph-Level Selection Policy (GSP) to integrate the utterance representation from original IGN and NESP-enhanced IGN. With the development, deployment, and experience of AI models by both viewers and players, it is crucial to provide a comprehensive summary of AI applications in basketball. To reduce computational complexity, we use pre-defined pseudo labels through self-supervised methods to mask unnecessary utterance nodes for selection. Experimental results show that AdaIGN outperforms state-of-the-art methods on two popular datasets. Our code will be available at https://github.com/TuGengs/AdaIGN.","Multimodal Emotion Recognition in Conversations (ERC) aims to identify the emotions conveyed by each utterance in a conversational video. Current efforts encounter challenges in balancing intra- and inter-speaker context dependencies when tackling intra-modal interactions. This balance is vital as it encompasses modeling self-dependency (emotional inertia) where speakers' own emotions affect them and modeling interpersonal dependencies (empathy) where counterparts' emotions influence a speaker. Furthermore, challenges arise in addressing cross-modal interactions that involve content with conflicting emotions across different modalities. To address this issue, we introduce an adaptive interactive graph network (IGN) called AdaIGN that employs the Gumbel Softmax trick to adaptively select nodes and edges, enhancing intra- and cross-modal interactions. Unlike undirected graphs, we use a directed IGN to prevent future utterances from impacting the current one. Next, we propose Node- and Edge-level Selection Policies (NESP) to guide node and edge selection, along with a Graph-Level Selection Policy (GSP) to integrate the utterance representation from original IGN and NESP-enhanced IGN. Moreover, we design a task-specific loss function that prioritizes text modality and intra-speaker context selection. To reduce computational complexity, we use pre-defined pseudo labels through self-supervised methods to mask unnecessary utterance nodes for selection. Experimental results show that AdaIGN outperforms state-of-the-art methods on two popular datasets. Our code will be available at https://github.com/TuGengs/AdaIGN.",0
"Segmentation of tumors in ultrasound (US) images of the breast is a critical issue in medical imaging. Due to the poor quality of US images and the varying specifications of US machines, segmentation and classification of abnormalities present difficulties even for trained radiologists. The paper aims to introduce a novel AI-based hybrid model for US segmentation that offers high accuracy, requires relatively smaller datasets, and is capable of handling previously unseen data. The software can be used for diagnostics and the US-guided biopsies. The development of artificial intelligence (AI) has enabled the acoustic analysis of multi-factor sound sources. A unique and robust hybrid approach that combines deep learning (DL) and multi-agent artificial life (AL) has been introduced. The algorithms are verified on three US datasets. The method outperforms 14 selected state-of-the-art algorithms applied to US images characterized by complex geometry and high level of noise. The paper offers an original classification of the images and tests to analyze the limits of the DL. The model has been trained and verified on 1264 ultrasound images. The main challenge we face in this process is how to effectively extract the features of music sounds and accurately identify different tones through algorithms. The images are in the JPEG and PNG formats. By using the MFCC algorithm, we have successfully solved this problem as it can effectively describe the time-frequency characteristics of music sound. The 14 benchmark algorithms include deformable shapes, edge linking, superpixels, machine learning, and DL methods. The tests use eight-region shape- and contour-based evaluation metrics. The proposed method (DL-AL) produces excellent results in terms of the dice coefficient (region) and the relative Hausdorff distance H3 (contour-based) as follows: the easiest image complexity level, Dice = 0.96 and H3 = 0.26; the medium complexity level, Dice = 0.91 and H3 = 0.82; and the hardest complexity level, Dice = 0.90 and H3 = 0.84. All other metrics follow the same pattern. The DL-AL outperforms the second best (Unet-based) method by 10–20%. The method has been also tested by a series of unconventional tests. The model was trained on low complexity images and applied to the entire set of images. These results are summarized below. (1) Only the low complexity images have been used for training (68% unknown images): Dice = 0.80 and H3 = 2.01. (2) The low and the medium complexity images have been used for training (51% unknown images): Dice = 0.86 and H3 = 1.32. (3) The low, medium, and hard complexity images have been used for training (35% unknown images): Dice = 0.92 and H3 = 0.76. These tests show a significant advantage of DL-AL over 30%","Segmentation of tumors in ultrasound (US) images of the breast is a critical issue in medical imaging. Due to the poor quality of US images and the varying specifications of US machines, segmentation and classification of abnormalities present difficulties even for trained radiologists. The paper aims to introduce a novel AI-based hybrid model for US segmentation that offers high accuracy, requires relatively smaller datasets, and is capable of handling previously unseen data. The software can be used for diagnostics and the US-guided biopsies. A unique and robust hybrid approach that combines deep learning (DL) and multi-agent artificial life (AL) has been introduced. The algorithms are verified on three US datasets. The method outperforms 14 selected state-of-the-art algorithms applied to US images characterized by complex geometry and high level of noise. The paper offers an original classification of the images and tests to analyze the limits of the DL. The model has been trained and verified on 1264 ultrasound images. The images are in the JPEG and PNG formats. The age of the patients ranges from 22 to 73 years. The 14 benchmark algorithms include deformable shapes, edge linking, superpixels, machine learning, and DL methods. The tests use eight-region shape- and contour-based evaluation metrics. The proposed method (DL-AL) produces excellent results in terms of the dice coefficient (region) and the relative Hausdorff distance H3 (contour-based) as follows: the easiest image complexity level, Dice = 0.96 and H3 = 0.26; the medium complexity level, Dice = 0.91 and H3 = 0.82; and the hardest complexity level, Dice = 0.90 and H3 = 0.84. All other metrics follow the same pattern. The DL-AL outperforms the second best (Unet-based) method by 10–20%. The method has been also tested by a series of unconventional tests. The model was trained on low complexity images and applied to the entire set of images. These results are summarized below. (1) Only the low complexity images have been used for training (68% unknown images): Dice = 0.80 and H3 = 2.01. (2) The low and the medium complexity images have been used for training (51% unknown images): Dice = 0.86 and H3 = 1.32. (3) The low, medium, and hard complexity images have been used for training (35% unknown images): Dice = 0.92 and H3 = 0.76. These tests show a significant advantage of DL-AL over 30%",0
"The designed autonomous system enhances iron plate registration efficiency and significantly reduces factory time and labor costs. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions. In pandemic management, ChatGPT rapidly disseminates vital information. As a sport, volleyball has high technical requirements, and the traditional volleyball teaching method has certain limitations. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions. Balancing AI’s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.","Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI’s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.",0
"Artificial neural networks have emerged as computationally plausible models of human language processing. Initially, the system utilizes a text region detection network to identify the text area, enabling camera adjustments along the x and y axes and zoom enhancements for clearer text imagery. A major criticism of these models is that the amount of training data they receive far exceeds that of humans during language learning. Here, we use two complementary approaches to ask how the models’ ability to capture human fMRI responses to sentences is affected by the amount of training data. This paper’s contributions are threefold: (1) the design of a comprehensive, on-site industrial OCR system for autonomous registration of iron plates; (2) the development of a realistic synthetic image generation strategy and a robust data augmentation strategy to address data scarcity; and (3) demonstrated impressive experimental results, indicating potential for on-site industrial applications. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally plausible in terms of the amount of training data given that this amount is similar to what children are estimated to be exposed to during the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to reach state-of-the-art next-word prediction performance on the human benchmark at different stages during training. Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing fMRI responses to sentences. Further, (ii) lower perplexity—a measure of next-word prediction performance—is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. In tandem, these findings establish that although some training is necessary for the models’ predictive ability, a developmentally realistic amount of training (~100 million words) may suffice.","Artificial neural networks have emerged as computationally plausible models of human language processing. A major criticism of these models is that the amount of training data they receive far exceeds that of humans during language learning. Here, we use two complementary approaches to ask how the models’ ability to capture human fMRI responses to sentences is affected by the amount of training data. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally plausible in terms of the amount of training data given that this amount is similar to what children are estimated to be exposed to during the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to reach state-of-the-art next-word prediction performance on the human benchmark at different stages during training. Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing fMRI responses to sentences. Further, (ii) lower perplexity—a measure of next-word prediction performance—is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. In tandem, these findings establish that although some training is necessary for the models’ predictive ability, a developmentally realistic amount of training (~100 million words) may suffice.",0
"This study examines the ethical challenges and regulatory dynamics of Artificial Intelligence (AI) in relation to data integrity and its influence on social dynamics. Employing a cross-sectional survey approach, primary data was collected from 650 AI practitioners across various sectors, encompassing developers, data scientists, ethicists, and policymakers. Artifcial intelligence helps with tracking activities, evaluating diagnostic images, predicting injury risk, and several other uses. The findings revealed a strong positive correlation between higher levels of regulatory compliance and perceived effectiveness in AI implementation, as well as between AI ethics awareness and data integrity assurance. Moreover, a significant relationship was observed between professional training in AI and its positive impact on social dynamics. However, experience in the AI field, while positively correlated, showed a weaker link to data integrity, indicating that experience alone is insufficient for ensuring effective AI practices. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. Since taekwondo’s competition analysis is an analysis in which researchers manually write events, it takes a very long time to analyze, and the scale of the analysis varies depending on the researcher’s tendencies. Future research directions include exploring AI ethics and regulation in diverse cultural contexts and the impact of emerging technologies like quantum computing on AI ethics.","This study examines the ethical challenges and regulatory dynamics of Artificial Intelligence (AI) in relation to data integrity and its influence on social dynamics. Employing a cross-sectional survey approach, primary data was collected from 650 AI practitioners across various sectors, encompassing developers, data scientists, ethicists, and policymakers. The study investigated the correlations between regulatory compliance, ethical awareness, professional training, and experience in AI practice with the effectiveness of AI implementation and data integrity. The findings revealed a strong positive correlation between higher levels of regulatory compliance and perceived effectiveness in AI implementation, as well as between AI ethics awareness and data integrity assurance. Moreover, a significant relationship was observed between professional training in AI and its positive impact on social dynamics. However, experience in the AI field, while positively correlated, showed a weaker link to data integrity, indicating that experience alone is insufficient for ensuring effective AI practices. The study highlights the importance of ethical considerations, regulatory frameworks, and professional training in shaping AI development and its societal implications. The need for dynamic, adaptable, and inclusive regulatory frameworks that can align AI practices with societal values and ethical norms is emphasized. Future research directions include exploring AI ethics and regulation in diverse cultural contexts and the impact of emerging technologies like quantum computing on AI ethics.",0
"In the last decade, AI use in Orthopaedics increased approximately tenfold. They raise the questions:
1. whether it is possible to communicate with, understand, and even empathically perceive artificial agents;
2. whether we should ascribe actual subjectivity and thus quasi-personal status to them beyond a certain level of simulation;
3. what will be the impact of an increasing dissolution of the distinction between simulated and real encounters. It concludes with possible developments and open challenges in AI applications in extended reality-based solutions. This assumption is ultimately based on the presupposition of a shared form of life, conceived here as �conviviality.�
(2) The possibility that future artificial agents could meet these preconditions is refuted on the basis of embodied and enactive cognition, which links subjectivity and consciousness to the aliveness of an organism. Initially, the system utilizes a text region detection network to identify the text area, enabling camera adjustments along the x and y axes and zoom enhancements for clearer text imagery. Here, possible consequences are discussed, especially using the example of virtual psychotherapy. Finally, the paper makes case for a mindful appproach to the language we use to talk about artificial systems and pleads for preventing a systematic pretense of subjectivity.","Advances in artificial intelligence (AI) create an increasing similarity between the performance of AI systems or AI-based robots and human communication. They raise the questions:
1. whether it is possible to communicate with, understand, and even empathically perceive artificial agents;
2. whether we should ascribe actual subjectivity and thus quasi-personal status to them beyond a certain level of simulation;
3. what will be the impact of an increasing dissolution of the distinction between simulated and real encounters.
(1) To answer these questions, the paper argues that the precondition for actually understanding others consists in the implicit assumption of the subjectivity of our counterpart, which makes shared feelings and a we-intentionality possible. This assumption is ultimately based on the presupposition of a shared form of life, conceived here as �conviviality.�
(2) The possibility that future artificial agents could meet these preconditions is refuted on the basis of embodied and enactive cognition, which links subjectivity and consciousness to the aliveness of an organism.
(3) Even if subjectivity is in principle impossible for artificial agents, the distinction between simulated and real subjectivity might nevertheless become increasingly blurred. Here, possible consequences are discussed, especially using the example of virtual psychotherapy. Finally, the paper makes case for a mindful appproach to the language we use to talk about artificial systems and pleads for preventing a systematic pretense of subjectivity.",0
"This paper navigates artificial intelligences recent advancements and increasing media attention. In the last decade, AI use in Orthopaedics increased approximately tenfold. A notable focus is placed on Eliezer Yudkowsky, a leading figure within the domain of artificial intelligence alignment, who aims to bridge the understanding gap between public perceptions and rationalist viewpoints on artificial intelligence technology. This focus analyzes his predicted course of action for artificial intelligence outlined within his unpublished paper AGI Ruin: A List of Lethalities. The experiment used piano sound as an example to verify the accuracy and reliability of the system. This is achieved by attempting to understand the concept of intelligence itself and identifying a reasonable working definition of that concept. The concept of intelligence is then applied to contemporary artificial intelligence capabilities and developments to understand its applicability to the technologies. This paper finds contemporary artificial intelligence systems are, to some extent, intelligent. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. However, it argues that both weak and strong artificial intelligence systems, devoid of human-defined goals, would not inherently pose existential threats to humanity, challenging the notions of artificial intelligence alignment, bringing into question the validity of Nick Bostroms Orthogonality Thesis. Our results revealed that the area of sports analytics is gaining momentum and AI in the basketball world has more adoption in China, USA, Australia, Canada, Italy and Spain from a research perspective. Furthermore, the possibility of artificial life created through the method of assembling various modules each emulating a separate mind function is discussed.","This paper navigates artificial intelligences recent advancements and increasing media attention. A notable focus is placed on Eliezer Yudkowsky, a leading figure within the domain of artificial intelligence alignment, who aims to bridge the understanding gap between public perceptions and rationalist viewpoints on artificial intelligence technology. This focus analyzes his predicted course of action for artificial intelligence outlined within his unpublished paper AGI Ruin: A List of Lethalities. This is achieved by attempting to understand the concept of intelligence itself and identifying a reasonable working definition of that concept. The concept of intelligence is then applied to contemporary artificial intelligence capabilities and developments to understand its applicability to the technologies. This paper finds contemporary artificial intelligence systems are, to some extent, intelligent. However, it argues that both weak and strong artificial intelligence systems, devoid of human-defined goals, would not inherently pose existential threats to humanity, challenging the notions of artificial intelligence alignment, bringing into question the validity of Nick Bostroms Orthogonality Thesis. Furthermore, the possibility of artificial life created through the method of assembling various modules each emulating a separate mind function is discussed.",0
"The impressive capabilities of living organisms arise from the way autonomy is materialized by their bodies. Across scales, living beings couple computational or cognitive intelligence with physical intelligence through body morphology, material multifunctionality, and mechanical compliance. While soft robotics has advanced the design and fabrication of physically intelligent bodies, the integration of information-processing capabilities for computational intelligence remains a challenge. This study explores the comprehensive understanding of taekwondo, the application of fourth industrial revolution technologies in various kinds of sports, the development of taekwondo through artificial intelligence (AI), and essential technology in the fourth industrial revolution while suggesting advanced science directions through a literature review. This paper presents the development of a comprehensive, on-site industrial Optical Character Recognition (OCR) system tailored for reading text on iron plates. Progress toward untethered autonomy will require deliberate convergence in how the field codevelops new materials, fabrication methods, and control strategies for soft robots. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Here, a new perspective is put forward: that researchers should use tasks alone to impose material and information constraints on soft robot design. Machine learning algorithms are used to analyze and identify the data to accurately assess the student’s movements. Taekwondo is a traditional martial art that originated in Republic of Korea and gradually became a globally recognized sport. This framework allows emergent synergies between material and information processing properties of soft matter to be readily exploited for task-capable agents. Particular attention is paid to the scale dependence of solutions. Finally, an outlook is presented on emerging research opportunities for achieving autonomy in future soft robots as large as elephant trunks and as small as paramecia.","The impressive capabilities of living organisms arise from the way autonomy is materialized by their bodies. Across scales, living beings couple computational or cognitive intelligence with physical intelligence through body morphology, material multifunctionality, and mechanical compliance. While soft robotics has advanced the design and fabrication of physically intelligent bodies, the integration of information-processing capabilities for computational intelligence remains a challenge. Consequently, perception and control limitations have constrained how soft robots are built today. Progress toward untethered autonomy will require deliberate convergence in how the field codevelops new materials, fabrication methods, and control strategies for soft robots. Here, a new perspective is put forward: that researchers should use tasks alone to impose material and information constraints on soft robot design. A conceptual framework is proposed for a task-first design paradigm that sidesteps limitations imposed by control strategies. This framework allows emergent synergies between material and information processing properties of soft matter to be readily exploited for task-capable agents. Particular attention is paid to the scale dependence of solutions. Finally, an outlook is presented on emerging research opportunities for achieving autonomy in future soft robots as large as elephant trunks and as small as paramecia.",0
"In this paper, Self-Reproduction characteristic of Artificial Life is introduced to computer animation. The sports industry is progressively embracing technological advancements, and artificial intelligence stands out as a prominent innovation. It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers. Based on Artificial Fish's phenotype, the contents of its chromosome are given. Based on this model, heredity rules are given. Artificial Fish could reproduce and grow in the virtual marine environment freely controlled by the gene model and rules. Our proposed music sound learning model is based on a BP neural network, which trains the network to learn the mapping relationship between music sound and pitch. Artificial behaviors include predefined behaviors and nondeterminate behaviors. Cognitive models based on Artificial Intelligence is put forward and built to control behaviors of artificial fish in high level. We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. These made groundwork to improve the efficiency and automatic level of artificial fish animation.","In this paper, Self-Reproduction characteristic of Artificial Life is introduced to computer animation. A Self-Reproduction model of Artificial Fish based on gene control is put forward and built. Based on Artificial Fish's phenotype, the contents of its chromosome are given. Based on this model, heredity rules are given. Artificial Fish could reproduce and grow in the virtual marine environment freely controlled by the gene model and rules. Artificial behaviors include predefined behaviors and nondeterminate behaviors. Cognitive models based on Artificial Intelligence is put forward and built to control behaviors of artificial fish in high level. Simulation program is designed and developed based on all these models built above. These made groundwork to improve the efficiency and automatic level of artificial fish animation.",0
"The experiment used piano sound as an example to verify the accuracy and reliability of the system. In this paper, the concepts of ""Life"", ""Artificial Life"" and ""Generalized Artificial Life"" and the problem ""Is Artificial Life true Life?"" In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions.","In this paper, the concepts of ""Life"", ""Artificial Life"" and ""Generalized Artificial Life"" and the problem ""Is Artificial Life true Life?"" are discussed.",0
"Therefore, the purpose of this study is to design an intelligent auxiliary system using artificial muscle integrated optical equipment to realize real-time monitoring and accurate evaluation of volleyball teaching, so as to assist coaches to accurately guide students’ movement skills. The game consists of a simulated Petri dish where two colonies of microorganisms-software agents-must struggle to survive. This review is performed based on literature sourced from Web of Science and Dimensions databases, where articles were thoroughly examined to identify AI use cases. The technical bases of the contest as well as a description of the artificial life model are explained in detail. The pedagogical experience acquired in the contest development is discussed, as well as the resulting learning experience, which generated students enthusiasm and has helped them to develop mental models of possible AI algorithms.","This work reports an experience in using an Artificial Life competitive game that simulates an artificial life environment for unstructured and informal Artificial Intelligence (AI) teaching to students from computer science engineering careers. The game consists of a simulated Petri dish where two colonies of microorganisms-software agents-must struggle to survive. To achieve this goal, the participants must implement surviving strategies for their agents, which include fighting strategies and basic reproduction rules to prevail over all the artificial environment. The technical bases of the contest as well as a description of the artificial life model are explained in detail. The pedagogical experience acquired in the contest development is discussed, as well as the resulting learning experience, which generated students enthusiasm and has helped them to develop mental models of possible AI algorithms.",0
"As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. By employing fuzzy logic controls, the ideal placement of distribution generators (DGs) can be determined, ensuring the reliability indices are identified through optimal power flow solutions and fuzzy logic controllers to maintain system feasibility. Our results revealed that the area of sports analytics is gaining momentum and AI in the basketball world has more adoption in China, USA, Australia, Canada, Italy and Spain from a research perspective. To identify areas of weakness, especially within transmission companies, accessing optimal power flow algorithms becomes essential in a deregulated power system. Both transmission and distribution networks should be appropriately adjusted to alleviate congestion within the respective companies. The aggregator must assess system performance, utilizing data obtained from distribution and transmission companies within the deregulated power system.","﻿Fuzzy logic emerges as a powerful tool for optimizing power flow solutions, particularly in the context of deregulated power systems. By employing fuzzy logic controls, the ideal placement of distribution generators (DGs) can be determined, ensuring the reliability indices are identified through optimal power flow solutions and fuzzy logic controllers to maintain system feasibility. In a deregulated power system, strategic placement of distribution generator units plays a crucial role in minimizing power loss and enhancing overall system performance by mitigating fluctuations. To identify areas of weakness, especially within transmission companies, accessing optimal power flow algorithms becomes essential in a deregulated power system. Both transmission and distribution networks should be appropriately adjusted to alleviate congestion within the respective companies. The aggregator must assess system performance, utilizing data obtained from distribution and transmission companies within the deregulated power system.",0
"In this article, the causes of technological disturbances in electrical systems are considered, and several characteristic disadvantages of the protection and automation of elements of electrical systems are highlighted. The tendency to decrease the reliability of relay protection associated with the transition from analog to digital types of protection is substantiated. Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution. Based on the studied examples, the use of fuzzy logic in protections, the expediency of using fuzzy logic elements in protection devices, and the automation of electrical systems to identify types of short circuits are justified. This article analyzes the most common damages and presents the results of modeling an electrical system with transformer coupling, where all types of asymmetric short circuits were initiated. The dynamics of changes in the symmetrical components of short-circuit currents of the forward, reverse, and zero sequences are determined. Rules have been created for the identification of asymmetric types of short circuits. An algorithm of protection and automation operation using fuzzy logic elements has been developed. Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution.","﻿In this article, the causes of technological disturbances in electrical systems are considered, and several characteristic disadvantages of the protection and automation of elements of electrical systems are highlighted. The tendency to decrease the reliability of relay protection associated with the transition from analog to digital types of protection is substantiated. Based on the studied examples, the use of fuzzy logic in protections, the expediency of using fuzzy logic elements in protection devices, and the automation of electrical systems to identify types of short circuits are justified. This article analyzes the most common damages and presents the results of modeling an electrical system with transformer coupling, where all types of asymmetric short circuits were initiated. The dynamics of changes in the symmetrical components of short-circuit currents of the forward, reverse, and zero sequences are determined. Rules have been created for the identification of asymmetric types of short circuits. An algorithm of protection and automation operation using fuzzy logic elements has been developed. The proposed algorithm of protection and automation will reduce the time to determine the type of damage and trigger protections.",0
"Fuzzy logic-based quantification of usability expectation for an m-commerce mobile application is a process of measuring the usability of a mobile application by using fuzzy logic principles. The usability of any mobile application is used to find out the user experience of the mobile application by analyzing the user's expectations and preferences. In the last decade, AI use in Orthopaedics increased approximately tenfold. Fuzzy logic-based quantification of usability expectation assesses the user experience of an m-commerce mobile application by taking into account the user's needs, preferences, and expectations. Five-elements music therapy—based on the five-element theory—is a unique non-pharmacological therapy of East Asian traditional medicine. Usability expectation also takes into account the ability of the user to understand and interact with the application, the degree to which the application meets the user's expectations, and the overall satisfaction with the application. This process helps to identify areas of improvement, enabling the developers to make necessary changes for a better user experience. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. The proposed usability metric framework is based on the Goal-Question-Metric (GQM) approach and is intended to provide a comprehensive and systematic approach to design metrics to assess the qualitative aspect of mobile phone applications. The framework has been developed and tested in an m-commerce context and provides a set of measurable criteria to quantify m-commerce mobile applications as per standard. The results of the evaluation can then be used to improve m-commerce mobile applications and to ensure that the user experience is optimized","﻿Fuzzy logic-based quantification of usability expectation for an m-commerce mobile application is a process of measuring the usability of a mobile application by using fuzzy logic principles. The usability of any mobile application is used to find out the user experience of the mobile application by analyzing the user's expectations and preferences. Fuzzy logic always be the optimal choice for quantification. Fuzzy logic-based quantification of usability expectation assesses the user experience of an m-commerce mobile application by taking into account the user's needs, preferences, and expectations. Usability expectation also takes into account the ability of the user to understand and interact with the application, the degree to which the application meets the user's expectations, and the overall satisfaction with the application. This process helps to identify areas of improvement, enabling the developers to make necessary changes for a better user experience. This study presents to design of a usability metric framework and then quantifies the overall usability quality of an m-commerce mobile application with the help of fuzzy logic. The proposed usability metric framework is based on the Goal-Question-Metric (GQM) approach and is intended to provide a comprehensive and systematic approach to design metrics to assess the qualitative aspect of mobile phone applications. The framework has been developed and tested in an m-commerce context and provides a set of measurable criteria to quantify m-commerce mobile applications as per standard. The results of the evaluation can then be used to improve m-commerce mobile applications and to ensure that the user experience is optimized",0
"The performance of photovoltaic (PV) affected directly by climatic changes, The controller maintain maximum potential energy conversation to operate the pimping system at nominal conditions, fuzzy logic intelligent controllers are successfully suitable and applicable in engineering and applied science. The aim of this paper is present an experimental approach in Implementation of fuzzy logic maximum power point tracking (MPPT) with boost converter based on Arduino Mega micro-controller to maximize energy production in different weather condition applied to small scale pumping system for water and chemical fluid analyses in isolated area. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics
and sports medicine literature. As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. The system is supplied by 20 (W) solar photovoltaic (PV) panel. This paper present a real-time MATLAB/Simulink fuzzy logic method controlling and monitoring MPPT application using an low cost Arduino Mega micro-controller combined with (LV25, LP55) sensors controlling boost converter interconnected with solar panel and plastic pump.","﻿The performance of photovoltaic (PV) affected directly by climatic changes, The controller maintain maximum potential energy conversation to operate the pimping system at nominal conditions, fuzzy logic intelligent controllers are successfully suitable and applicable in engineering and applied science. The aim of this paper is present an experimental approach in Implementation of fuzzy logic maximum power point tracking (MPPT) with boost converter based on Arduino Mega micro-controller to maximize energy production in different weather condition applied to small scale pumping system for water and chemical fluid analyses in isolated area. The system is supplied by 20 (W) solar photovoltaic (PV) panel. This paper present a real-time MATLAB/Simulink fuzzy logic method controlling and monitoring MPPT application using an low cost Arduino Mega micro-controller combined with (LV25, LP55) sensors controlling boost converter interconnected with solar panel and plastic pump.",0
"Therefore, the purpose of this study is to design an intelligent auxiliary system using artificial muscle integrated optical equipment to realize real-time monitoring and accurate evaluation of volleyball teaching, so as to assist coaches to accurately guide students’ movement skills. This article employs a fuzzy logic controller (FLC) to investigate voltage stability in a PV-based DC microgrid. In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions. Due to the widespread use of intermittent PV power, voltage stability is a crucial problem for DC microgrids and is difficult to accomplish. This study proposes an FLC-based voltage control technique that leverages input factors including PV output power, DC-DC converter duty cycle, and load current to identify the best course of action for preserving the system's voltage stability. Recently, artificial intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. The simulation results demonstrate that the suggested FLC-based control strategy successfully maintains the microgrid's voltage stability under a variety of operational circumstances, including changing solar irradiance and load variations. Moreover, the FLC performs better than other control methods.","﻿This article employs a fuzzy logic controller (FLC) to investigate voltage stability in a PV-based DC microgrid. Several photovoltaic (PV) modules, a DC-DC converter, and loads make up the microgrid. Due to the widespread use of intermittent PV power, voltage stability is a crucial problem for DC microgrids and is difficult to accomplish. This study proposes an FLC-based voltage control technique that leverages input factors including PV output power, DC-DC converter duty cycle, and load current to identify the best course of action for preserving the system's voltage stability. The FLC's performance is assessed by simulation, and it is meant to be resilient to parameter fluctuations and uncertainties. The simulation results demonstrate that the suggested FLC-based control strategy successfully maintains the microgrid's voltage stability under a variety of operational circumstances, including changing solar irradiance and load variations. Moreover, the FLC performs better than other control methods.",0
"With the development, deployment, and experience of AI models by both viewers and players, it is crucial to provide a comprehensive summary of AI applications in basketball. With the development, deployment, and experience of AI models by both viewers and players, it is crucial to provide a comprehensive summary of AI applications in basketball. This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. In this regard, we introduce a general barrier function and prescribed performance methodology to tackle constrained range impediments effectively. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. With the aid of the dynamic surface technology, we propose a decentralized adaptive event-triggering fault-tolerant (ETFT) formation control strategy. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). The system is equipped with an interactive interface that shows students correct demonstrations of movements and provides real-time feedback and guidance. Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems.","﻿This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. In this regard, we introduce a general barrier function and prescribed performance methodology to tackle constrained range impediments effectively. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. With the aid of the dynamic surface technology, we propose a decentralized adaptive event-triggering fault-tolerant (ETFT) formation control strategy. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems.",0
"Fuzzy inference systems (FISs) have been developed for many years but the use of FISs for high-dimensional problems is still a challenging task. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics
and sports medicine literature. The OCR results are then converted into digital characters and recorded in the iron plate registration system. Here, we primarily focus on addressing the problem that is associated with the use of the T-norms for designing high-dimensional FISs (HDFISs). Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution. The main novelty is that we propose an adaptive dimension-dependent membership function (DMF). For the minimum T-norm, an empirical observation led us to develop a mechanism that has the natural ability to deal with super high-dimensional problems, which results in another HDFIS named HDFIS-min. This can develop five-element music therapy. The simulation results demonstrate that both of them have competitive performance on handling high-dimensional datasets.","﻿Fuzzy inference systems (FISs) have been developed for many years but the use of FISs for high-dimensional problems is still a challenging task. The most frequently used T-norms for computing the firing strengths are product and minimum operators of which the former is often preferred because of its differentiability. However, for high-dimensional problems, the product T-norm suffers from the numeric underflow problem. Here, we primarily focus on addressing the problem that is associated with the use of the T-norms for designing high-dimensional FISs (HDFISs). For the product T-norm, we construct an HDFIS named HDFIS-prod, which easily escapes from the numeric underflow problem. The main novelty is that we propose an adaptive dimension-dependent membership function (DMF). For the minimum T-norm, an empirical observation led us to develop a mechanism that has the natural ability to deal with super high-dimensional problems, which results in another HDFIS named HDFIS-min. Both HDFIS-prod and HDFIS-min are tested on 18 datasets with feature dimensions varying from 1024 to 120450. The simulation results demonstrate that both of them have competitive performance on handling high-dimensional datasets.",0
"This study explores the comprehensive understanding of taekwondo, the application of fourth industrial revolution technologies in various kinds of sports, the development of taekwondo through artificial intelligence (AI), and essential technology in the fourth industrial revolution while suggesting advanced science directions through a literature review. This article examines a solution to the major problems of induction machine control in order to achieve superior dynamic performance. Conventional direct torque control and indirect control with flux orientation have some drawbacks, such as current harmonics, torque ripples, flux ripples, and rise time. In this article, we propose a comparative analysis between previous approaches and the one using fuzzy logic. Results from the simulation show that the direct torque control method using fuzzy logic is more effective in providing a precise and fast response without overshooting, and it eliminates torque and flux fluctuations at low switching frequencies. The fashion industry has shown increasing interest in applying artificial intelligence (AI), yet there is a significant gap in exploring the potential of emerging diffusion-modeling-based AI image-generation systems for fashion design and commerce.","﻿This article examines a solution to the major problems of induction machine control in order to achieve superior dynamic performance. Conventional direct torque control and indirect control with flux orientation have some drawbacks, such as current harmonics, torque ripples, flux ripples, and rise time. In this article, we propose a comparative analysis between previous approaches and the one using fuzzy logic. Results from the simulation show that the direct torque control method using fuzzy logic is more effective in providing a precise and fast response without overshooting, and it eliminates torque and flux fluctuations at low switching frequencies. The demonstrated improvements in dynamic performance contribute to increased operational efficiency and reliability in industrial applications.",0
"The main idea of this paper is the substantiation of the methodological approach to the assessment of personnel risks of enterprises based on the application of the fuzzy logic apparatus in order to identify the problems of personnel risk management and provide appropriate recommendations for their solution. The methodological basis of the study is the classic provisions and fundamental works of foreign and domestic scientists, statistical data, the results of our research into the problems of assessing personnel risks of enterprises. The methods of fuzzy set theory, comparative analysis, scientific abstraction, generalization of scientific experience of modern theoretical research, systemcomplex approach were used. The study proposed a methodological approach to assessing the level of personnel risks of an enterprise; numerical experiments were conducted on the basis of a group of construction equipment manufacturers. Analysis of the results of assessing the level of personnel risks of enterprises made it possible to identify the problems of managing personnel risks at enterprises Statement of a mathematical problem: the work considers hierarchical fuzzy data, namely: four groups of indicators for assessing the level of personnel risks (quantitative composition – F1, state of qualifications and intellectual potential – F2, staff turnover – F3, motivational system – F4), each of the indicators has a different number of fuzzy coefficients (there are twelve of them in the current work – vi , i=1÷12). Indicators are functions of fuzzy coefficients: F1 = r(v1, v2, v3); F2 = g(v4,v5, v6, v7); F3 = h(v8, v9, v10,); F4=q(v11, v12). As an output variable, there is a functional – an integrated indicator Int = f(F1, F2, F3, F4) of the personnel risk level, which, in turn, is also a fuzzy value. Our proposed music sound learning model is based on a BP neural network, which trains the network to learn the mapping relationship between music sound and pitch. Here, the functions r, g, h, q, f are unknown functions of the given variables. We have expert evaluations of the change in all input data; as a rule, they vary within three terms: Low (I), Medium (G), High (E). Formalized information on each variable can be written as , then for a group of indicators we have: . Using a fuzzy system and performing calculations with its help requires the system to have the following structural elements: membership functions of input and output variables, a rule base, and an output mechanism. The aim of this review article is to simplify the concept of AI and study the extent of AI use in Orthopaedics
and sports medicine literature. The built mathematical model and the method of its formalization on the basis of FST make it possible to estimate the level of personnel risk at the enterprise, which enables further substantiation of a set of measures to increase the efficiency of its use. The constructed system of fuzzy logical inference can be considered intelligent as it uses elements of computational intelligence, in particular, the theory of fuzzy sets. The proposed methodological approach to assessing the level of personnel risks of enterprises based on the apparatus of fuzzy logic allows, in contrast to existing ones, to integrate the consideration of both qualitative and quantitative indicators when assessing the level of personnel risks and personnel movement indicators and to significantly increase the efficiency of decision-making under conditions of uncertainty and reduce costs in the event of adverse situations.","﻿The main idea of this paper is the substantiation of the methodological approach to the assessment of personnel risks of enterprises based on the application of the fuzzy logic apparatus in order to identify the problems of personnel risk management and provide appropriate recommendations for their solution. The methodological basis of the study is the classic provisions and fundamental works of foreign and domestic scientists, statistical data, the results of our research into the problems of assessing personnel risks of enterprises. The methods of fuzzy set theory, comparative analysis, scientific abstraction, generalization of scientific experience of modern theoretical research, systemcomplex approach were used. The study proposed a methodological approach to assessing the level of personnel risks of an enterprise; numerical experiments were conducted on the basis of a group of construction equipment manufacturers. Analysis of the results of assessing the level of personnel risks of enterprises made it possible to identify the problems of managing personnel risks at enterprises Statement of a mathematical problem: the work considers hierarchical fuzzy data, namely: four groups of indicators for assessing the level of personnel risks (quantitative composition – F1, state of qualifications and intellectual potential – F2, staff turnover – F3, motivational system – F4), each of the indicators has a different number of fuzzy coefficients (there are twelve of them in the current work – vi , i=1÷12). Indicators are functions of fuzzy coefficients: F1 = r(v1, v2, v3); F2 = g(v4,v5, v6, v7); F3 = h(v8, v9, v10,); F4=q(v11, v12). As an output variable, there is a functional – an integrated indicator Int = f(F1, F2, F3, F4) of the personnel risk level, which, in turn, is also a fuzzy value. Here, the functions r, g, h, q, f are unknown functions of the given variables. We have expert evaluations of the change in all input data; as a rule, they vary within three terms: Low (I), Medium (G), High (E). Formalized information on each variable can be written as , then for a group of indicators we have: . Using a fuzzy system and performing calculations with its help requires the system to have the following structural elements: membership functions of input and output variables, a rule base, and an output mechanism. These structural elements are the components that will be built when designing a fuzzy system. The built mathematical model and the method of its formalization on the basis of FST make it possible to estimate the level of personnel risk at the enterprise, which enables further substantiation of a set of measures to increase the efficiency of its use. The constructed system of fuzzy logical inference can be considered intelligent as it uses elements of computational intelligence, in particular, the theory of fuzzy sets. The proposed methodological approach to assessing the level of personnel risks of enterprises based on the apparatus of fuzzy logic allows, in contrast to existing ones, to integrate the consideration of both qualitative and quantitative indicators when assessing the level of personnel risks and personnel movement indicators and to significantly increase the efficiency of decision-making under conditions of uncertainty and reduce costs in the event of adverse situations.",0
"Real-acting objects are characterized by the presence of various types of random perturbations, which significantly reduce the quality of the control process, which determines the use of modern methods of intellectual technology to solve the problem of synthesis of control systems of structurally complex dynamic objects, allowing to compensate the influence of external factors with the properties of randomness and partial uncertainty. The article considers issues of synthesis of the automatic control system of dynamic objects by applying the theory of intelligent control. In this case, a neural network based on radial-basis functions is used at each discrete interval for neuro-fuzzy approximation of the control system, allowing real-time adjustment of the regulator parameters. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. The radial basis function is designed to approximate functions defined in the implicit form of pattern sets. The neuro-fuzzy regulator's parameter configuration is accomplished using a genetic algorithm, enabling more efficient computation to determine the regulator's set parameters. Our study offers contributions to theory and practice in the sports science and applied AI domains. The regulator's parameters are represented as a vector, facilitating their application to multidimensional objects. With the aid of using the system, the volleyball technique level of students has been improved, and the teaching effect has been significantly enhanced. The effectiveness of the neuro-fuzzy regulator is explained by the possibility of providing quality control of the dynamic object under random perturbations and uncertainty of input data.","﻿Real-acting objects are characterized by the presence of various types of random perturbations, which significantly reduce the quality of the control process, which determines the use of modern methods of intellectual technology to solve the problem of synthesis of control systems of structurally complex dynamic objects, allowing to compensate the influence of external factors with the properties of randomness and partial uncertainty. The article considers issues of synthesis of the automatic control system of dynamic objects by applying the theory of intelligent control. In this case, a neural network based on radial-basis functions is used at each discrete interval for neuro-fuzzy approximation of the control system, allowing real-time adjustment of the regulator parameters. The radial basis function is designed to approximate functions defined in the implicit form of pattern sets. The neuro-fuzzy regulator's parameter configuration is accomplished using a genetic algorithm, enabling more efficient computation to determine the regulator's set parameters. The regulator's parameters are represented as a vector, facilitating their application to multidimensional objects. To determine the optimal tuning parameters of the neuro-fuzzy regulator, characterized by high convergence and the possibility of determining global extrema, a genetic algorithm was used. The effectiveness of the neuro-fuzzy regulator is explained by the possibility of providing quality control of the dynamic object under random perturbations and uncertainty of input data.",0
"Easy internet access and technological advancements have resulted in information overload and a plethora of options, making decision-making extremely difficult. Recommender System (RS) is a potential solution for assisting users in making decisions by recommending or predicting product ratings. Three fundamental forms of RS that use implicit or explicit feedback for recommendation are collaborative, content-based, and hybrid filtering. With the rapid development of artificial intelligence, intelligent auxiliary systems have been widely used in various fields. These additional variables can have a significant impact on RS’s performance. Traditional RSs used approaches based on the nearest neighbor or other machine learning models, but thanks to recent advances in artificial intelligence and deep learning, RSs are now being developed using Convolutional Neural Networks (CNN), which can efficiently exploit auxiliary information. This study presented the development of an AI Taekwondo performance improvement analysis and evaluation system and a metaverse-based virtual Taekwondo pumsae/fighting coaching platform through an AI-based motion tracking analysis method. Here, we discussed the challenges proposed by the future combination of five-element music therapy and AI. Therefore, the purpose of this study is to design an intelligent auxiliary system using artificial muscle integrated optical equipment to realize real-time monitoring and accurate evaluation of volleyball teaching, so as to assist coaches to accurately guide students’ movement skills.","Easy internet access and technological advancements have resulted in information overload and a plethora of options, making decision-making extremely difficult. Recommender System (RS) is a potential solution for assisting users in making decisions by recommending or predicting product ratings. Three fundamental forms of RS that use implicit or explicit feedback for recommendation are collaborative, content-based, and hybrid filtering. Ratings are the most common form of feedback, but product descriptions, reviews, images, audios, and videos are also important and can help improve the performance of the traditional RS. These additional variables can have a significant impact on RS’s performance. Traditional RSs used approaches based on the nearest neighbor or other machine learning models, but thanks to recent advances in artificial intelligence and deep learning, RSs are now being developed using Convolutional Neural Networks (CNN), which can efficiently exploit auxiliary information. In addition to comparing CNN-based RSs on common grounds, this article provides a full examination of CNN-based RSs and how they might use various types of auxiliary information. The study also discusses data characteristics, data statistics, and auxiliary information in a variety of publicly available datasets. Different evaluation measures for RSs are also discussed, and readers are provided with interesting challenges and open research issues.",0
"By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. Traditional education systems often adopt a one-size-fits-all approach to teaching that does not take into account the unique needs and learning styles of each student. In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions. This makes the learning process more dynamic and personalized. It can therefore be applied to all types of education, including language learning, mathematics, science, etc. This paper presents the development of a comprehensive, on-site industrial Optical Character Recognition (OCR) system tailored for reading text on iron plates. However, improving the efficiency of machine learning algorithms depends more on the improvement of numerical optimization algorithms, so it is necessary to summarize the optimization algorithms in large-scale machine learning. This paper tries to make a detailed overview of the existing machine learning algorithms in optimizing personalized education recommendation system, and introduces the algorithm optimization process.","In recent years, with the continuous progress and development of science and technology, especially the continuous development of artificial intelligence, machine algorithm and other technologies, the education system has also begun to carry out more personalized content from traditional functions. Traditional education systems often adopt a one-size-fits-all approach to teaching that does not take into account the unique needs and learning styles of each student. An education system personalized and optimized by machine learning algorithms can provide customized learning materials and recommendations based on each student's learning history, interests and abilities to improve learning outcomes, and machine learning algorithms can provide real-time feedback on student performance and adjust learning plans based on feedback. This makes the learning process more dynamic and personalized. It can therefore be applied to all types of education, including language learning, mathematics, science, etc. However, improving the efficiency of machine learning algorithms depends more on the improvement of numerical optimization algorithms, so it is necessary to summarize the optimization algorithms in large-scale machine learning. This paper tries to make a detailed overview of the existing machine learning algorithms in optimizing personalized education recommendation system, and introduces the algorithm optimization process.",0
"This paper presents a comprehensive literature review of the research and application of machine learning (ML) algorithms in recommender systems (RS). Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. The review highlights the enhanced recommendation accuracy, increased scalability, personalization and context awareness, diverse ML techniques, and strategies for handling cold start and data sparsity, and the foundation for future advancements in ML algorithms for RSs considering the application in manufacturing enterprises.","This paper presents a comprehensive literature review of the research and application of machine learning (ML) algorithms in recommender systems (RS). The study aims to identify recent trends, explore real-life applications, and guide researchers in positioning their research activities in this domain published in 2023 (Jan-June). The findings are categorized into different domains including education, healthcare, ML algorithms (auto-encoders and reinforcement learning), e-commerce, and digital journalism. The review highlights the enhanced recommendation accuracy, increased scalability, personalization and context awareness, diverse ML techniques, and strategies for handling cold start and data sparsity, and the foundation for future advancements in ML algorithms for RSs considering the application in manufacturing enterprises.",0
"Machine learning algorithms are used to analyze and identify the data to accurately assess the student’s movements. Smart cities represent the convergence of information and communication technologies (ICT) with urban management to improve the quality of life of city dwellers. In this context, recommender systems, tools that offer personalised suggestions to city dwellers, have emerged as key contributors to this convergence. Their successful application in various areas of city life and their ability to process massive amounts of data generated in urban environments has expedited their status as a crucial technology in the evolution of city planning. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Our methodology included reviewing the Web of Science database, resulting in 130 articles that, filtered for relevancy, were reduced to 86. The first stage consisted of carrying out a bibliometric analysis with the objective of analysing structural aspects with the SciMAT tool. Secondly, a systematic literature review was undertaken using the PRISMA 2020 statement. The results illustrated the different processes by which recommendations are filtered in areas such as tourism, health, mobility, and transport. This research is seen as a significant breakthrough that can drive the evolution and efficiency of smart cities, establishing a solid framework for future research in this dynamic field.","Smart cities represent the convergence of information and communication technologies (ICT) with urban management to improve the quality of life of city dwellers. In this context, recommender systems, tools that offer personalised suggestions to city dwellers, have emerged as key contributors to this convergence. Their successful application in various areas of city life and their ability to process massive amounts of data generated in urban environments has expedited their status as a crucial technology in the evolution of city planning. Our methodology included reviewing the Web of Science database, resulting in 130 articles that, filtered for relevancy, were reduced to 86. The first stage consisted of carrying out a bibliometric analysis with the objective of analysing structural aspects with the SciMAT tool. Secondly, a systematic literature review was undertaken using the PRISMA 2020 statement. The results illustrated the different processes by which recommendations are filtered in areas such as tourism, health, mobility, and transport. This research is seen as a significant breakthrough that can drive the evolution and efficiency of smart cities, establishing a solid framework for future research in this dynamic field.",0
"Internet of Things (IoT) based remote healthcare applications provide fast and preventative medical services to the patients at risk. However, predicting heart disease is a complex task and diagnosis results are rarely accurate. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed for providing prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, the physiological data are collected from the patient’s remotely by using the four bio sensors such as ECG sensor, Pressure sensor, Pulse sensor and Glucose sensor. An Arduino controller receives the collected data from the IoT sensors to predict and diagnose the disease. This paper’s contributions are threefold: (1) the design of a comprehensive, on-site industrial OCR system for autonomous registration of iron plates; (2) the development of a realistic synthetic image generation strategy and a robust data augmentation strategy to address data scarcity; and (3) demonstrated impressive experimental results, indicating potential for on-site industrial applications. Chat Generated Pre-trained
Transformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. The simulation experiments conducted in MATLAB environment show that our system can accurately recognize and extract the main frequency of music, and has higher performance compared to traditional methods. The proposed DEEP CARDIO method achieves an overall accuracy of 99.90% whereas, the MABC-SVM, HCBDA and MLbPM method achieves 86.91%, 88.65% and 93.63% respectively.","Internet of Things (IoT) based remote healthcare applications provide fast and preventative medical services to the patients at risk. However, predicting heart disease is a complex task and diagnosis results are rarely accurate. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed for providing prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, the physiological data are collected from the patient’s remotely by using the four bio sensors such as ECG sensor, Pressure sensor, Pulse sensor and Glucose sensor. An Arduino controller receives the collected data from the IoT sensors to predict and diagnose the disease. A cardiovascular disease prediction model is implemented by using BiGRU (Bidirectional-Gated Recurrent Unit) attention model which diagnose the cardiovascular disease and classify into five available cardiovascular classes. The recommendation system provides physical and dietary recommendations to cardiac patients based on the classified data, via user mobile application. The performance of the DEEP-CARDIO is validated by Cloud Simulator (CloudSim) using the real-time Framingham’s and Statlog heart disease dataset. The proposed DEEP CARDIO method achieves an overall accuracy of 99.90% whereas, the MABC-SVM, HCBDA and MLbPM method achieves 86.91%, 88.65% and 93.63% respectively.",0
"The latest effort in delivering computing resources as a service to managers and consumers represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to users over the internet from large-scale data centers. However, with the advent of the cloud-based IoT and artificial intelligence (AI), which are advancing customer experience automations in many application areas, such as recommender systems (RS), a need has arisen for various modifications to support the IoT devices that are at the center of the automation world, including recent language models like ChatGPT and Bard and technologies like nanotechnology. The experiment used piano sound as an example to verify the accuracy and reliability of the system. Although numerous research studies have been published on FC “smart” applications, none hitherto have been conducted on fog-based smart marketing domains such as recommender systems. FC is considered a novel computational system, which can mitigate latency and improve bandwidth utilization for autonomous consumer behavior applications requiring real-time data-driven decision making. The designed autonomous system enhances iron plate registration efficiency and significantly reduces factory time and labor costs. Indeed, our conceptualization of the “fog-based recommender systems” opens many novel and challenging avenues for academic research, some of which are highlighted in the later part of this paper. In recent years, music has been regarded as a promising non-pharmacological intervention for a number of physical and mental conditions.","The latest effort in delivering computing resources as a service to managers and consumers represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to users over the internet from large-scale data centers. However, with the advent of the cloud-based IoT and artificial intelligence (AI), which are advancing customer experience automations in many application areas, such as recommender systems (RS), a need has arisen for various modifications to support the IoT devices that are at the center of the automation world, including recent language models like ChatGPT and Bard and technologies like nanotechnology. This paper introduces the marketing community to a recent computing development: IoT-driven fog computing (FC). Although numerous research studies have been published on FC “smart” applications, none hitherto have been conducted on fog-based smart marketing domains such as recommender systems. FC is considered a novel computational system, which can mitigate latency and improve bandwidth utilization for autonomous consumer behavior applications requiring real-time data-driven decision making. This paper provides a conceptual framework for studying the effects of fog computing on consumer behavior, with the goal of stimulating future research by using, as an example, the intersection of FC and RS. Indeed, our conceptualization of the “fog-based recommender systems” opens many novel and challenging avenues for academic research, some of which are highlighted in the later part of this paper.
Keywords: fog computing; recommender system; internet of things (IoT); edge computing; artificial intelligence (AI); software defined networks (SDNs)
ormation as well as personal and situational data [66].",0
"Purpose: The general purpose of the study was to investigate the effectiveness of recommender systems in knowledge discovery. Methodology: The study adopted a desktop research methodology. Desk research refers to secondary data or that which can be collected without fieldwork. Desk research is basically involved in collecting data from existing resources hence it is often considered a low cost technique as compared to field research, as the main cost is involved in executive’s time, telephone charges and directories. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. This secondary data was easily accessed through the online journals and library. Findings: The findings reveal that there exists a contextual and methodological gap relating to recommender systems in knowledge discovery. The study on the effectiveness of recommender systems in knowledge discovery found that such systems played a pivotal role in facilitating users' exploration of vast information repositories, enabling them to uncover relevant resources and expand their knowledge. It found that recommender systems employing advanced algorithms and personalized techniques demonstrated higher effectiveness in generating relevant recommendations tailored to users' preferences and needs. Additionally, the study highlighted the positive correlation between user engagement metrics and knowledge discovery outcomes, emphasizing the importance of fostering active user participation in the recommendation process. Contextual information was also identified as a crucial factor influencing recommendation effectiveness. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Unique Contribution to Theory, Practice and Policy: The Social Learning theory, Information Foraging theory and Cognitive Load theory may be used to anchor future studies on recommender systems in knowledge discovery. The study provided recommendations to enhance the efficacy of such systems. It suggested adopting hybrid recommender systems that combine collaborative and content-based filtering techniques to offer more accurate and diverse recommendations. Additionally, the study emphasized the importance of integrating contextual information into recommendation algorithms to dynamically adjust recommendations based on situational context. Furthermore, it recommended the use of explainable AI techniques to improve transparency and user understanding of recommendation processes. Maximizing user engagement through active participation and feedback was also highlighted as crucial, along with prioritizing recommendation diversity to foster exploration and serendipitous discovery of new knowledge resources.","Purpose: The general purpose of the study was to investigate the effectiveness of recommender systems in knowledge discovery. Methodology: The study adopted a desktop research methodology. Desk research refers to secondary data or that which can be collected without fieldwork. Desk research is basically involved in collecting data from existing resources hence it is often considered a low cost technique as compared to field research, as the main cost is involved in executive’s time, telephone charges and directories. Thus, the study relied on already published studies, reports and statistics. This secondary data was easily accessed through the online journals and library. Findings: The findings reveal that there exists a contextual and methodological gap relating to recommender systems in knowledge discovery. The study on the effectiveness of recommender systems in knowledge discovery found that such systems played a pivotal role in facilitating users' exploration of vast information repositories, enabling them to uncover relevant resources and expand their knowledge. It found that recommender systems employing advanced algorithms and personalized techniques demonstrated higher effectiveness in generating relevant recommendations tailored to users' preferences and needs. Additionally, the study highlighted the positive correlation between user engagement metrics and knowledge discovery outcomes, emphasizing the importance of fostering active user participation in the recommendation process. Contextual information was also identified as a crucial factor influencing recommendation effectiveness. Overall, the study underscored the significance of continuous refinement and optimization of recommender system algorithms to enhance knowledge discovery outcomes for users. Unique Contribution to Theory, Practice and Policy: The Social Learning theory, Information Foraging theory and Cognitive Load theory may be used to anchor future studies on recommender systems in knowledge discovery. The study provided recommendations to enhance the efficacy of such systems. It suggested adopting hybrid recommender systems that combine collaborative and content-based filtering techniques to offer more accurate and diverse recommendations. Additionally, the study emphasized the importance of integrating contextual information into recommendation algorithms to dynamically adjust recommendations based on situational context. Furthermore, it recommended the use of explainable AI techniques to improve transparency and user understanding of recommendation processes. Maximizing user engagement through active participation and feedback was also highlighted as crucial, along with prioritizing recommendation diversity to foster exploration and serendipitous discovery of new knowledge resources.",0
"The application of Artificial Intelligence (AI) is significantly increasing in many Human Resources (HR) functions. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. This study employs a Delphi study-based methodology specifically, organising an expert panel that provides their opinions through their ratings and comments of a set of propositions. Each line is then transformed into rectangular patches for character recognition by the text recognition network, comprising a vision-based text recognition model and a language network. In this study, we have delved into the various challenges of matching employee profiles to job profiles and the current problems faced by executives, human resource personnel or supervisors such as project managers in an organisation. The study also sheds light on the potential or feasibility solutions of artificial intelligence in the form of recommender systems where we also test a couple of propositions that focus on potential solutions and various challenges for matching employee profiles to job profiles in an organisation.","The application of Artificial Intelligence (AI) is significantly increasing in many Human Resources (HR) functions. This research aims to understand how diverse experts from distinct organisations, such as Project Managers, Managers, Supervisors and Human Resource Managers, perceive the potential of artificial intelligence-based recommender systems to match job profiles with employee profiles. This study employs a Delphi study-based methodology specifically, organising an expert panel that provides their opinions through their ratings and comments of a set of propositions. Based on the online Delphi study results and participant opinions, this research aims to identify the challenges related to employee-job profile matching through artificial intelligence and machine learning tools in the form of recommender systems. In this study, we have delved into the various challenges of matching employee profiles to job profiles and the current problems faced by executives, human resource personnel or supervisors such as project managers in an organisation. The study also sheds light on the potential or feasibility solutions of artificial intelligence in the form of recommender systems where we also test a couple of propositions that focus on potential solutions and various challenges for matching employee profiles to job profiles in an organisation.",0
"The development of artificial intelligence (AI) has enabled the acoustic analysis of multi-factor sound sources. Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. Chat Generated Pre-trained
Transformer (ChatGPT), which is an AI-chatbot, represents an extremely controversial topic in the academic community. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. Five-elements music therapy—based on the five-element theory—is a unique non-pharmacological therapy of East Asian traditional medicine. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.","Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.",0
"In the last decade, AI use in Orthopaedics increased approximately tenfold. Given the challenges of inter-domain information fusion and data sparsity in collaborative filtering algorithms, this paper proposes a cross-domain information fusion matrix decomposition algorithm to enhance the accuracy of personalized recommendations in artificial intelligence recommendation systems. The study begins by collecting Douban movie rating data and social network information. To ensure data integrity, Levenshtein distance detection is employed to remove duplicate scores, while natural language processing technology is utilized to extract keywords and topic information from social texts. Additionally, graph convolutional networks are utilized to convert user relationships into feature vectors, and a unique thermal coding method is used to convert discrete user and movie information into binary matrices. The experiment used piano sound as an example to verify the accuracy and reliability of the system. The main purpose is to improve the efficiency and accuracy of music teaching through artificial intelligence technology. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. Weighted average and feature connection techniques are then applied to integrate features from different fields. Moreover, the paper combines the item-based collaborative filtering algorithm with merged user characteristics to generate personalized recommendation lists. In the experimental stage, the paper conducts cross-domain information fusion optimization on four mainstream mathematical matrix decomposition algorithms: alternating least squares method, non-negative matrix decomposition, singular value decomposition, and latent factor model (LFM). It compares these algorithms with the non-fused approach. The results indicate a significant improvement in score accuracy, with mean absolute error and root mean squared error reduced by 12.8% and 13.2% respectively across the four algorithms. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. Additionally, when k = 10, the average F1 score reaches 0.97, and the ranking accuracy coverage of the LFM algorithm increases by 54.2%. Overall, the mathematical matrix decomposition algorithm combined with cross-domain information fusion demonstrates clear advantages in accuracy, prediction performance, recommendation diversity, and ranking quality, and improves the accuracy and diversity of the recommendation system. By effectively addressing collaborative filtering challenges through the integration of diverse techniques, it significantly surpasses traditional models in recommendation accuracy and variety.","Given the challenges of inter-domain information fusion and data sparsity in collaborative filtering algorithms, this paper proposes a cross-domain information fusion matrix decomposition algorithm to enhance the accuracy of personalized recommendations in artificial intelligence recommendation systems. The study begins by collecting Douban movie rating data and social network information. To ensure data integrity, Levenshtein distance detection is employed to remove duplicate scores, while natural language processing technology is utilized to extract keywords and topic information from social texts. Additionally, graph convolutional networks are utilized to convert user relationships into feature vectors, and a unique thermal coding method is used to convert discrete user and movie information into binary matrices. To prevent overfitting, the Ridge regularization method is introduced to gradually optimize potential feature vectors. Weighted average and feature connection techniques are then applied to integrate features from different fields. Moreover, the paper combines the item-based collaborative filtering algorithm with merged user characteristics to generate personalized recommendation lists. In the experimental stage, the paper conducts cross-domain information fusion optimization on four mainstream mathematical matrix decomposition algorithms: alternating least squares method, non-negative matrix decomposition, singular value decomposition, and latent factor model (LFM). It compares these algorithms with the non-fused approach. The results indicate a significant improvement in score accuracy, with mean absolute error and root mean squared error reduced by 12.8% and 13.2% respectively across the four algorithms. Additionally, when k = 10, the average F1 score reaches 0.97, and the ranking accuracy coverage of the LFM algorithm increases by 54.2%. Overall, the mathematical matrix decomposition algorithm combined with cross-domain information fusion demonstrates clear advantages in accuracy, prediction performance, recommendation diversity, and ranking quality, and improves the accuracy and diversity of the recommendation system. By effectively addressing collaborative filtering challenges through the integration of diverse techniques, it significantly surpasses traditional models in recommendation accuracy and variety.",0
"Video games have been in the focus of the research and academic community for the last few years, with the study and experimentation of Artificial General Intelligence (AGI) standing out. However, one limitation of this music therapy is that the classification of the five elements and its application is mainly based on subjective judgment. AGI experimentation platforms allow to analyze and study, in a visual way, the behavior of different AI agents previously defined. The literature indicated cases of sports convergence with the application of fourth industrial revolution technologies, such as the game of go, golf, table tennis, soccer, American football, skiing, archery, and fencing. In this work a novel game engine, called GAGI, capable of serving as an AGI experimentation platform is presented. As a game engine, GAGI is able to design and create novel 2D and 3D video games using C++ programming language. Moreover, GAGI provides the user with a unique environment for simulating and studying AI agents inside the created game. Additionally, the article will also evaluate the role of ChatGPT in scientifc research
and publications. The features of the proposed software is compared against others widely-used game engines in the video games industry as well as in the research community, highlighting the advantages in terms of design capability and AI support. GAGI also offers the possibility to reproduce the experiments, opening up multiple possibilities for the research community.","Video games have been in the focus of the research and academic community for the last few years, with the study and experimentation of Artificial General Intelligence (AGI) standing out. AGI experimentation platforms allow to analyze and study, in a visual way, the behavior of different AI agents previously defined. In this work a novel game engine, called GAGI, capable of serving as an AGI experimentation platform is presented. As a game engine, GAGI is able to design and create novel 2D and 3D video games using C++ programming language. Moreover, GAGI provides the user with a unique environment for simulating and studying AI agents inside the created game. Users can deploy multiple AI agents while interacting with them in real time, improving the understanding of their interactions and behaviors. The features of the proposed software is compared against others widely-used game engines in the video games industry as well as in the research community, highlighting the advantages in terms of design capability and AI support. GAGI also offers the possibility to reproduce the experiments, opening up multiple possibilities for the research community.",0
"In this paper, we focus on the AI-based solutions applied in medical image scan segmentation and intelligent visual content generation, i.e., computer-generated three-dimensional (3D) images in the context of extended reality (XR). Monte Carlo Tree Search (MCTS) is a pronounced empirical search algorithm for agent decision-making, especially when enhanced by Deep Learning (DL), in mastering board games that were once thought to be unconquerable. However, it does not appear to be as equally successful in the domain of real-time video games, where the simulation time limit for exploration is a crucial factor, since they are generally designed to be played by human users and hence require a significant amount of resources for simulation. We in this paper propose a surrogate-assisted MCTS approach, specifically targeting commercial real-time video games by approximating the result of gameplay with a deep-learning-based surrogate model. With the rapid development of artificial intelligence, intelligent auxiliary systems have been widely used in various fields. The key contribution of our work is that we designed a modified MCTS for video games that are both commercial and processed in real-time. Since commercial video games include considerably more complex and dynamic gameplays to satisfy their market consumers, as opposed to their non-commercial analogs, our work can be regarded as having challenged the domain unattempted by precedent studies. We validated the performance of our method by conducting a comparative experiment with other algorithms, including the traditional MCTS, under the environment of a commercial real-time video game.","Monte Carlo Tree Search (MCTS) is a pronounced empirical search algorithm for agent decision-making, especially when enhanced by Deep Learning (DL), in mastering board games that were once thought to be unconquerable. However, it does not appear to be as equally successful in the domain of real-time video games, where the simulation time limit for exploration is a crucial factor, since they are generally designed to be played by human users and hence require a significant amount of resources for simulation. We in this paper propose a surrogate-assisted MCTS approach, specifically targeting commercial real-time video games by approximating the result of gameplay with a deep-learning-based surrogate model. The key contribution of our work is that we designed a modified MCTS for video games that are both commercial and processed in real-time. Since commercial video games include considerably more complex and dynamic gameplays to satisfy their market consumers, as opposed to their non-commercial analogs, our work can be regarded as having challenged the domain unattempted by precedent studies. We validated the performance of our method by conducting a comparative experiment with other algorithms, including the traditional MCTS, under the environment of a commercial real-time video game.",0
"Whether the application of exergames in physical education (PE) courses can significantly improve student performance in PE learning is still controversial. This review explores the promoting effect of exergames on student PE learning and the conditions in which the effect of exergames can be maximized. Based on the PICOS method, two researchers independently searched the ProQuest database, EBSCO database, Web of Science (WoS) database, PubMed database, Chinese National Knowledge Infrastructure (CNKI) database, Wanfang database, and VIP database, evaluated the literature quality using the Cochrane system evaluation manual, and performed a meta-analysis of the included literature. A total of 16 randomized controlled trials involving 2962 subjects were included in this study. Here, we discussed the challenges proposed by the future combination of five-element music therapy and AI. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. Subgroup analysis indicated that better results could be achieved when exergames were introduced in small kindergarten classes and continued for 1–2 months.","﻿Whether the application of exergames in physical education (PE) courses can significantly improve student performance in PE learning is still controversial. This review explores the promoting effect of exergames on student PE learning and the conditions in which the effect of exergames can be maximized. Based on the PICOS method, two researchers independently searched the ProQuest database, EBSCO database, Web of Science (WoS) database, PubMed database, Chinese National Knowledge Infrastructure (CNKI) database, Wanfang database, and VIP database, evaluated the literature quality using the Cochrane system evaluation manual, and performed a meta-analysis of the included literature. A total of 16 randomized controlled trials involving 2962 subjects were included in this study. The meta-analysis showed that exergames effectively improved student performance in PE learning (SMD = 0.45, 95% CI: 0.27–0.63, P < 0.00001). Subgroup analysis indicated that better results could be achieved when exergames were introduced in small kindergarten classes and continued for 1–2 months.",0
"Artificial Intelligence (AI) stands as a pivotal innovation deeply ingrained in both our daily routines and industrial operations. As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Its rapid evolution promises transformative impacts across various sectors, from cutting-edge industries to the lives of ordinary individuals. AI constantly updates human experiences, shaping interactions and augmenting capabilities. For instance, contemporary educational institutions leverage AI algorithms for attendance tracking via facial recognition technology. Looking ahead, the advent of autonomous vehicles represents a pinnacle of AI application, where vehicles rely entirely on AI systems for navigation, detecting traffic signals, and navigating roads.","Artificial Intelligence (AI) stands as a pivotal innovation deeply ingrained in both our daily routines and industrial operations. Its rapid evolution promises transformative impacts across various sectors, from cutting-edge industries to the lives of ordinary individuals. AI constantly updates human experiences, shaping interactions and augmenting capabilities. For instance, contemporary educational institutions leverage AI algorithms for attendance tracking via facial recognition technology. Looking ahead, the advent of autonomous vehicles represents a pinnacle of AI application, where vehicles rely entirely on AI systems for navigation, detecting traffic signals, and navigating roads.",0
"International relations scholarship has long emphasized that popular culture can impact public understandings and political realities. Further, we hypothesized that AI may promote its use in the medical field. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. Within paradoxical videogame representations of AI weapons both as insurmountable enemies that pose existential threats to humankind in narratives and as easy targets that human protagonists routinely overcome in gameplay, we identify distortions of human machine interaction that contradict real-world scenarios. Taekwondo is a traditional martial art that originated in Republic of Korea and gradually became a globally recognized sport. These distortions revolve around videogames affording players enhanced human agency to dominate AI weapons to offer enjoyable gameplay, contradicting the same weapons being intended to diminish human agency on real-world battlefields. By leveraging the Actor-Network Theory concept of translation, we explain how these distorted portrayals of AI weapons are produced by entanglements between heterogeneous human and non-human actors that aim to make videogames mass-marketable and profitable. In so doing, we echo game studies research that calls for greater attention to the commercial and ludic dimensions of videogames so that international relations scholarship can better account for pop cultures bounded abilities to impact public understandings and political realities.","International relations scholarship has long emphasized that popular culture can impact public understandings and political realities. In this article, we explore these potentials in the context of military-themed videogames and their portrayals of weaponized artificial intelligence (AI). Within paradoxical videogame representations of AI weapons both as insurmountable enemies that pose existential threats to humankind in narratives and as easy targets that human protagonists routinely overcome in gameplay, we identify distortions of human machine interaction that contradict real-world scenarios. These distortions revolve around videogames affording players enhanced human agency to dominate AI weapons to offer enjoyable gameplay, contradicting the same weapons being intended to diminish human agency on real-world battlefields. By leveraging the Actor-Network Theory concept of translation, we explain how these distorted portrayals of AI weapons are produced by entanglements between heterogeneous human and non-human actors that aim to make videogames mass-marketable and profitable. In so doing, we echo game studies research that calls for greater attention to the commercial and ludic dimensions of videogames so that international relations scholarship can better account for pop cultures bounded abilities to impact public understandings and political realities.",0
"Machine learning algorithms are used to analyze and identify the data to accurately assess the student’s movements. Accurately scientific disciplines, including biomechanics, genetics, ethology, and neurology, it is essential to accurately track the behavior of animals throughout studies, particularly without employing markers. However, it has proven difficult to extract precise stances from backgrounds that are always shifting. Recently, we unveiled an open-source toolset that makes use of a cutting-edge algorithm for estimating human position. With the help of this toolbox, users may train a deep neural network to accurately monitor user-defined features with tracking accuracy that rivals that of human labeling. With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. We have added new features, including as graphical user interfaces (GUIs), efficiency improvements, and network refinement based on active learning, to this revised Python module. In order to help customers create a unique and repeatable analysis pipeline using a graphical processing unit (GPU).","Accurately scientific disciplines, including biomechanics, genetics, ethology, and neurology, it is essential to accurately track the behavior of animals throughout studies, particularly without employing markers. However, it has proven difficult to extract precise stances from backgrounds that are always shifting. Recently, we unveiled an open-source toolset that makes use of a cutting-edge algorithm for estimating human position. With the help of this toolbox, users may train a deep neural network to accurately monitor user-defined features with tracking accuracy that rivals that of human labeling. We have added new features, including as graphical user interfaces (GUIs), efficiency improvements, and network refinement based on active learning, to this revised Python module. In order to help customers create a unique and repeatable analysis pipeline using a graphical processing unit (GPU).",0
"Providing an appropriate difficulty level in a game is critical for keeping players engaged. Dynamic Difficulty Adjustment (DDA) is a common approach for optimizing player experience by automatically modifying game aspects. This paper reviews literature addressing mechanisms for adjusting video game difficulties in response to players performance, emotions, or personality. For this purpose, we examined DDA studies using employed machine-learning techniques, player modeling approaches, data types used to assess players states, testbed game genre, and application. Journal and conference articles published up to September 2022 served as the data sources in this review. This review is performed based on literature sourced from Web of Science and Dimensions databases, where articles were thoroughly examined to identify AI use cases. The findings reveal that most studies have shown significant effects of DDA on parameters such as enjoyment, flow, motivation, engagement, and immersion. In addition, machine-learning and player modeling techniques have recently received more attention in the DDA design. However, given the ever-increasing use of games in various domains, more research is needed to understand player preferences better to adjust game parameters efficiently. The main challenge we face in this process is how to effectively extract the features of music sounds and accurately identify different tones through algorithms.","Providing an appropriate difficulty level in a game is critical for keeping players engaged. Dynamic Difficulty Adjustment (DDA) is a common approach for optimizing player experience by automatically modifying game aspects. This paper reviews literature addressing mechanisms for adjusting video game difficulties in response to players performance, emotions, or personality. For this purpose, we examined DDA studies using employed machine-learning techniques, player modeling approaches, data types used to assess players states, testbed game genre, and application. Journal and conference articles published up to September 2022 served as the data sources in this review. The findings reveal that most studies have shown significant effects of DDA on parameters such as enjoyment, flow, motivation, engagement, and immersion. In addition, machine-learning and player modeling techniques have recently received more attention in the DDA design. However, given the ever-increasing use of games in various domains, more research is needed to understand player preferences better to adjust game parameters efficiently. By conducting further research into players cognitive characteristics, such as visual attention, working memory, and response time, it will be possible to understand players preferences better.",0
"Additionally, the article will also evaluate the role of ChatGPT in scientifc research
and publications. However, empirical evidence of their effectiveness is sparse. Through experimental verification, the intelligent assistant system can monitor students’ movements in real time, accurately evaluate their technical level, and provide personalized guidance. This scoping review follows PRISMA-ScR guidelines to summarize literature on serious video games for agricultural learning, highlighting research trends and identifying gaps. We systematically searched nine prominent research databases for papers on serious video games for agriculture learning published between January 2000 and July 2022. Two independent reviewers conducted screening, data extraction, and synthesized the collected data using a narrative approach. The initial search identified 3,297 articles, of which 0.58% ( n = 19) were included in the review. The experiment used piano sound as an example to verify the accuracy and reliability of the system. Most reviewed games were released in the last five years, with a predominant presence in the mobile platform. They commonly employed a simulation-based approach, featuring 2-D graphics and designed for single-player experiences. These games mainly target students, focusing on crop production and sustainable agriculture. Educational theories were often unspecified in the studies. Evaluation protocols primarily consisted of pilot studies, emphasizing user experience and knowledge enhancement. Positive outcomes, such as improved user experiences, knowledge, and attitude and behavior changes, were commonly observed in these studies. This study highlights advancements in using serious video games for agricultural learning over 20 years. As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. However, it stresses the need for deeper exploration of game elements' impact on user experience and effectiveness. Creating games for underrepresented players and specific agricultural challenges is essential, as is enhancing theoretical foundations and learning approaches. Rigorous research designs are vital for assessing game effectiveness across short, medium, and long terms.","Serious video games provide a immersive learning environment for agriculture by simulating real-life challenges scenarios. However, empirical evidence of their effectiveness is sparse. This scoping review follows PRISMA-ScR guidelines to summarize literature on serious video games for agricultural learning, highlighting research trends and identifying gaps. We systematically searched nine prominent research databases for papers on serious video games for agriculture learning published between January 2000 and July 2022. Two independent reviewers conducted screening, data extraction, and synthesized the collected data using a narrative approach. The initial search identified 3,297 articles, of which 0.58% ( n = 19) were included in the review. Most reviewed games were released in the last five years, with a predominant presence in the mobile platform. They commonly employed a simulation-based approach, featuring 2-D graphics and designed for single-player experiences. These games mainly target students, focusing on crop production and sustainable agriculture. Educational theories were often unspecified in the studies. Evaluation protocols primarily consisted of pilot studies, emphasizing user experience and knowledge enhancement. Positive outcomes, such as improved user experiences, knowledge, and attitude and behavior changes, were commonly observed in these studies. This study highlights advancements in using serious video games for agricultural learning over 20 years. However, it stresses the need for deeper exploration of game elements' impact on user experience and effectiveness. Creating games for underrepresented players and specific agricultural challenges is essential, as is enhancing theoretical foundations and learning approaches. Rigorous research designs are vital for assessing game effectiveness across short, medium, and long terms.",0
"With the development of education and technology, teachers have gradually realized that games should not be just a way for students to entertain themselves. Applying games to teaching resources can achieve better teaching outcomes. The study was backed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework and furthermore utilized computational literature review as well as bibliometric analysis techniques for knowledge extraction purposes. However, related resources are constantly emerging on the internet. To achieve higher quality recommendations, a personalized recommendation model for educational video game resources based on knowledge graphs is proposed. Firstly, feature extraction is performed alternately on the user side and the item side. Then a hidden Markov model is introduced on the basis of the dual end neighbor algorithm. Considering the temporal nature of the user, the model is optimized. The optimized model takes into account the long-term and short-term preferences of users and mines their potential preferences. Through experimental analysis, the hit rate index value of the designed model reaches 0.7989. The normalized cumulative gain value of the broken line is 0.6045. More than 89% of users are satisfied with the recommendation of this model. The study was backed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework and furthermore utilized computational literature review as well as bibliometric analysis techniques for knowledge extraction purposes. The constructed model can achieve efficient and high-quality recommendation of educational video game resources, providing users with a more convenient and efficient online experience.","With the development of education and technology, teachers have gradually realized that games should not be just a way for students to entertain themselves. Applying games to teaching resources can achieve better teaching outcomes. However, related resources are constantly emerging on the internet. To achieve higher quality recommendations, a personalized recommendation model for educational video game resources based on knowledge graphs is proposed. Firstly, feature extraction is performed alternately on the user side and the item side. Then a hidden Markov model is introduced on the basis of the dual end neighbor algorithm. Considering the temporal nature of the user, the model is optimized. The optimized model takes into account the long-term and short-term preferences of users and mines their potential preferences. Through experimental analysis, the hit rate index value of the designed model reaches 0.7989. The normalized cumulative gain value of the broken line is 0.6045. More than 89% of users are satisfied with the recommendation of this model. The running time is 0.2863s. The constructed model can achieve efficient and high-quality recommendation of educational video game resources, providing users with a more convenient and efficient online experience.",0
"The system uses artificial muscle integrated optical equipment, and collects the movement data of students in volleyball training in real time through optical sensors. The metaverse has emerged as an exciting new paradigm for human-computer interaction (HCI) and virtual collaboration. This paper presents a comprehensive review of the metaverse to address the gap in the existing literature where there is a lack of a survey that reviews the nature of the metaverse and its building blocks from a human-centric perspective. We first synthesize a definition of the metaverse from existing literature and delineate key affordances. We then introduce a detailed framework encompassing the metaverses nature, infrastructure technologies, and input/output technologies that facilitate multi-sensory HCI, alongside applications across diverse domains. The components within this framework are explained in depth, offering insights into the metaverses nature and the readiness level of current technologies. The experiment used piano sound as an example to verify the accuracy and reliability of the system. Subsequently, the detected text region undergoes line-by-line division through a text segmentation network.","The metaverse has emerged as an exciting new paradigm for human-computer interaction (HCI) and virtual collaboration. This paper presents a comprehensive review of the metaverse to address the gap in the existing literature where there is a lack of a survey that reviews the nature of the metaverse and its building blocks from a human-centric perspective. We first synthesize a definition of the metaverse from existing literature and delineate key affordances. We then introduce a detailed framework encompassing the metaverses nature, infrastructure technologies, and input/output technologies that facilitate multi-sensory HCI, alongside applications across diverse domains. The components within this framework are explained in depth, offering insights into the metaverses nature and the readiness level of current technologies. Based on this comprehensive analysis, we outline major open challenges and propose promising directions demanding further exploration and investigation. By clarifying the vision for the metaverse and characterizing the building blocks required to realize it, this review provides essential insights and serves as an invaluable resource for metaverse developers and researchers working to advance this transformative new medium.",0
"The lifestyle of modern society has changed significantly with the emergence of artificial intelligence (AI), machine learning (ML), and deep learning (DL) technologies in recent years. As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. Artificial intelligence is a multidimensional technology with various components such as advanced algorithms, ML and DL. Together, AI, ML, and DL are expected to provide automated devices to ophthalmologists for early diagnosis and timely treatment of ocular disorders in the near future. The literature indicated cases of sports convergence with the application of fourth industrial revolution technologies, such as the game of go, golf, table tennis, soccer, American football, skiing, archery, and fencing. In fact, AI, ML, and DL have been used in ophthalmic setting to validate the diagnosis of diseases, read images, perform corneal topographic mapping and intraocular lens calculations. Diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma are the 3 most common causes of irreversible blindness on a global scale. Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution. Ophthalmic imaging provides a way to diagnose and objectively detect the progression of a number of pathologies including DR, AMD, glaucoma, and other ophthalmic disorders. There are 2 methods of imaging used as diagnostic methods in ophthalmic practice: fundus digital photography and optical coherence tomography (OCT). Of note, OCT has become the most widely used imaging modality in ophthalmology settings in the developed world. Our study offers contributions to theory and practice in the sports science and applied AI domains. Changes in population demographics and lifestyle, extension of average lifespan, and the changing pattern of chronic diseases such as obesity, diabetes, DR, AMD, and glaucoma create a rising demand for such images. Furthermore, the limitation of availability of retina specialists and trained human graders is a major problem in many countries. Consequently, given the current population growth trends, it is inevitable that analyzing such images is time-consuming, costly, and prone to human error. Therefore, the detection and treatment of DR, AMD, glaucoma, and other ophthalmic disorders through unmanned automated applications system in the near future will be inevitable. We provide an overview of the potential impact of the current AI, ML, and DL methods and their applications on the early detection and treatment of DR, AMD, glaucoma, and other ophthalmic diseases.","The lifestyle of modern society has changed significantly with the emergence of artificial intelligence (AI), machine learning (ML), and deep learning (DL) technologies in recent years. Artificial intelligence is a multidimensional technology with various components such as advanced algorithms, ML and DL. Together, AI, ML, and DL are expected to provide automated devices to ophthalmologists for early diagnosis and timely treatment of ocular disorders in the near future. In fact, AI, ML, and DL have been used in ophthalmic setting to validate the diagnosis of diseases, read images, perform corneal topographic mapping and intraocular lens calculations. Diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma are the 3 most common causes of irreversible blindness on a global scale. Ophthalmic imaging provides a way to diagnose and objectively detect the progression of a number of pathologies including DR, AMD, glaucoma, and other ophthalmic disorders. There are 2 methods of imaging used as diagnostic methods in ophthalmic practice: fundus digital photography and optical coherence tomography (OCT). Of note, OCT has become the most widely used imaging modality in ophthalmology settings in the developed world. Changes in population demographics and lifestyle, extension of average lifespan, and the changing pattern of chronic diseases such as obesity, diabetes, DR, AMD, and glaucoma create a rising demand for such images. Furthermore, the limitation of availability of retina specialists and trained human graders is a major problem in many countries. Consequently, given the current population growth trends, it is inevitable that analyzing such images is time-consuming, costly, and prone to human error. Therefore, the detection and treatment of DR, AMD, glaucoma, and other ophthalmic disorders through unmanned automated applications system in the near future will be inevitable. We provide an overview of the potential impact of the current AI, ML, and DL methods and their applications on the early detection and treatment of DR, AMD, glaucoma, and other ophthalmic diseases.",0
"By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. With the unprecedented advancement of data aggregation and deep learning algorithms, artificial intelligence (AI) and machine learning (ML) are poised to transform the practice of medicine. Each line is then transformed into rectangular patches for character recognition by the text recognition network, comprising a vision-based text recognition model and a language network. The purpose of this review is to critically evaluate the recent and novel literature regarding ML in the field of orthopedics and to address its potential impact on the future of musculoskeletal care.","With the unprecedented advancement of data aggregation and deep learning algorithms, artificial intelligence (AI) and machine learning (ML) are poised to transform the practice of medicine. The field of orthopedics, in particular, is uniquely suited to harness the power of big data, and in doing so provide critical insight into elevating the many facets of care provided by orthopedic surgeons. The purpose of this review is to critically evaluate the recent and novel literature regarding ML in the field of orthopedics and to address its potential impact on the future of musculoskeletal care.",0
"This study explores the comprehensive understanding of taekwondo, the application of fourth industrial revolution technologies in various kinds of sports, the development of taekwondo through artificial intelligence (AI), and essential technology in the fourth industrial revolution while suggesting advanced science directions through a literature review. Industry 4.0 concepts and technologies ensure the ongoing development of micro- and macro-economic entities by focusing on the principles of interconnectivity, digitalization, and automation. In this context, artificial intelligence is seen as one of the major enablers for Smart Logistics and Smart Production initiatives. The main challenge we face in this process is how to effectively extract the features of music sounds and accurately identify different tones through algorithms. This paper systematically analyzes the scientific literature on artificial intelligence, machine learning, and deep learning in the context of Smart Logistics management in industrial enterprises. Furthermore, based on the results of the systematic literature review, the authors present a conceptual framework, which provides fruitful implications based on recent research findings and insights to be used for directing and starting future research initiatives in the field of artificial intelligence (AI), machine learning (ML), and deep learning (DL) in Smart Logistics.","Industry 4.0 concepts and technologies ensure the ongoing development of micro- and macro-economic entities by focusing on the principles of interconnectivity, digitalization, and automation. In this context, artificial intelligence is seen as one of the major enablers for Smart Logistics and Smart Production initiatives. This paper systematically analyzes the scientific literature on artificial intelligence, machine learning, and deep learning in the context of Smart Logistics management in industrial enterprises. Furthermore, based on the results of the systematic literature review, the authors present a conceptual framework, which provides fruitful implications based on recent research findings and insights to be used for directing and starting future research initiatives in the field of artificial intelligence (AI), machine learning (ML), and deep learning (DL) in Smart Logistics.",0
"Machine learning (ML) is a form of artificial intelligence which is placed to transform the twenty-first century. As a sport, volleyball has high technical requirements, and the traditional volleyball teaching method has certain limitations. Rapid, recent progress in its underlying architecture and algorithms and growth in the size of datasets have led to increasing computer competence across a range of fields. These include driving a vehicle, language translation, chatbots and beyond human performance at complex board games such as Go. With the aid of AI, the combination of intelligent technology and on-site teaching solves the lack of individuation in the traditional mode and enhances students’ interest in learning. Here, we review the fundamentals and algorithms behind machine learning and highlight specific approaches to learning and optimisation. We then summarise the applications of ML to medicine. In particular, we showcase recent diagnostic performances, and caveats, in the fields of dermatology, radiology, pathology and general microscopy.","Machine learning (ML) is a form of artificial intelligence which is placed to transform the twenty-first century. Rapid, recent progress in its underlying architecture and algorithms and growth in the size of datasets have led to increasing computer competence across a range of fields. These include driving a vehicle, language translation, chatbots and beyond human performance at complex board games such as Go. Here, we review the fundamentals and algorithms behind machine learning and highlight specific approaches to learning and optimisation. We then summarise the applications of ML to medicine. In particular, we showcase recent diagnostic performances, and caveats, in the fields of dermatology, radiology, pathology and general microscopy.",0
"Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) have revolutionized the field of advanced robotics in recent years. AI, ML, and DL are transforming the field of advanced robotics, making robots more intelligent, efficient, and adaptable to complex tasks and environments. Our proposed music sound learning model is based on a BP neural network, which trains the network to learn the mapping relationship between music sound and pitch. The main purpose is to improve the efficiency and accuracy of music teaching through artificial intelligence technology. These technologies are also being used in the development of collaborative robots (cobots) that can work alongside humans and adapt to changing environments and tasks. The AI, ML, and DL can be used in advanced transportation systems in order to provide safety, efficiency, and convenience to the passengers and transportation companies . Also, the AI, ML, and DL are playing a critical role in the advancement of manufacturing assembly robots, enabling them to work more efficiently, safely, and intelligently. Furthermore, they have a wide range of applications in aviation management, helping airlines to improve efficiency, reduce costs, and improve customer satisfaction. Moreover, the AI, ML, and DL can help taxi companies in order to provide better, more efficient, and safer services to customers. The research presents an overview of current developments in AI, ML, and DL in advanced robotics systems and discusses various applications of the systems in robot modification. Additionally, the article will also evaluate the role of ChatGPT in scientifc research
and publications. By reviewing the applications of AI, ML, and DL in advanced robotics systems, it is possible to investigate and modify the performances of advanced robots in various applications in order to enhance productivity in advanced robotic industries.","Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) have revolutionized the field of advanced robotics in recent years. AI, ML, and DL are transforming the field of advanced robotics, making robots more intelligent, efficient, and adaptable to complex tasks and environments. Some of the applications of AI, ML, and DL in advanced robotics include autonomous navigation, object recognition and manipulation, natural language processing, and predictive maintenance. These technologies are also being used in the development of collaborative robots (cobots) that can work alongside humans and adapt to changing environments and tasks. The AI, ML, and DL can be used in advanced transportation systems in order to provide safety, efficiency, and convenience to the passengers and transportation companies . Also, the AI, ML, and DL are playing a critical role in the advancement of manufacturing assembly robots, enabling them to work more efficiently, safely, and intelligently. Furthermore, they have a wide range of applications in aviation management, helping airlines to improve efficiency, reduce costs, and improve customer satisfaction. Moreover, the AI, ML, and DL can help taxi companies in order to provide better, more efficient, and safer services to customers. The research presents an overview of current developments in AI, ML, and DL in advanced robotics systems and discusses various applications of the systems in robot modification. Further research works regarding the applications of AI, ML, and DL in advanced robotics systems are also suggested in order to fill the gaps between the existing studies and published papers. By reviewing the applications of AI, ML, and DL in advanced robotics systems, it is possible to investigate and modify the performances of advanced robots in various applications in order to enhance productivity in advanced robotic industries.",0
"Artifcial intelligence (AI) is looked upon nowadays as the potential major catalyst for the fourth industrial revolution. Commercial applications of artificial intelligence and machine learning have made remarkable progress recently, particularly in areas such as image recognition, natural speech processing, language translation, textual analysis, and self-learning. Progress had historically languished in these areas, such that these skills had come to seem ineffably bound to intelligence. However, these commercial advances have performed best at single-task applications in which imperfect outputs and occasional frank errors can be tolerated. The practice of anesthesiology is different. It embodies a requirement for high reliability, and a pressured cycle of interpretation, physical action, and response rather than any single cognitive act. The system is equipped with an interactive interface that shows students correct demonstrations of movements and provides real-time feedback and guidance. This review covers the basics of what is meant by artificial intelligence and machine learning for the practicing anesthesiologist, describing how decision-making behaviors can emerge from simple equations. Relevant clinical questions are introduced to illustrate how machine learning might help solve them—perhaps bringing anesthesiology into an era of machine-assisted discovery.","Commercial applications of artificial intelligence and machine learning have made remarkable progress recently, particularly in areas such as image recognition, natural speech processing, language translation, textual analysis, and self-learning. Progress had historically languished in these areas, such that these skills had come to seem ineffably bound to intelligence. However, these commercial advances have performed best at single-task applications in which imperfect outputs and occasional frank errors can be tolerated. The practice of anesthesiology is different. It embodies a requirement for high reliability, and a pressured cycle of interpretation, physical action, and response rather than any single cognitive act. This review covers the basics of what is meant by artificial intelligence and machine learning for the practicing anesthesiologist, describing how decision-making behaviors can emerge from simple equations. Relevant clinical questions are introduced to illustrate how machine learning might help solve them—perhaps bringing anesthesiology into an era of machine-assisted discovery.",0
"Adaptation and innovation are extremely important to the manufacturing industry. This development should lead to sustainable manufacturing using new technologies. With the development, deployment, and experience of AI models by both viewers and players, it is crucial to provide a comprehensive summary of AI applications in basketball. To promote sustainability, smart production requires global perspectives of smart production application technology. In this regard, thanks to intensive research efforts in the field of artificial intelligence (AI), a number of AI-based techniques, such as machine learning, have already been established in the industry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze, systematically, the scientific literature relating to the application of artificial intelligence and machine learning (ML) in industry. In fact, with the introduction of the Industry 4.0, artificial intelligence and machine learning are considered the driving force of smart factory revolution. The purpose of this review was to classify the literature, including publication year, authors, scientific sector, country, institution, and keywords. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. The sports industry is progressively embracing technological advancements, and artificial intelligence stands out as a prominent innovation. Our study offers contributions to theory and practice in the sports science and applied AI domains. Furthermore, UCINET and NVivo 12 software were used to complete them. A literature review on ML and AI empirical studies published in the last century was carried out to highlight the evolution of the topic before and after Industry 4.0 introduction, from 1999 to now. The designed autonomous system enhances iron plate registration efficiency and significantly reduces factory time and labor costs. As one of the products of the rapid development of information technology, Artificial Intelligence (AI) involves many interdisciplinary subjects, adding new elements to music education. A first interesting result is the greater number of works published by the USA and the increasing interest after the birth of Industry 4.0.","Adaptation and innovation are extremely important to the manufacturing industry. This development should lead to sustainable manufacturing using new technologies. To promote sustainability, smart production requires global perspectives of smart production application technology. In this regard, thanks to intensive research efforts in the field of artificial intelligence (AI), a number of AI-based techniques, such as machine learning, have already been established in the industry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze, systematically, the scientific literature relating to the application of artificial intelligence and machine learning (ML) in industry. In fact, with the introduction of the Industry 4.0, artificial intelligence and machine learning are considered the driving force of smart factory revolution. The purpose of this review was to classify the literature, including publication year, authors, scientific sector, country, institution, and keywords. The analysis was done using the Web of Science and SCOPUS database. Furthermore, UCINET and NVivo 12 software were used to complete them. A literature review on ML and AI empirical studies published in the last century was carried out to highlight the evolution of the topic before and after Industry 4.0 introduction, from 1999 to now. Eighty-two articles were reviewed and classified. A first interesting result is the greater number of works published by the USA and the increasing interest after the birth of Industry 4.0.",0
"With the continuous developments of information technology, advanced computer technology and information technology have been promoted and used in the field of music. Autoimmune diseases are chronic, multifactorial conditions. Literature was sourced from six internet search electronic databases, consisting of three English databases and three Korean databases, from January 2016 to August 2023. This paper presents the development of a comprehensive, on-site industrial Optical Character Recognition (OCR) system tailored for reading text on iron plates. Here, we surveyed the use of ML methods to address clinical problems in autoimmune disease. A systematic review was conducted using MEDLINE, embase and computers and applied sciences complete databases. Relevant papers included “machine learning” or “artificial intelligence” and the autoimmune diseases search term(s) in their title, abstract or key words. Exclusion criteria: studies not written in English, no real human patient data included, publication prior to 2001, studies that were not peer reviewed, non-autoimmune disease comorbidity research and review papers. By analyzing the advantages of AI in music education, this paper systematically summarizes the application of AI in music education and discusses the development prospects of AI in music education. The study was backed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework and furthermore utilized computational literature review as well as bibliometric analysis techniques for knowledge extraction purposes. Support vector machines and random forests were the most popular ML methods used. ML models using data on multiple sclerosis, rheumatoid arthritis and inflammatory bowel disease were most common. A small proportion of studies (7.7% or 13/169) combined different data types in the modelling process. Cross-validation, combined with a separate testing set for more robust model evaluation occurred in 8.3% of papers (14/169). The field may benefit from adopting a best practice of validation, cross-validation and independent testing of ML models. Many models achieved good predictive results in simple scenarios (e.g. classification of cases and controls). Progression to more complex predictive models may be achievable in future through integration of multiple data types.","Autoimmune diseases are chronic, multifactorial conditions. Through machine learning (ML), a branch of the wider field of artificial intelligence, it is possible to extract patterns within patient data, and exploit these patterns to predict patient outcomes for improved clinical management. Here, we surveyed the use of ML methods to address clinical problems in autoimmune disease. A systematic review was conducted using MEDLINE, embase and computers and applied sciences complete databases. Relevant papers included “machine learning” or “artificial intelligence” and the autoimmune diseases search term(s) in their title, abstract or key words. Exclusion criteria: studies not written in English, no real human patient data included, publication prior to 2001, studies that were not peer reviewed, non-autoimmune disease comorbidity research and review papers. 169 (of 702) studies met the criteria for inclusion. Support vector machines and random forests were the most popular ML methods used. ML models using data on multiple sclerosis, rheumatoid arthritis and inflammatory bowel disease were most common. A small proportion of studies (7.7% or 13/169) combined different data types in the modelling process. Cross-validation, combined with a separate testing set for more robust model evaluation occurred in 8.3% of papers (14/169). The field may benefit from adopting a best practice of validation, cross-validation and independent testing of ML models. Many models achieved good predictive results in simple scenarios (e.g. classification of cases and controls). Progression to more complex predictive models may be achievable in future through integration of multiple data types.",0
"Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. Through experimental verification, the intelligent assistant system can monitor students’ movements in real time, accurately evaluate their technical level, and provide personalized guidance. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind.","Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind.",0
"The sports industry is progressively embracing technological advancements, and artificial intelligence stands out as a prominent innovation. The literature indicated cases of sports convergence with the application of fourth industrial revolution technologies, such as the game of go, golf, table tennis, soccer, American football, skiing, archery, and fencing. Artificial intelligence (AI) has recently become a very popular buzzword, as a consequence of disruptive technical advances and impressive experimental results, notably in the field of image analysis and processing. In medicine, specialties where images are central, like radiology, pathology or oncology, have seized the opportunity and considerable efforts in research and development have been deployed to transfer the potential of AI to clinical applications. With AI becoming a more mainstream tool for typical medical imaging analysis tasks, such as diagnosis, segmentation, or classification, the key for a safe and efficient use of clinical AI applications relies, in part, on informed practitioners. Initially, the system utilizes a text region detection network to identify the text area, enabling camera adjustments along the x and y axes and zoom enhancements for clearer text imagery. The aim of this review is to present the basic technological pillars of AI, together with the state-of-the-art machine learning methods and their application to medical imaging. In addition, we discuss the new trends and future research directions. This will help the reader to understand how AI methods are now becoming an ubiquitous tool in any medical image analysis workflow and pave the way for the clinical implementation of AI-based solutions.","Artificial intelligence (AI) has recently become a very popular buzzword, as a consequence of disruptive technical advances and impressive experimental results, notably in the field of image analysis and processing. In medicine, specialties where images are central, like radiology, pathology or oncology, have seized the opportunity and considerable efforts in research and development have been deployed to transfer the potential of AI to clinical applications. With AI becoming a more mainstream tool for typical medical imaging analysis tasks, such as diagnosis, segmentation, or classification, the key for a safe and efficient use of clinical AI applications relies, in part, on informed practitioners. The aim of this review is to present the basic technological pillars of AI, together with the state-of-the-art machine learning methods and their application to medical imaging. In addition, we discuss the new trends and future research directions. This will help the reader to understand how AI methods are now becoming an ubiquitous tool in any medical image analysis workflow and pave the way for the clinical implementation of AI-based solutions.",0
"This study conducted a content analysis of research studies that have examined the application of artificial intelligence (AI) in the education sector. The study also aimed to identify possible research trends and difficulties related to the use of AI in education. A total of 100 papers, comprising 63 empirical papers (consisting of 74 studies) and 37 analytic papers, were chosen from the education and educational research category of the Social Sciences Citation Index database for the period of 2010 to 2020. The content analysis revealed that the research questions could be categorized into three layers: the development layer, which includes classification, matching, recommendation, and deep learning; the application layer, which encompasses feedback, reasoning, and adaptive learning; and the integration layer, which involves affection computing, role-playing, immersive learning, and gamification. Furthermore, it was recommended to conduct further research on four emerging areas of study: Internet of Things, swarm intelligence, deep learning, and neuroscience. Additionally, an evaluation of the application of artificial intelligence in education was proposed. However, we have also suggested that the obstacles in education may arise from the improper application of AI techniques, the shifting roles of instructors and students, and the presence of social and ethical concerns. The results offer valuable insights into the application of artificial intelligence (AI) in the field of education. This research strengthens the theoretical basis of AI in education and presents a promising opportunity for educators and AI engineers to engage in additional collaborative research.","This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research.",1
"The development and proliferation of artificial intelligence (AI) is occurring rapidly, and AI has become integrated into our everyday lives. Indeed, artificial intelligence has revolutionized the methods by which individuals acquire knowledge. Nevertheless, the implementation of AI in the educational field has encountered difficulties and ethical concerns. This study aims to examine the potential, advantages, and obstacles of artificial intelligence in the field of education. A systematic review technique was employed to examine the existing and pertinent literature in order to identify the current research emphasis and gain a comprehensive comprehension of AI technology in education for educators. Additionally, this review aims to suggest future research areas. The findings indicate that the use of AI in education has progressed significantly in industrialized countries, particularly during the Industry 4.0 period. The report addresses further difficulties and provides recommendations.","Artificial intelligence (AI) is developing and its application is spreading at an alarming rate, and AI has become part of our daily lives. As a matter of fact, AI has changed the way people learn. However, its adoption in the educational sector has been saddled with challenges and ethical issues. The purpose of this study is to analyze the opportunities, benefits, and challenges of AI in education. A review of available and relevant literature was done using the systematic review method to identify the current research focus and provide an in-depth understanding of AI technology in education for educators and future research directions. Findings showed that AI's adoption in education has advanced in the developed countries and most research became popular within the Industry 4.0 era. Other challenges, as well as recommendations, are discussed in the study.",1
"As of 2021, around 30 countries have published their national strategy for artificial intelligence (AI). These documents outline strategies and predictions addressing the influence of AI on policy sectors, such as education, and usually address the societal and moral consequences of AI. This article conducts a thematic analysis of 24 country AI policy strategies, examining the significance of education in the global AI policy discussion. The study reveals that discussions on policy mostly overlook the integration of AI in education (AIED), despite the significant importance placed on education's role in preparing a workforce for AI and cultivating more AI professionals. In addition, the ethical ramifications of AIED are given little consideration, despite the prevalence of AI ethics discourse in these texts. This indicates that AIED and its wider policy and ethical consequences have not been widely recognized by the general public and influential decision-makers. This is concerning because effective policy-making and thoughtful ethical deliberation are closely interconnected, as argued in this article. Based on these discoveries, the article utilizes a set of five AI ethics principles to explore how policymakers might more effectively integrate the consequences of AIED. Ultimately, the paper provides suggestions to AIED scholars on how to effectively interact with the policymaking process and conduct ethics and policy-oriented AIED research. The goal is to influence policy discussions in order to benefit the public.","As of 2021, more than 30 countries have released national artificial intelligence (AI) policy strategies. These documents articulate plans and expectations regarding how AI will impact policy sectors, including education, and typically discuss the social and ethical implications of AI. This article engages in thematic analysis of 24 such national AI policy strategies, reviewing the role of education in global AI policy discourse. It finds that the use of AI in education (AIED) is largely absent from policy conversations, while the instrumental value of education in supporting an AI-ready workforce and training more AI experts is overwhelmingly prioritized. Further, the ethical implications of AIED receive scant attention despite the prominence of AI ethics discussion generally in these documents. This suggests that AIED and its broader policy and ethical implications—good or bad—have failed to reach mainstream awareness and the agendas of key decision-makers, a concern given that effective policy and careful consideration of ethics are inextricably linked, as this article argues. In light of these findings, the article applies a framework of five AI ethics principles to consider ways in which policymakers can better incorporate AIED’s implications. Finally, the article offers recommendations for AIED scholars on strategies for engagement with the policymaking process, and for performing ethics and policy-oriented AIED research to that end, in order to shape policy deliberations on behalf of the public good.",1
"Approach: This review study employed a narrative synthesis and a systematic literature review. The literature and information were sourced from a range of publications and research articles accessed through academic databases such as EBSCO, Google Scholar, Scopus, Web of Science, and ScienceDirect. The inclusion criteria encompassed research that provided a clear definition of artificial intelligence in the education sector, were published and written in English, and underwent peer review. Five autonomous reviewers evaluated the search results, retrieved data, and determined the quality of the research in order to summarize and publish the findings. Conclusion: Artificial intelligence has already made its way into the education industry. Integrating artificial intelligence is a crucial and essential element in the advancement of education. Moreover, artificial intelligence is progressively employed as a digital assistant. They provide support to teachers and students in multiple ways, such as granting pupils access to a diverse array of educational resources tailored to their individual learning requirements and academic disciplines. Nevertheless, artificial intelligence breakthroughs carry certain hazards, including those related to safety, security, and privacy. Artificial intelligence technologies have both beneficial and bad impacts on the education sector. Therefore, it is imperative to give top priority to integrating artificial intelligence into education and devising suitable strategies to fulfill the demands and expectations of teachers and students through the use of AI technology. Consequently, academic performance will be outstanding. Recommendation & Implication: In the future, qualitative research methods like interviews or quantitative analytic methods like online questionnaires could be utilized to offer more comprehensive explanations and clear-cut conclusions. The consequences of this research can be utilized by school administrators, teachers, and students to have a deeper understanding and effectively apply suitable ways for enhancing educational performance using artificial intelligence.","Method: A narrative synthesis and a systematic literature review were conducted in this review article. The literature and information were obtained from various books and research articles on EBSCO, Google Scholar, Scopus, Web of Science, and ScienceDirect. The inclusion criteria were studies that clearly defined artificial intelligence in the education sector, were published and written in English and were peer-reviewed. Five independent reviewers assessed search results, extracted data, and set the studies’ quality to summarise and report the findings.

Result: Artificial intelligence has already entered the education sector. Implementing artificial intelligence is a strategic and critical factor in educational development. Furthermore, artificial intelligence is increasingly being used as a digital assistant. They assist teachers and students in various ways, including giving students access to a wide range of learning materials based on their specific learning needs and subjects. However, some risks are associated with artificial intelligence advancements, such as safety, security, and privacy concerns. As a result, artificial intelligence technologies positively and negatively affect the education sector.

Conclusion: Artificial intelligence technologies have positive and negative effects on education. Thus, it is critical to prioritise artificial intelligence in education and implement appropriate strategies to meet teachers' and students' needs and expectations through AI technologies. As a result, academic performance will be excellent.

Recommendation & Implication: Qualitative research, such as interviews, or quantitative analysis, such as online questionnaires, may be developed in the future to provide more explanations and explicit findings. The implications could be applied to school administrators, teachers, and students to understand better and implement appropriate strategies to improve educational performance through AI.",1
"Artificial Intelligence (AI) is significantly transforming the world, with both positive and negative consequences. The incorporation of AI into different facets of human existence is currently in progress, and the intricate moral issues arising from the creation, implementation, and utilization of this technology serve as a prompt to reevaluate the educational curriculum for future AI developers, designers, and professionals. Training future members of the AI community, as well as other stakeholders, to consider the possible influence of AI on people's lives and to accept responsibility for maximizing its advantages while minimizing its potential downsides is extremely important. One way to achieve this is by including AI ethics more comprehensively and methodically into the curriculum. This study provides a concise overview of several approaches to AI ethics and presents a series of recommendations for the teaching of AI ethics.","Artificial Intelligence (AI) is reshaping the world in profound ways; some of its impacts are certainly beneficial but widespread and lasting harms can result from the technology as well. The integration of AI into various aspects of human life is underway, and the complex ethical concerns emerging from the design, deployment, and use of the technology serves as a reminder that it is time to revisit what future developers and designers, along with professionals, are learning when it comes to AI. It is of paramount importance to train future members of the AI community, and other stakeholders as well, to reflect on the ways in which AI might impact people’s lives and to embrace their responsibilities to enhance its benefits while mitigating its potential harms. This could occur in part through the fuller and more systematic inclusion of AI ethics into the curriculum. In this paper, we briefly describe different approaches to AI ethics and offer a set of recommendations related to AI ethics pedagogy.",1
"In his keynote session at ICCE 2019, Stephen Yang discussed the emerging challenge of precision education in the context of utilizing artificial intelligence (AI), machine learning, and learning analytics to enhance teaching quality and learning performance. The objective of precision education is to promptly identify students who are at risk and offer appropriate assistance based on their teaching and learning experiences (Lu et al., 2018). Based on the central concept of precision education, this special issue promotes a thorough discussion between impersonal technology and compassionate humanity, resulting in a deeper comprehension of precision education. Thirteen research papers focusing on precision education, AI, machine learning, and learning analytics were exchanged for this special issue. These papers aimed to provide a comprehensive understanding of how AI can be applied in education, covering various applications, methods, pedagogical models, and environments.","As addressed by Stephen Yang in his ICCE 2019 keynote speech (Yang, 2019), precision
education is a new challenge when applying artificial intelligence (AI), machine learning, and learning analytics
to improve teaching quality and learning performance. The goal of precision education is to identify at-risk
students as early as possible and provide timely intervention on the basis of teaching and learning experiences
(Lu et al., 2018). Drawing from this main theme of precision education, this special issue advocates an in-depth
dialogue between cold technology and warm humanity, in turn offering greater understanding of precision
education. For this special issue, thirteen research papers that specialize in precision education, AI, machine
learning, and learning analytics to engage in an in-depth research experiences concerning various applications,
methods, pedagogical models, and environments were exchanged to achieve better understanding of the
application of AI in education",1
"The utilization of Artificial Intelligence (AI) technology in education has led to a rise in the quantity of published studies in this domain. Nevertheless, there have been no extensive evaluations carried out to thoroughly examine all the different facets of this domain. Using topic-based bibliometrics, we analyze 4,519 publications from 2000 to 2019 to uncover trends and subjects related to the application of artificial intelligence (AI) in education (AIEd). The review findings indicate a growing inclination within the academic community towards utilizing AI for educational objectives. The primary areas of research encompass intelligent tutoring systems designed for special education, natural language processing applied to language education, educational robots utilized for AI education, educational data mining focused on performance prediction, discourse analysis in computer-supported collaborative learning, neural networks employed for teaching evaluation, affective computing employed for learner emotion detection, and recommender systems used for personalized learning. In addition, we explore the difficulties and potential future paths of Artificial Intelligence in Education (AIEd).","With the increasing use of Artificial Intelligence (AI) technologies in education, the number of published studies in the field has increased. However, no large-scale reviews have been conducted to comprehensively investigate the various aspects of this field. Based on 4,519 publications from 2000 to 2019, we attempt to fill this gap and identify trends and topics related to AI applications in education (AIEd) using topicbased bibliometrics. Results of the review reveal an increasing interest in using AI for educational purposes from the academic community. The main research topics include intelligent tutoring systems for special education; natural language processing for language education; educational robots for AI education; educational data mining for performance prediction; discourse analysis in computer-supported collaborative learning; neural networks for teaching evaluation; affective computing for learner emotion detection; and recommender systems for personalized learning. We also discuss the challenges and future directions of AIEd.",1
"This article highlights five major areas of disagreement that deserve careful consideration in future discussions and decision-making, given the rapid growth of interest and debate surrounding AI in education. The following actions should be taken: (1) Concentrate on discussing AI technologies that currently exist, rather than exaggerating the potential of speculative AI technologies; (2) Clearly emphasize the limitations of AI in terms of modeling social contexts and simulating human intelligence, reasoning, autonomy, and emotions; (3) Highlight the negative social consequences of using AI; (4) Recognize that claims about AI are influenced by personal values; and (5) Give more consideration to the environmental and ecological sustainability of ongoing AI development and implementation. Therefore, contrary to common beliefs that AI is an impartial instrument, it is argued that the utilization of AI in education should be seen as a political act that affects different groups of individuals in different educational settings.","In light of fast-growing popular, political and professional discourses around AI in education, this article outlines five broad areas of contention that merit closer attention in future discussion and decision-making. These include: (1) taking care to focus on issues relating to 'actually existing' AI rather than the overselling of speculative AI technologies; (2) clearly foregrounding the limitations of AI in terms of modelling social contexts, and simulating human intelligence, reckoning, autonomy and emotions; (3) foregrounding the social harms associated with AI use; (4) acknowledging the value-driven nature of claims around AI; and (5) paying closer attention to the environmental and ecological sustainability of continued AI development and implementation. Thus, in contrast to popular notions of AI as a neutral tool, the argument is made for engaging with the ongoing use of AI in education as a political action that has varying impacts on different groups of people in various educational contexts.",1
"The field of engineering education is continuously adapting to stay abreast of the most recent technical advancements and fulfill the expanding demands of the engineering sector. An encouraging advancement in this domain is the utilization of generative artificial intelligence technologies, shown by the ChatGPT conversational bot. ChatGPT has the capacity to provide tailored and efficient learning experiences by offering students individualized feedback and explanations, along with generating lifelike virtual simulations for practical learning. Nevertheless, it is crucial to take into account the constraints of this technology. Generative AI systems like ChatGPT are reliant on the quality of their training data and have the potential to perpetuate biases or even produce and disseminate falsehoods. In addition, the utilization of generative AI in education gives rise to ethical apprehensions, including the possibility of students engaging in unethical or deceitful practices, as well as the potential displacement of human workers due to technological redundancy. Although the current status of generative AI technology, exemplified by ChatGPT, is remarkable, it is not without its limitations. However, it serves as a mere glimpse into the future potential of this field. Engineering educators must comprehend the ramifications of this technology and investigate how to modify the engineering education system to enable future engineers to utilize the advantages of generative AI while mitigating any adverse effects.","Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.",1
"Artificial intelligence (AI) is swiftly revolutionizing diverse sectors, including education. Artificial intelligence (AI) is employed in school management to optimize the learning process, enhance student results, and streamline administrative operations. The objective of this research is to investigate the utilization of artificial intelligence in the field of educational management, encompassing its advantages and difficulties. The study effort utilizes a systematic review methodology to analyze the literature on artificial intelligence in educational management. The study reveals that AI offers numerous benefits, such as enhancing student engagement, customizing learning experiences, and achieving cost-effectiveness. Nevertheless, artificial intelligence (AI) presents other obstacles, including ethical dilemmas, possible prejudices, and the necessity to retrain the workforce. The research findings indicate that AI possesses a substantial potential to enhance educational management. However, it is imperative to exercise prudence and caution when implementing it.","Artificial intelligence (AI) is rapidly transforming various industries, including education. AI is being used in educational management
to enhance the learning process, improve student outcomes, and streamline administrative tasks. This research work aims to explore the
application of AI in educational management, including its benefits and challenges. The research work employs a systematic review
methodology, examining the literature on AI in educational management. The study finds that AI has several advantages, including
improving student engagement, personalization of learning, and cost-effectiveness. However, AI also poses several challenges, such as
ethical concerns, potential biases, and the need for re-skilling the workforce. The research concludes that AI has an enormous capacity
to improve educational management, but it must be deployed with care and caution.",1
"The utilization of artificial intelligence (AI) in the smart vision effort brings about a significant change in how diabetic retinopathy is diagnosed and treated, resulting in revolutionary benefits. The main objective of this program is to tackle all types of diabetic retinopathy by employing advanced AI techniques such as deep neural networks and machine learning. These sophisticated algorithms are specifically created to quickly and accurately diagnose conditions, allowing for prompt interventions to prevent vision loss by detecting complex patterns that cannot be seen by the human eye. By detecting intricate patterns that are imperceptible to the human eye, these algorithms ensure prompt and precise diagnosis. Early detection is essential since it enables prompt medical attention, thereby greatly diminishing the likelihood of permanent vision impairment. The smart vision program paves the way for a future in which diabetic retinopathy no longer causes blindness, providing a more promising, distinct, and secure optical future for individuals impacted by the condition.","Using artificial intelligence (AI) to its transformative advantage, the smart vision initiative represents a paradigm shift in the diagnostics and treatment of diabetic retinopathy. The primary aim of this initiative is to address all forms of diabetic retinopathy using cutting-edge AI techniques, including deep neural networks and machine learning. These advanced algorithms are designed for rapid and precise diagnosis, enabling swift interventions to prevent visual impairment by identifying intricate patterns that are invisible to the human eye. Through the identification of complex patterns that are invisible to the human eye, these algorithms guarantee quick and accurate diagnosis. This early detection is crucial as it allows for immediate care, significantly reducing the risk of irreversible vision loss. The smart vision initiative sets the stage for a future where diabetic retinopathy no longer leads to blindness, offering a brighter, clearer, and safer optical future for those affected by the condition.",1
"The utilization of artificial intelligence (AI) and computer vision (CV) has the potential to completely revolutionize the delivery of healthcare. AI-powered computer vision can be utilized for medical image analysis, disease identification, patient health tracking, surgical support, speeding up drug development, and developing personalized treatment plans. The utilization of AI-assisted computer vision in healthcare offers several benefits, including enhanced diagnosis, reduced expenses, customized treatment, improved patient outcomes, and expedited drug discovery. Nevertheless, the utilization of these technologies also poses challenges in regards to data privacy, bias, and legal issues. This chapter explores several applications of computer vision in healthcare systems, such as medical picture analysis, disease diagnosis, movement and gait analysis, surgical support, behavioral analysis, and medicine development. The chapter also addresses the challenges associated with implementing computer vision in healthcare, such as data privacy issues, bias, legal considerations, limited accessibility, and the intricacies of biological systems. In summary, the utilization of AI-assisted computer vision in healthcare systems has the potential to greatly transform the industry by facilitating faster and more precise diagnosis, improving patient results, and reducing expenses. In order to ensure the ethical and responsible use of these technologies, it is imperative to tackle the associated concerns.","The way healthcare is provided could be completely changed by the application of artificial intelligence (AI) and computer vision (CV). AI-enhanced computer vision can be applied to medical picture analysis, disease detection, patient health monitoring, surgical assistance, drug discovery acceleration, and the creation of individualized treatment programs. Improved diagnosis, lower costs, personalized treatment, better patient outcomes, and quicker drug discovery are all advantages of employing AI-assisted computer vision in healthcare. However, the application of these technologies also presents difficulties in terms of data privacy, bias, and legal matters. The sorts of computer vision utilized in healthcare systems are discussed in this chapter, including medical image analysis, disease diagnosis, movement and gait analysis, surgical support, behavioral analysis, and medication discovery. The difficulties of employing computer vision in healthcare are also covered in the chapter, including data privacy concerns, bias, legal concerns, a lack of accessibility, and the complexity of biological systems. Overall, AI-assisted computer vision holds immense promise for revolutionizing healthcare systems by enabling quicker and more accurate diagnosis, enhancing patient outcomes, and cutting costs. To make sure that these technologies are used in an ethical and responsible manner, it is crucial to address the issues related to them.",1
"Agriculture is of utmost importance and serves as the principal source of income for many countries. The presence of pathogens such as viruses, fungus, and bacteria in plants leads to a disease that results in significant financial losses for agricultural companies worldwide. Monitoring disease in plants is essential for ensuring the security of harvests in terms of both quality and quantity. Therefore, it is crucial to identify plant diseases. The plant disease condition is evident in specific plant organs. However, it is typically seen that the infection is found in specific leaves of plants. Researchers employ computer vision, deep learning, few-shot learning, and soft computing techniques to automatically detect plant diseases using leaf images. These strategies also help farmers take prompt and suitable actions to prevent a decrease in the quality and quantity of crops. By applying these techniques in illness recognition, it is possible to avoid the drawback of biased selection of disease features, extract relevant features, and enhance the speed and efficiency of technology and research. Furthermore, specific molecular approaches have been developed to proactively address and reduce the risk posed by pathogens. Therefore, this review assists the researcher in utilizing machine learning, deep learning, and few-shot learning to automatically identify diseases in plants. It also offers specific diagnostic strategies to prevent the occurrence of these diseases. Furthermore, this paper also addresses some of the forthcoming research endeavors in the field of disease classification.","Agriculture is the ultimate imperative and primary source of origin to furnish domestic income for multifarious countries. The disease caused in plants due to various pathogens like viruses, fungi, and bacteria is liable for considerable monetary losses in the agriculture corporation across the world. The security of crops concerning quality and quantity is crucial to monitor disease in plants. Thus, recognition of plant disease is essential. The plant disease syndrome is noticeable in distinct parts of plants. Nonetheless, commonly the infection is detected in distinct leaves of plants. Computer vision, deep learning, few-shot learning, and soft computing techniques are utilized by various investigators to automatically identify the disease in plants via leaf images. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. Also, certain molecular techniques have been established to prevent and mitigate the pathogenic threat. Hence, this review helps the investigator to automatically detect disease in plants using machine learning, deep learning and few shot learning and provide certain diagnosis techniques to prevent disease. Moreover, some of the future works in the classification of disease are also discussed.",1
"The domain of artificial intelligence (AI) technologies is extensive. There is a wide array of both individual and collaborative AI-based solutions that are currently accessible. One example of such technology is computer vision. Computer vision is closely connected to various other technologies such as machine learning (ML), deep learning (DL), and artificial neural networks. Computer vision is utilized in various domains. Healthcare has seen widespread application in recent decades. Healthcare utilizes algorithms in the aforementioned technologies to extract relevant information from medical photos. This chapter provides an overview of computer vision, including its various applications and its specific use in the healthcare industry. Furthermore, we will examine the case of tumor identification using computer vision in a MATLAB environment.","The sphere of artificial intelligence (AI) technology is quite wide. There are many individual and collaborative AI-based technologies available. One of them is computer vision technology. Computer vision is also related to other technologies: Machine learning (ML), deep learning (DL), artificial neural networks, etc. Computer vision is applied in many different areas. One of the areas where it has been widely applied in recent times is healthcare. In healthcare, various algorithms in the aforementioned technologies are used to obtain meaningful information from medical images. In this chapter, the concept of computer vision, its fields of application, and its application in healthcare are reviewed. Also, the example of tumor detection by computer vision in a MATLAB environment is considered.",1
"Inverse gas chromatography (IGC) is a method that has become exceedingly sensitive, versatile, and efficient for material analysis. By utilizing thermochemical methods, IGC offers valuable understanding of the physicochemical properties of materials, including dispersive surface free energy, Gibbs surface energy components, and Guttamann Lewis acid-base parameters. This extensive overview explores the historical context, equipment, and wide-ranging uses of IGC. Valuable material regarding the selection and description of various models utilized in IGC experiments is available for researchers and practitioners. IGC has diverse applications in sectors such as polymers, pharmaceuticals, minerals, surfactants, and nanomaterials. In addition, IGC enables the quantification of significant factors such as sorption enthalpy and entropy, dispersive and specific surface energy components, co/adhesion work, glass transition temperature, surface heterogeneity, miscibility, solubility parameters, and specific surface area. These insights enhance comprehension of material behavior and assist in the design and optimization of innovative materials. Furthermore, the incorporation of computer vision and image processing methods into IGC has improved our comprehension of the complex surface texture, roughness, and associated characteristics of materials. The combination of IGC, computer vision, and AI offers promising prospects for further investigation into chemical materials, creating fresh pathways for research and exploration. This study presents a thorough examination of IGC, including its methodology and applications. Additionally, it emphasizes the potential benefits of merging IGC with AI and computer vision. The valuable information and profound insights provided in this text will be advantageous for researchers, scientists, and professionals working in the advanced materials sector. It will empower them to utilize IGC and AI techniques to find and produce unique materials.","Inverse gas chromatography (IGC) has emerged as a highly sensitive, adaptable, and effective technology for material analysis. Through employing thermochemical approaches, IGC provides crucial insight into physicochemical information of materials such as dispersive surface free energy, Gibbs surface energy components and Guttamann Lewis acid-base parameters. In this comprehensive review, we delve into the historical background, instrumentation, and diverse applications of IGC. Researchers and practitioners will find valuable information on the selection and description of numerous models used in IGC experiments. The applications of IGC span various domains, including polymers, medicines, minerals, surfactants, and nanomaterials. Furthermore, IGC facilitates the measurement of important parameters such as sorption enthalpy and entropy, surface energy components (dispersive and specific), co/adhesion work, glass transition temperature, surface heterogeneity, miscibility, solubility parameters, and specific surface area. These insights contribute to a deeper understanding of material behavior and aid in the design and optimization of advanced materials. Moreover, the integration of computer vision and image processing techniques with IGC has enhanced our understanding of materials intricate surface texture, roughness, and related properties. This convergence of IGC with computer vision and artificial intelligence (AI) presents exciting opportunities for future exploration of chemical materials, opening new avenues for research and discovery. This paper not only provides a comprehensive overview of IGC, its techniques, and applications but also highlights the synergistic potential of combining IGC with AI and computer vision. The informative content and insights presented here will benefit researchers, scientists, and professionals in the field of advanced materials, enabling them to leverage IGC and AI for innovative materials discovery and development.",1
"Currently, the utilization of Artificial Intelligence (AI) in industrial control, smart home, and other domains has garnered positive feedback. Nevertheless, AI technology necessitates specific computer performance criteria and also confronts challenges in network security, data analysis, human-computer interaction, and other areas. Currently, the visual platform of embedded systems has made significant progress in practical applications. However, its development has been greatly hindered by issues such as low overall development efficiency and unsteady system performance. This paper developed an AI-based EP Vision System (VS). The platform integrated embedded hardware design with the Support Vector Machine (SVM) algorithm to achieve intelligent robot interaction and target detection capabilities. According to the test results, under identical conditions, students and experts had positive ratings of System X at rates of 83.5% and 90% respectively, whereas negative evaluations were reported at rates of 16.5% and 10% respectively. Nevertheless, their favorable assessment of System Y only represented 19% and 4%, whereas the unfavorable assessment accounted for 81% and 96%. The percentage of favorable assessment for System X was much more than that for System Y, suggesting that System X is capable of meeting the practical application needs and enhancing the efficiency of system recognition to some degree. The study demonstrated a direct correlation between artificial intelligence (AI) technology and emotional intelligence (EP) vs (VS).","At present, the application of Artificial Intelligence (AI) in industrial control, smart home and other fields has received good response. However, AI technology has certain requirements for computer performance, and also faces problems in network security, data analysis, human-computer interaction, etc. At present, the visual platform of embedded system has achieved remarkable results in practical applications, but its development has been seriously hampered by problems such as low overall development efficiency and unstable system performance. This paper designed an EP Vision System (VS) based on AI technology. The platform combined the embedded hardware design with the Support Vector Machine (SVM) algorithm to realize the intelligent robot interaction and target detection functions. The test results showed that when other conditions were the same, students and experts had 83.5% and 90% positive evaluations of System X, and 16.5% and 10% negative evaluations respectively. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. The proportion of positive evaluation of System X was much higher than that of System Y, which indicated that System X can meet the actual application requirements and improve the system recognition efficiency to a certain extent. It showed the positive relationship between AI technology and EP VS.",1
"Implemented on contemporary smart automobiles. Several Artificial Intelligence foundation models have been suggested for intelligent sensing to identify familiar item categories in novel yet similar situations. Nevertheless, the basic models of smart sensing still face difficulties in accurately identifying all item types in both familiar and unfamiliar situations. This letter seeks to expand the scope of smart sensing research for intelligent cars. We begin by providing an overview of the existing foundation models that are commonly employed, as well as the fundamental intelligence required for the intelligent sensing of vehicles. Next, we elucidate the concept of Sora-based Parallel Vision, which aims to upgrade the underlying models of intelligent sensing from a basic level (1.0) to an advanced one (2.0) and ultimately to a comprehensive level (3.0). The text presents a number of illustrative case studies that demonstrate the possible applications of Sora-based Parallel Vision. It also outlines the future research path of this technology.","installed on the modern intelligent vehicles. Many Artificial Intelligence based foundation models have been proposed for smart sensing to recognize the known object classes in the new but similar scenarios. However, it is still challenging for the foundation models of smart sensing to detect all the object classes in both seen and unseen scenarios. This letter aims at pushing the boundary of smart sensing research for intelligent vehicles. We first summarize the current widely-used foundation models and the foundation intelligence needed for smart sensing of intelligent vehicles. We then explain Sora-based Parallel Vision to boost the foundation models of smart sensing from basic intelligence (1.0) to enhanced intelligence (2.0) and final generalized intelligence (3.0). Several representative case studies are discussed to show the potential usages of Sora-based Parallel Vision, followed by its future research direction.",1
"Utilizing AI and machine learning, namely the vision transformer technique, for bacterial detection shows great potential in addressing the shortcomings of conventional methods. This approach offers improved speed and accuracy in identifying disease-causing bacteria such as E. coli. Research is currently being conducted to evaluate the usefulness of water in microbiology, specifically in relation to the presence of coli and salmonella, which are important for human survival. This study presents a groundbreaking positional self-attention transformer model for categorizing bacterial colonies. By incorporating a positional self-attention mechanism, we improved the performance of the model, building upon the established success of transformer architectures in several fields. We introduced an innovative method for categorizing bacterial colonies by employing a positional self-attention transformer model. This enables the model to efficiently capture spatial linkages and patterns within bacterial colonies, hence leading to exceptionally precise categorization outcomes. The model was trained on a large collection of bacterial pictures, guaranteeing its resilience and ability to adapt to various colony kinds. The suggested approach effectively captured the spatial linkages and sequential patterns inherent in bacterial colony images, enabling more precise and resilient categorization. The suggested model exhibited exceptional performance, with a classification accuracy of 98.50% in identifying bacterial colonies. This innovative methodology outperforms conventional methods by successfully capturing complex spatial interactions within microbial structures, providing unparalleled precision in detecting small morphological differences. The model's capacity to adjust to various colony shapes and arrangements is a notable progress, with the potential to revolutionize the field of bacterial colony categorization using cutting-edge deep learning methods. The model's high classification accuracy indicates its potential for practical applications in early detection of infectious diseases and focused treatment development. This study's results highlight the efficacy of integrating positional self-attention into transformer models for image-based classification tasks, namely in the field of bacterial colony analysis.","The application of AI and machine learning, particularly the vision transformer method, in bacterial detection presents a promising solution to overcome limitations of traditional methods, offering faster and more accurate detection of disease-causing bacteria like E. coli and salmonella in water, crucial for human survival, with ongoing research to further assess its effectiveness in microbiology. This research introduces a revolutionary positional self-attention transformer model for the classification of bacterial colonies. Leveraging the proven success of transformer architectures in various domains, we enhanced the model's performance by integrating a positional self-attention mechanism. We presented a novel approach for bacterial colony classification utilizing a positional self-attention transformer model. This allows the model to effectively capture spatial relationships and patterns within bacterial colonies, contributing to highly accurate classification results. We trained the model on a substantial dataset of bacterial images, which ensures its robustness and generalization to diverse colony types. The proposed model adeptly captured the spatial relationships and sequential patterns inherent in bacterial colony images, allowing for more accurate and robust classification. The proposed model demonstrated remarkable performance, achieving an accuracy of 98.50% in the classification of bacterial colonies. This novel approach surpasses traditional methods by effectively capturing intricate spatial relationships within microbial structures, offering unprecedented accuracy in discerning subtle morphological variations. The model's adaptability to diverse colony shapes and arrangements marks a significant advancement, promising to redefine the landscape of bacterial colony classification through the lens of state-of-the-art deep learning techniques. The high classification accuracy attained by the model, suggests its potential for practical applications in the early diagnosis of infectious diseases and the development of targeted treatments. The findings of this study underscore the effectiveness of incorporating positional self-attention in transformer models for image-based classification tasks, particularly in the domain of bacterial colony analysis.",1
"An autonomous vehicle is a sophisticated and all-encompassing application of advanced technology. It incorporates functions such as scene perception, optimization calculation, multi-level assisted driving, and more. This is achieved through the use of computer vision, sensors, information fusion, information communication, high-performance computing, artificial intelligence, and automatic control technologies. Computer vision is a crucial component of autonomous driving, serving as a primary means of data processing. Furthermore, it introduces groundbreaking transformations to the forthcoming transportation system. Image processing and computer vision are crucial in autonomous driving as they allow vehicles to observe and comprehend their surroundings, leading to intelligent decision-making and control. This paper discusses the application of computer vision and artificial intelligence in automatic driving. It focuses on image processing technology, including camera and sensor technology, image acquisition and preprocessing, feature extraction, and object detection. The goal is to explore the use of computer vision algorithms in automatic driving. The study of lane keeping and recognition, obstacle detection and avoidance, and traffic signal and sign recognition holds immense practical importance.","Autonomous vehicle is a typical high-tech comprehensive application, including scene perception, optimization calculation, multi-level assisted driving and other functions, using computer vision, sensors, information fusion, information communication, high-performance computing, artificial intelligence and automatic control and other technologies. In these technologies, computer vision, as a direct entry point to data processing, is an integral part of autonomous driving. Secondly, it brings revolutionary changes to the future transportation system. The application of image processing and computer vision in autonomous driving plays a key role in enabling vehicles to perceive and understand the surrounding environment and achieve intelligent decision-making and control. Therefore, in combination with the application of computer vision and artificial intelligence in automatic driving, this paper expounds the image processing technology in automatic driving, including camera and sensor technology, image acquisition and preprocessing, feature extraction and object detection, so as to discuss the application of computer vision algorithm in automatic driving. The research on lane keeping and recognition, obstacle detection and avoidance, traffic signal and sign recognition is of great practical significance.",1
"Medical picture segmentation is an essential problem in computer vision, serving as a vital function in applications such as diagnostics, treatment planning, and medical research. This study investigates various techniques utilized in medical research to accomplish image segmentation. The techniques encompass a spectrum of methodologies, including conventional methods such as thresholding, edge detection, region-based and clustering, as well as contemporary artificial intelligence techniques, specifically deep learning methods. An in-depth analysis is conducted to assess the advantages and constraints of each approach. This research aims to analyze several architectures employed in medical picture segmentation, with a specific focus on evaluating their performance. The objective is to thoroughly examine various segmentation methods, providing a comparative analysis of their efficacy. This document explores the latest advancements in segmentation technology, focusing on significant advances that have the potential to greatly enhance the accuracy and efficiency of interpreting medical images. The study presents the outcomes of multiple approaches to medical image segmentation, along with an in-depth analysis of the strengths and weaknesses of the different techniques used. This is achieved through a thorough compilation and detailed critique of the results obtained from employing various segmentation strategies. This study improves our understanding of how these techniques can be utilized in the medical field, particularly in the domain of computer vision.","Medical image segmentation is a crucial task in computer vision, playing a pivotal role in applications such as diagnostics, treatment planning, and medical research. The present study explores a wide range of methodologies employed in the field of medical research to achieve image segmentation. These techniques range from traditional approaches based on thresholding, edge detection, region-based and clustering, to modern artificial intelligence methods, particularly deep learning techniques. The strengths and limitations of each method are thoroughly examined. This paper focuses on analyzing various architectures used for medical image segmentation, specifically evaluating their performance. It aims to delve deeply into the different segmentation methods, offering a comparative perspective on their effectiveness. Furthermore, This document delves into the most recent technological progress in segmentation, emphasizing major breakthroughs capable of transforming the precision and productivity of analyzing medical images. Through an exhaustive compilation and detailed critique of the results obtained by employing a range of segmentation strategies, the study presents the outcomes of multiple approaches, accompanied by an in-depth analysis of the strengths and weaknesses inherent to the various techniques applied to medical image segmentation. This research enhances the comprehension of how these methods can be applied within the medical sector, especially in the area of computer vision.",1
"This paper presents a study that uses artificial intelligence (AI) to apply computer vision algorithms for identifying human emotions in video recordings while users interact with various visual stimuli. The research seeks to reveal the development of software that can detect emotions by utilizing AI algorithms and image processing pipelines to recognize users' facial expressions. The procedure entails evaluating users using visual stimuli and facilitating the application of computer vision algorithms that are in line with psychology theories that define emotions and their discernible characteristics. The study showcases the viability of using convolutional neural networks (CNN) and software development and training based on facial expressions to accurately identify emotions. The results demonstrate successful emotion detection. However, in order to enhance precision, further training is required for settings that involve a wider range of images and the implementation of additional algorithms to differentiate closely related emotional patterns. The discussion and conclusions highlight the inherent capabilities of artificial intelligence. The utilization of computer vision algorithms in emotion detection offers valuable insights into software development, continuous training, and the dynamic nature of emotion identification technologies. Additional training is required for situations involving a wider range of photos, coupled with the development of more advanced algorithms that can accurately differentiate between facial expressions that closely resemble each other in terms of emotional patterns. This will improve the level of certainty and accuracy.","This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. The discussion and conclusions emphasize the potential of A.I. and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy.",1
"The face is the primary and indispensable component of the human body, and due to its unique characteristics, it plays a vital role in the identification of individuals. Facial recognition technology (FRT) is a highly successful and captivating technology of the contemporary day. Following the COVID-19 epidemic, there is a global shift towards the adoption of contactless Facial Recognition Technology (FRT). Thanks to its non-contact biometric features, Facial Recognition Technology (FRT) is gaining significant popularity on a global scale. Companies are substituting traditional fingerprint scanners with artificial intelligence-powered facial recognition technology (FRT), which is creating significant opportunities in the business sector. Security and surveillance, authentication/access control systems, digital healthcare, and photo retrieval are among the domains where its utilization has become indispensable. In this communication, we discussed the worldwide implementation of Facial Recognition Technology (FRT), its increasing popularity in the market, its application in different industries, as well as the obstacles and growing concerns associated with it, with a particular focus on India and globally.","The face is the most essential part of the human body, and because of its distinctive traits, it is crucial for recognizing people. Facial recognition technology (FRT) is one of the most successful and fascinating technologies of the modern times. The world is moving towards contactless FRT after the COVID-19 pandemic. Due to its contactless biometric characteristics, FRT is becoming quite popular worldwide. Businesses are replacing conventional fingerprint scanners with artificial intelligence—based FRT, opening up enormous commercial prospects. Security and surveillance, authentication/access control systems, digital healthcare, photo retrieval, etc., are some sectors where its use has become essential. In the present communication, we presented the global adoption of FRT, its rising trend in the market, utilization of the technology in various sectors, its challenges and rising concerns with special reference to India and worldwide.",1
"Advancements in technology have allowed computers to accurately detect and classify facial expressions in order to ascertain an individual's emotional state in a still image or a video. Facial Expression Recognition (FER) has emerged as a highly prominent study field in computer vision. Lately, deep facial expression recognition (FER) systems have mainly focused on tackling two major obstacles: the issue of overfitting caused by a lack of sufficient training data, and the existence of expression-unrelated changes such as lighting conditions, head position, image quality, and biases related to individual identities. This work presents a thorough examination of deep facial expression recognition (FER), including an analysis of techniques and datasets that provide valuable information about these inherent challenges. This study begins by providing a comprehensive chronology that illustrates the development of techniques and datasets in the field of deep facial expression recognition (FER). This timeline depicts the advancement and evolution of the methodologies and data sources employed in Facial Expression Recognition (FER). Next, a thorough examination of Facial Expression Recognition (FER) methods is presented, encompassing the fundamental principles of FER (such as preprocessing, feature extraction, classification, etc.) spanning from the era of traditional methods utilizing manually designed features (e.g., SVM and HOG) to the era of deep learning. Additionally, a concise overview is given about the benchmark datasets, which are divided into two categories: controlled environments (lab) and uncontrolled environments (in the wild). These datasets are utilized to assess various facial expression recognition (FER) approaches, and a comparison of different FER models is also shown. The paper discusses the current deep neural networks and training methods used for Facial Expression Recognition (FER), focusing on both static photos and dynamic image sequences. The text identifies the remaining obstacles and the related possibilities in Facial Expression Recognition (FER), as well as the future paths for creating strong and reliable deep FER systems.","Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of the techniques and data resources used in FER. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) to the deep learning era. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.",1
"Advancements in technology have allowed computers to analyze and classify facial expressions in order to ascertain an individual's emotional state in a still image or a video. Facial Expression Recognition (FER) is a widely studied topic in computer vision. Lately, deep facial expression recognition (FER) systems have mainly focused on tackling two major obstacles: the issue of overfitting caused by a lack of sufficient training data, and the existence of expression-unrelated changes, such as lighting conditions, head position, image quality, and bias towards specific individuals. This study presents a thorough examination of deep Facial Expression Recognition (FER), covering the techniques and datasets that provide valuable information about these inherent challenges. This work begins by providing a comprehensive timeline that illustrates the progression of techniques and datasets used in deep facial expression recognition (FER). This timeline demonstrates the evolution and advancement of the methodologies and data sources employed in Facial Expression Recognition (FER). Next, this paper presents a thorough examination of Facial Expression Recognition (FER) methods, encompassing the fundamental principles of FER such as preprocessing, feature extraction, classification, and various techniques. The review spans from the traditional era of FER, which relied on manually crafted features like SVM and HOG, to the current era of deep learning. Furthermore, a concise overview is given about the benchmark datasets, which may be classified into two categories: controlled environments (lab) and uncontrolled environments (in the wild). These datasets are utilized to assess various facial expression recognition (FER) approaches, as well as to compare different FER models. The paper discusses the current deep neural networks and training methodologies used for Facial Expression Recognition (FER), focusing on both static photos and dynamic image sequences. The text identifies the remaining obstacles and the related possibilities in Facial Expression Recognition (FER), as well as the future paths for creating resilient deep FER systems.","Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of the techniques and data resources used in FER. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) to the deep learning era. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.",1
"Facial recognition is a widely recognized and highly regarded area of study within the subject of Computer Vision, particularly due to the progress made in deep learning and the availability of extensive datasets. Facial recognition technology has made substantial advancements and is extensively utilized in practical situations. A comprehensive facial recognition system comprises three primary components: facial recognition, orientation, and representation. This method use deep convolutional neural networks to identify and align faces to a standard perspective, as well as extract information for recognition. This article offers a comprehensive summary of the most recent progress in various domains, demonstrating how deep learning has significantly improved their capabilities. The field of object detection in machine vision is a complex topic that necessitates substantial enhancements. Although picture classification accuracy has reached approximately 2.25%, surpassing human performance, object identification algorithms are still in their initial development phases. Presently, algorithms are able to attain a maximum of 40.8 Mean Average Precision Scores (MAPS) when applied to contemporary items. Therefore, it is of utmost importance to meticulously choose the dataset in order to obtain the most favorable outcomes.","Facial recognition is a well-established and popular field in Computer Vision, especially with advancements in deep learning and data sets. Deep facial recognition has made significant progress and is widely applied in real-world scenarios. A complete facial recognition system involves three main components: facial recognition, orientation, and representation. This system detects faces, aligns them to a standard view, and extracts features for recognition using deep convolutional neural networks. This article provides a detailed overview of the latest advancements in these areas, showing how deep learning has greatly enhanced their abilities. Object detection in machine vision is a challenging area that requires significant improvements. While image classification accuracy is nearing 2.25%, surpassing human performance, object detection algorithms are still in the early stages. Current algorithms achieve only 40.8 MAPS on modern objects, so careful dataset selection is crucial for optimal results.",1
"Facial recognition technology (FRT) is an artificial intelligence (AI)-based technology employed during the COVID-19 pandemic to manage the transmission of the virus. As preparations for future pandemics are now in progress, this technology is seen as an effective tool for monitoring affected persons and gathering real-time surveillance data. When used correctly, Facial Recognition Technology (FRT) can assist governments in implementing public health surveillance. This refers to the organized gathering, storage, utilization, and distribution of personal information to identify and control the spread of diseases. However, FRT also poses ethical and legal dilemmas. These include the potential use of FRT without obtaining consent from the individuals being monitored, the safeguarding of biometric data collected during surveillance, and the possibility of this information being utilized for purposes other than public health. Although widely implemented in nations like Russia and China, western jurisdictions are significantly more hesitant to embrace it, both for pandemic-related objectives and in other contexts.","Facial recognition technology (FRT) is one of several artificial intelligence (AI)-based technologies used during the COVID-19 pandemic to control the spread of the virus. As planning for future pandemics is currently underway, this technology is envisioned as an efficient tool to track infected individuals and collect real-time surveillance data. When properly used, FRT can support governments’ strategies to implement public health surveillance, which is defined in the literature as ‘the systematic collection, storage, usage, and dissemination of personal information to identify an outbreak and mitigate the spread of disease’.
Nonetheless, FRT presents some ethical and legal challenges, such as its use without ensuring consent from the individuals under surveillance, the protection of biometric data collected through surveillance, and the risk of using this information for other purposes besides public health. Despite being widely deployed in countries such as Russia and China, for pandemic purposes and beyond, western jurisdictions are much more reluctant to adopt it.",1
"Amidst the COVID-19 outbreak, Delhi, India, encountered a critical problem when almost 1,500 people who tested positive for COVID-19 disappeared. During public health emergencies, such as pandemics, natural disasters, or other calamities, hospitals and medical centers encounter a sudden surge of patients. Hospital management encounters challenges in effectively managing patient flow, particularly when patients need to be transferred between facilities or when new temporary healthcare facilities are established. These issues can lead to a rise in missing person situations. Patients may unintentionally be isolated from their family. The human face possesses a distinctive biometric system capable of ascertaining an individual's age, gender, mood, and even verifying their identity. Utilizing the capabilities of deep learning and artificial intelligence, computer vision plays a crucial role in Patient Identification. This study introduces an advanced patient face detection model that combines a twofold approach. The first component utilizes MTCNN, a cutting-edge multi-task cascaded convolution neural network, for face detection and alignment. The second component employs FaceNet, a well-known convolutional neural network (CNN) algorithm for face embedding. Finally, a KNN algorithm is used as a classifier to achieve an impressive accuracy rate of 97.1%. In order to prioritize public safety during the pandemic, we have developed a Resnet34 model specifically designed for detecting masks. This model has been trained using the Face Mask Detection dataset and has achieved an impressive accuracy rate of 97%. This work not only focuses on the urgent issues related to patient identification and safety during crises, but also has implications for wider healthcare applications. The offered models present potential opportunities for improving patient care and security.","During the COVID-19 pandemic, Delhi, India, faced a pressing issue where approximately 1,500 COVID-19-positive patients went missing. In public health emergencies, such as pandemics, natural disasters, or other calamities, hospitals, and medical centres experience a sudden influx of patients, and hospital management faces difficulties in keeping track of patients, especially when they need to be moved between facilities or when new temporary healthcare facilities are set up. As a consequence of these challenges, there can be an increase in missing person cases. Patients may be inadvertently separated from their families. The human face is a unique biometric system that can determine the age, gender, mood, of an individual, and even identity for verification purposes. Harbouring the power of deep learning and artificial intelligence, one of the most important applications of computer vision is Patient Identification. In this study, we have proposed a state-of-the-art patient face detection model using a twofold model that uses MTCNN short for “multi-task cascaded convolution neural network” for face detection and alignment purposes with a FaceNet Convolutional Neural Network (CNN) a renowned face embedding algorithm finally with KNN algorithm as a classifier to get an accuracy of 97.1%. Also, to ensure public safety during the pandemic we have constituted a Resnet34 model for mask detection trained on the Face Mask Detection dataset with an accuracy of 97%. This study not only addresses the immediate challenges of patient identification and safety during crises but also carries implications for broader healthcare applications. The proposed models offer promising avenues for enhancing patient care and security.",1
"Well-being is a fundamental aspect of positive psychology, renowned for its beneficial impact on both the personal and professional aspects of individuals, as well as on teams and organizations. Comprehending and advocating for personal well-being is crucial for the health and sustained achievement of staff members. However, existing methods for evaluating subjective well-being rely on lengthy surveys and questionnaires, which hinder the ability to offer immediate feedback necessary for increasing awareness and modifying individual conduct. This research presents a framework for comprehending the process of non-verbal communication in cooperation. It utilizes video data to uncover important factors that can predict an individual's well-being in a team setting. The system utilizes advanced video acquisition methods and cutting-edge artificial intelligence tools to extract specific, comparative, and contextual features from panoramic video footage. Each time series undergoes statistical analysis, resulting in the creation of a dataset consisting of 125 features. These features are subsequently connected to PERMA surveys, which were designed within the field of positive psychology and measure Positive Emotion, Engagement, Relationships, Meaning, and Accomplishments. Machine learning algorithms are used to assess each component of the PERMA model as either a regression or classification problem. The methodology we employed was implemented in a specific instance, wherein 80 students participated in 20 groups over the course of one week, working together on a team assignment in a physical, in-person environment. As a result, we were able to develop multiple hypotheses that pinpoint the characteristics that influence an individual's well-being in a team setting. These encouraging findings indicate intriguing possibilities for further research, such as integrating various forms of media to analyze the personal well-being of individuals in a team setting.","Well-being is one of the pillars of positive psychology, which is known to have positive effects not only on the personal and professional lives of individuals but also on teams and organizations. Understanding and promoting individual well-being is essential for staff health and long-term success, but current tools for assessing subjective well-being rely on time-consuming surveys and questionnaires, which limit the possibility of providing the real-time feedback needed to raise awareness and change individual behavior. This paper proposes a framework for understanding the process of non-verbal communication in teamwork, using video data to identify significant predictors of individual well-being in teamwork. It relies on video acquisition technologies and state-of-the-art artificial intelligence tools to extract individual, relative, and environmental characteristics from panoramic video. Statistical analysis is applied to each time series, leading to the generation of a dataset of 125 features, which are then linked to PERMA (Positive Emotion, Engagement, Relationships, Meaning, and Accomplishments) surveys developed in the context of positive psychology. Each pillar of the PERMA model is evaluated as a regression or classification problem using machine learning algorithms. Our approach was applied to a case study, where 80 students collaborated in 20 teams for a week on a team task in a face-to-face setting. This enabled us to formulate several hypotheses identifying factors influencing individual well-being in teamwork. These promising results point to interesting avenues for research, for instance fusing different media for the analysis of individual well-being in teamwork.",1
"Face recognition plays a crucial role in a wide range of applications, including security, surveillance, and authentication. Many households have installed closed-circuit television (CCTV) cameras for the purpose of enhancing safety and identifying individuals. The purpose of these CCTV cameras is to ensure safety and identify individuals who visit their homes. In a select highly protected locations, access for unknown intruders is severely restricted. This study focuses on a system that use machine learning and artificial intelligence algorithms to identify the face of an intruder through a surveillance camera. The specified design is effectively realized using the HOG feature extraction and SVM classification algorithms. It accurately classifies the faces in a video stream provided as input. The primary aim of this study is to identify individuals' faces in a video using a HOG feature extractor. The faces will then be classified using SVM, allowing the machine to distinguish between authorized personnel working for the business and potential intruders.","Face recognition has a very important role in various applications, from security, surveillance to authentication. For safety most of the household is having CC cameras such that they could recognize the persons from it. These CCTV are allocated for having safety and to know who visited their houses. In few highly secured places where allowance to any unknown intruder is strictly prohibited. Thereby, this paper deals with a system which could recognize the face of the intruder through surveillance camera using ML and AI based algorithms. The design specified is successfully implemented using HOG feature extraction and SVM classification algorithms and it classifies the faces for a video stream given as input. The major objective entitled to this paper is to recognize the faces of people from the video by HOG feature extractor and classify them using SVM and train the machine to tell who is the person working for the organization and who are the intruder.",1
"The expanding population results in a larger consumer base, which in turn places greater demands on resources to meet the increasing needs of consumers on a daily basis. Given that technology is being employed to address various issues, it is reasonable to consider its application in resolving this particular problem as well. The concept aims to enhance the convenience and sophistication of the supermarket experience by eliminating the need for cashiers and queues, thereby enabling a seamless shopping experience. This project utilizes Artificial Intelligence and Internet of Things to automate the operations of a supermarket, resulting in improved efficiency. To gain access, an individual just needs to enter the premises after scanning their QR code using the designated application, which contains their distinctive identification number. The system will document the customer's presence within the store. The shopping carts and baskets are equipped with sensors that can detect the presence or removal of products. The merchandise are positioned on shelves equipped with pressure sensors that can identify any instance of a product being lifted. These shelves are inaccessible and may only be opened with your shopping cards. Upon reaching the counter, simply swipe your card once more. The amount corresponding to your purchase will be withdrawn from your account, and you will receive a receipt. We anticipate offering this technology to many supermarket chains domestically and internationally, assisting them in its implementation through a modest one-time expenditure.","The growing population also leads to a growing consumer base which increases the load and resources to cater the needs of the day-by-day increasing consumers. Just as technology is being used to solve all the problems so why not this one. The idea is to make a more convenient and advanced super market experience, where there are no cashiers or lines so that we can shop hassle free. This project implements Artificial Intelligence and Internet of Things to automate a supermarket for better efficiency. A person just needs to walk in after scanning their QR code through the app with their unique ID on it. It will record the customer's presence in the shop. The shopping carts and baskets have sensors on them, which can detect the product entering or being taken out. The products are placed on shelves which have pressure sensors to detect if any product is picked up. These shelves are closed and they only open with your shopping cards. When you reach the counter, you only have swipe your card again and money will be deducted from your account according to your purchase and a receipt will be given. We look forward to provide this technology to various super market chains in the country and abroad and help them implement it with a nominal one time investment.",1
"Autonomous vehicles (AVs) are anticipated to revolutionize future transportation systems, with decision making being a crucial component for achieving advanced automated driving. Data-driven decision-making approaches have gained increased attention as a solution to complex circumstances that rule-based methods struggle to handle well. The selection of datasets for data-driven approaches has a significant impact on decision-making performance. Therefore, it is crucial to thoroughly understand the available datasets. When considering the sources of collected data, driving data may be categorized into three types: vehicle-related data, environment-related data, and driver-related data. This study conducts a comparison of the most advanced datasets in three categories and provides a concise summary of their characteristics, such as the types of sensors employed, the methods of annotation, and the driving scenarios involved. This survey examines the properties of datasets and explores their potential uses in many elements of AV decision making. It aims to help researchers choose suitable datasets to support their own research. An overview of the forthcoming patterns in the evolution of AV datasets is provided.","Autonomous vehicles (AVs) are expected to reshape future transportation systems, and decision making is one of the critical modules toward high-level automated driving. To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more focus. The datasets to be used in developing data-driven methods dramatically influence the performance of decision making; hence, it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle-, environment-, and driver-related data. This study compares the state-of-the-art datasets of these three categories and summarizes their features, including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also discusses potential applications of datasets on various aspects of AV decision making, assisting researchers in finding appropriate ones to support their own research. The future trends of AV dataset development are summarized.",1
"Precise trajectory tracking is not feasible in real-world situations, but it is often thought to be helpful in designing motion planning algorithms. This study presents a robust and dependable framework for motion planning and control. The system effectively addresses tracking problems resulting from imprecise tracking by coordinating the motion planning layer and controller. More precisely, the motion space is partitioned into areas that are considered safe and areas that are considered risky. This is achieved by determining the size of the movement constraint based on the tracking error, which is used to create the repulsive potential field. The collision-free waypoint set can be achieved by combining global search and the proposed waypoint set filtering approach. An optimization-based strategy is used to suit the planned trajectory by minimizing the acceleration of the reference trajectory. Subsequently, the intended path is examined and adjusted by the implemented anti-collision modification to guarantee safety. By employing invertible transformation and adaptive compensation, it is possible to confine the transient trajectory tracking errors within the intended region, even in the presence of actuator failures. The cooperation between the planning and control levels ensures safety and reliability even in the presence of imprecise tracking and actuator defects, as tracking error is carefully accounted for and managed at the planning level. The simulation and experimental results confirm the benefits and efficacy of the suggested motion planning and control system.","Accurate trajectory tracking is unrealistic in real-world scenarios, however, which is commonly assumed to facilitate motion planning algorithm design. In this paper, a safe and reliable motion planning and control framework is proposed to handle the tracking errors caused by inaccurate tracking by coordinating the motion planning layer and controller. Specifically, motion space is divided into safe regions and risky regions by designing the movement restraint size dependent on tracking error to construct the repulsive potential field. The collision-free waypoint set can then be obtained by combining global search and the proposed waypoint set filtering method. The planned trajectory is fitted by an optimization-based approach which minimizes the acceleration of the reference trajectory. Then, the planned trajectory is checked and modified by the designed anti-collision modification to ensure safety. Using invertible transformation and adaptive compensation allows the transient trajectory tracking errors to be limited within the designed region even with actuator faults. Because tracking error is considered and margined at the planning level, safety and reliability can be guaranteed by the coordination between the planning and control levels under inaccurate tracking and actuator faults. The advantages and effectiveness of the proposed motion planning and control method are verified by simulation and experimental results.",1
"How can the risks associated with autonomous vehicles (AVs) be allocated among those in regular road traffic? The extensive body of literature on the ethics of autonomous vehicles (AVs) mostly focuses on moral decision-making in situations where collisions are inevitable. We advocate for expanding the discussion to encompass driving behaviors in ordinary road traffic, where prevalent ethical dilemmas develop as a result of the continual transfer of risk among road users. The allocation of risks in this scenario gives rise to ethical concerns that cannot be avoided through simplistic strategies like abruptly stopping. To assess participants' preferences regarding the driving actions of autonomous vehicles (AVs), we conducted a comprehensive survey in Germany using an interactive and visual representation of various traffic scenarios. The preferences of our participants differed dramatically from simple collision avoidance. Our participants demonstrated a willingness to assume risks on behalf of other road users, which suggests that the social dilemma of autonomous vehicles (AVs) may be reduced in hazardous conditions. Our research aims to establish a connection between engineers and philosophers in order to facilitate a more productive discussion on the ethical implications of autonomous vehicles.","How would people distribute risks of autonomous vehicles (AVs) in everyday road traffic? The rich literature on the ethics of autonomous vehicles (AVs) revolves around moral judgments in unavoidable collision scenarios. We argue for extending the debate to driving behaviors in everyday road traffic where ubiquitous ethical questions arise due to the permanent redistribution of risk among road users. This distribution of risks raises ethically relevant questions that cannot be evaded by simple heuristics such as “hitting the brakes.” Using an interactive, graphical representation of different traffic situations, we measured participants’ preferences on driving maneuvers of AVs in a representative survey in Germany. Our participants’ preferences deviated significantly from mere collision avoidance. Interestingly, our participants were willing to take risks themselves for the benefit of other road users, suggesting that the social dilemma of AVs may be mitigated in risky environments. Our research might build a bridge between engineers and philosophers to discuss the ethics of AVs more constructively.",1
"Artificial intelligence is a burgeoning technology that replicates human intelligence in machines by programming them to emulate human thinking and imitate their behaviors. An autonomous vehicle is capable of operating independently and performing essential tasks without any human intervention. This cutting-edge technology has the potential to enhance passenger safety, alleviate traffic congestion, optimize traffic flow, reduce fuel consumption, minimize pollution, and improve overall travel experiences. Autonomous vehicles are crucial in manufacturing, agricultural, transportation, and military domains. The actions of the autonomous vehicle are facilitated by sensor data and a limited number of artificial intelligence systems. Artificial intelligence encompasses the gathering of data, determining optimal routes, and carrying out tasks in self-driving vehicles, which necessitate the utilization of machine learning methods inherent to artificial intelligence. However, there are certain privacy and security problems associated with this. Autonomous vehicles place significant emphasis on security. This article will address the concerns around cybersecurity when integrating artificial intelligence into autonomous vehicles, as well as the advancements in self-driving car technology.","Artificial intelligence is one of the emerging technologies that simulate human intelligence in machines by programming it to think like human beings and mimic their actions. An autonomous vehicle can function itself and carry out necessary functions without any human involvement. This innovative technology may provide increased passenger safety, less congested roads, congestion reduction, optimum traffic, lower fuel consumption, less pollution, and better travel experiences. Autonomous vehicles play a vital role in industry, agriculture, transportation, and military applications. The autonomous vehicle's activities are supported by sensor data and a few artificial intelligence systems. Artificial intelligence is the collection of data, path planning, and execution in autonomous vehicles that require some machine learning techniques that are a part of artificial intelligence. But this comes with some privacy issues and security concerns. Security is an important concern for autonomous vehicles. The issues of cybersecurity while incorporating artificial intelligence in autonomous vehicles will be covered in this article, along with the growing technology of self-driving automobiles.",1
"Over the past few decades, there has been a consistent growth in the number of vehicles on the road, mostly driven by the increasing need for urban transportation and modern logistics. Two of the numerous adverse consequences resulting from the proliferation of vehicles on the road, which also hinder economic progress, are heightened traffic congestion and traffic accidents. The aforementioned challenges can be effectively addressed by enhancing the intelligence of vehicles and minimizing their need on human intervention. In the last century, numerous countries have carried out substantial research that has driven the automation of road vehicles. All major motor manufacturers worldwide are currently actively pursuing the development of autonomous vehicle (AV) technologies. Without a doubt, the extensive adoption of self-driving vehicles is closer than we perceive, thanks to the advancements in artificial intelligence (AI). AI has become an essential component for autonomous vehicles to accurately sense their environment and make real-time judgments. The advancement of AI is propelled by the expansion of big data generated by several sensing devices and state-of-the-art computing resources. In order to fully understand the functions of AI in AV systems, it is necessary to first analyze the development and history of AI.","Throughout the last decades, the number of vehicles on the road has steadily increased due to the rising demand for urban mobility and contemporary logistics. Two of the many detrimental effects of more vehicles on the road, which also impede economic development, are increased traffic congestion and traffic accidents. The issues mentioned above can be significantly resolved by making vehicles smarter by reducing their reliance on humans. Over the past century, various nations have conducted extensive research that has fueled the automation of road vehicles. The development of autonomous vehicle (AV) technologies is currently being pursued by all significant motor manufacturers worldwide. Undoubtedly, the widespread use of autonomous cars is more imminent than we realize given the development of artificial intelligence (AI). In order for AVs to perceive their surroundings and make the right decisions in real time, AI has emerged as a crucial component. This development of AI is being driven by the growth of big data from numerous sensing devices and cutting-edge computing resources. We must first examine AI's development and history in order to comprehend its functions in AV systems.",1
"The future viability of the worldwide automobile sector will be significantly impacted by the fourth industrial revolution and the advancement of artificial intelligence (AI). The future is expected to be shaped by new industry norms, such as the growing prevalence of autonomous self-driving technology, revised safety standards, more intricate insurance regulations, the evolving social acceptance of technological advancements, the need for city infrastructure that bridges the digital divide, and the emergence of disruptive business innovation through strategic collaborations involving open-source AI. This chapter examines the crucial elements of autonomous vehicles (AVs) by utilizing advancements in artificial intelligence (AI) in radar and laser technology. It also considers commercial risks, customer behavior in self-driving vehicles, limitations imposed by city infrastructure, and societal adjustments to new technology. The future direction of the autonomous vehicle (AV) business is anticipated to be shaped by the interaction of commercial, social, risk, infrastructure, and regulatory factors, which will have different effects on the industry's stakeholders. This study forecasts that the most probable sustainable future for the AV industry will be shaped by: (1) AI's pulsed laser LiDAR technology with a sufficiently high frequency of data collection and the need for GPS bi-directional cloud technology, (2) collective insurance instead of individual liability, (3) smart city infrastructure that will likely result in significant disparities in digital connectivity across different transportation regions, leading to regional inequality, and (4) customers who strongly favor a semi-autonomous vehicle controlled by a human driver rather than full machine autonomy.","The future sustainability of the global automotive industry will be greatly affected by the fourth industrial revolution and the evolution of artificial intelligence (AI). The “new normal” is projected to be driven by new industry standards including an increasingly autonomous self-driving technology, amended safety standards, more complex insurance regulations, adaptive social resistance to technological change, city infrastructure requirements with a digital divide, and disruptive business innovation based on strategic input supply partnerships with open-source AI. In this chapter, the key factors of the autonomous vehicles (AVs) are analyzed using AI developments in radar and laser technology, commercial risk factors, self-driving consumer behavior, city infrastructure constraints, and social adaptations to new technology. The future trajectory of the AV industry is expected to be an interplay between commercial, social, risk, infrastructure, and regulatory mechanisms with various impacts on the industry’s stakeholders. This study predicts that the most likely sustainable scenario for the AV industry is that it will be driven by: (1) AI’s pulsed laser LiDAR (Light Detection and Ranging) with a sufficient loop frequency and GPS bi-directional cloud technology requirement, (2) pooled insurance in contrast to individual liability, (3) smart city infrastructure with expected sharp digital divide across transport regions leading to more regional inequality, and (4) customers who strongly prefer a human controlled semi-autonomous vehicle rather than complete machine autonomy.",1
"The future of autonomous vehicles depends on the merging of human-centric design with sophisticated AI capabilities. In the future, autonomous vehicles will not only transport passengers but also engage with and adjust to their preferences, ensuring a comfortable, efficient, and enjoyable travel. This study introduces a new framework that utilizes Large Language Models (LLMs) to improve the decision-making processes of autonomous cars. This framework aims to seamlessly incorporate the advanced language and reasoning capabilities of LLMs into autonomous vehicles by integrating their natural language capabilities and contextual understanding, utilizing specialized tools, synergizing reasoning, and collaborating with various modules. The suggested framework has the capacity to fundamentally transform the functioning of autonomous vehicles by providing customized support, ongoing acquisition of knowledge, and clear decision-making processes, ultimately leading to the development of safer and more effective autonomous driving technologies.","The future of autonomous vehicles lies in the convergence of human-centric design and advanced AI capabilities. Autonomous vehicles of the future will not only transport passengers but also interact and adapt to their desires, making the journey comfortable, efficient, and pleasant. In this paper, we present a novel framework that leverages Large Language Models (LLMs) to enhance autonomous vehicles' decision-making processes. By integrating LLMs' natural language capabilities and contextual understanding, specialized tools usage, synergizing reasoning, and acting with various modules on autonomous vehicles, this framework aims to seamlessly integrate the advanced language and reasoning capabilities of LLMs into autonomous vehicles. The proposed framework holds the potential to revolutionize the way autonomous vehicles operate, offering personalized assistance, continuous learning, and transparent decision-making, ultimately contributing to safer and more efficient autonomous driving technologies.",1
"The potential of connected automated cars is diverse, and the progress of automation is closely linked to the growth of the Internet of Things (IoT), which enables artificial intelligence (AI). The initial progress in engineering, electronics, and various other domains has served as a source of inspiration for AI. Multiple technological proposals exist for the implementation of automated cars. Automated vehicles significantly enhance traffic optimization and reduce casualties. When investigating vehicle autonomy, there are two main areas of development: high-level system integrations, such as new-energy cars and intelligent transportation systems, and backward subsystem progress, which focuses on improving sensor and information processing systems. The Advanced Driver Assistance System demonstrates outcomes that align with the anticipated challenges encountered in achieving vehicle autonomy. Situational intelligence, which involves the collection of vast quantities of data, is utilized for the precise construction of high-definition city maps, land surveys, and quality assessment of roadways. The transport's infotainment system incorporates advanced technologies such as gesture recognition, language translation, and environmental perception. These capabilities are enabled by a combination of camera, Light Detection and Ranging (LiDAR), and Radio Detection And Ranging (RADAR) sensors, which also allow for object localization within the scene. This chapter provides an overview of the history of autonomous vehicles (AV), current research areas in artificial intelligence (AI) technology for AV, state-of-the-art datasets used in AV research, and the various Machine Learning (ML)/Deep Learning (DL) algorithms that make up the AV system. It concludes by discussing the challenges and opportunities of AI in AV.","The potential for connected automated vehicles is multifaceted, and automated advancement deals with more of Internet of Things (IoTs) development enabling artificial intelligence (AI). Early advancements in engineering, electronics, and many other fields have inspired AI. There are several proposals of technologies used in automated vehicles. Automated vehicles contribute greatly toward traffic optimization and casualty reduction. In studying vehicle autonomy, there are two categories of development available: high-level system integrations like new-energy vehicles and intelligent transportation systems and the other involves backward subsystem advancement like sensor and information processing systems. The Advanced Driver Assistance System shows results that meet the expectations of real-world problems in vehicle autonomy. Situational intelligence that collects enormous amounts of data is considered for high-definition creation of city maps, land surveying, and quality checking of roads as well. The infotainment system of the transport covers the driver's gesture recognition, language transaction, and perception of the surroundings with the assistance of a camera, Light Detection and Ranging (LiDAR), and Radio Detection And Ranging (RADAR) along with localization of the objects in the scene. This chapter discusses the history of autonomous vehicles (AV), trending research areas of artificial intelligence technology in AV, state-of-the-art datasets used for AV research, and several Machine Learning (ML)/Deep Learning (DL) algorithms constituting the functioning of AV as a system, concluding with the challenges and opportunities of AI in AV.",1
"In recent years, artificial intelligence has become an indispensable component of both production and service systems, as technology has become an essential feature of everyday life. Automated driving vehicles, commonly referred to as driverless cars, function automatically without the need for a human driver. Recent years have witnessed significant progress in the field of autonomous vehicles. The civilization currently need artificially intelligent autonomous automobiles. While there may be individuals who are hesitant to relinquish control of their vehicle to a computer, automated driving technologies possess the capacity to enhance road safety. Autonomous vehicles have the potential to tackle both environmental concerns and safety difficulties. Computers do not experience the same challenges as humans in maintaining focus while driving. Moreover, through proper responses, an autonomous vehicle has the ability to avert accidents caused by potentially hazardous situations on the road. Self-driving technology has numerous benefits, including increased accessibility to transportation for individuals who are unable to operate a vehicle. Due to factors such as lack of experience, disability, or advanced age, a significant number of individuals are unable to operate a motor vehicle. These individuals can travel with a significantly higher level of safety and autonomy. Consequently, this chapter will delve into the structures of both the software and hardware components of autonomous cars, along with their constituent parts, advantages, and forthcoming advancements.","Artificial intelligence is now a necessary component for both production and service systems in recent years, as technology has become a vital aspect of daily life. Automated driving vehicles operate autonomously, also known as driverless cars that can operate without a human driver. Research on autonomous vehicles has substantially advanced in recent years. Artificially intelligent autonomous vehicles are the current need of the society. Although some people might be apprehensive to give a computer control of their vehicle, automated driving technologies have the potential to make roads safer. Self-driving automobiles can address environmental issues as well as safety-related ones. Unlike humans, computers do not really have difficulty keeping attention when driving. Additionally, by responding appropriately, an automated car can prevent accidents to potentially dangerous events on the road. Self-driving technology has many advantages, one of which will make more easily accessible means of transport to people who are unable to drive. For a variety of reasons, such as inexperience, incapacity, or age, many people are unable to operate a vehicle. These individuals can travel considerably more safely and independently. Therefore, we will explore the architectures of both software and hardware of autonomous cars in this chapter, as well as their parts, benefits, and future developments.",1
"The emergence of autonomous vehicles has marked a revolutionary period in transportation, fundamentally altering the realm of mobility through state-of-the-art technologies. The key aspect of this transformation is the incorporation of Artificial Intelligence (AI) and learning algorithms, which drive cars towards unprecedented levels of autonomy. This study offers a thorough examination of the evolutionary path of artificial intelligence (AI) in autonomous cars, mapping the progress from fundamental concepts to the latest breakthroughs. Starting with an analysis of the present situation, the study explores the essential function of AI in molding the ability of cars to make decisions independently. This text explains the many stages of the AI-powered development process in automobiles, while also discussing the ethical concerns and potential biases that can arise in the creation of AI-driven software for autonomous vehicles. The paper provides statistical analysis of the utilization and categories of AI/learning algorithms over time, demonstrating the changing research environment in the automobile industry. Moreover, the research emphasizes the crucial significance of parameters in enhancing algorithms for both trucks and cars, enabling vehicles to adjust, acquire knowledge, and enhance their performance gradually. The text closes by delineating several degrees of autonomy, clarifying the intricate utilization of artificial intelligence and learning algorithms, and automating crucial jobs at each respective level. In addition, the study explores the differences in software package sizes among various levels of autonomy.","The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolution is the integration of Artificial Intelligence (AI) and learning algorithms, propelling vehicles into realms of unprecedented autonomy. This paper provides a comprehensive exploration of the evolutionary trajectory of AI within autonomous vehicles, tracing the journey from foundational principles to the most recent advancements. Commencing with a current landscape overview, the paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. The study presents statistical insights into the usage and types of AI/learning algorithms over the years, showcasing the evolving research landscape within the automotive industry. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI and learning algorithms, and automating key tasks at each level. Additionally, the document discusses the variation in software package sizes across different autonomy levels",1
"The development of more responsive and humane technology has placed significant emphasis on the interaction between humans and artificial intelligence (AI). Artificial empathy tactics are particularly intriguing in this context because they have the potential to enhance customer experiences in terms of emotions and social interactions. The objective of this research is to investigate how artificial empathy tactics might enhance emotive and social customer experiences, hence optimizing human-AI interactions. The research methodology employed is qualitative, involving a comprehensive analysis of multiple studies and relevant literature. The utilized data sources encompass pertinent journals, articles, and books pertaining to the research issue. The research findings indicate that incorporating artificial empathy tactics in human-AI interactions holds significant promise for enhancing the quality of interactions and customer experiences. Utilizing technologies like natural language processing, emotion identification, and sentiment analysis might enhance the ability of AI to accurately and empathetically respond to user wants and emotions.","Human-AI interaction has become an important focus in the development of more responsive and humane technology. In this context, the use of artificial empathy strategies is of particular interest due to its potential in improving customer experiences affectively and socially. This research aims to explore the optimization of human-AI interactions through the application of artificial empathy strategies in improving affective and social customer experiences. The research approach used is qualitative by reviewing various studies and related literature. The data sources used are journals, articles and books that are relevant to the research topic. From the research results, it was found that the implementation of artificial empathy strategies in human-AI interactions has great potential to improve the quality of interactions and customer experiences. The use of technologies such as natural language processing, emotion recognition, and sentiment analysis can enable AI to respond more precisely and sensitively to user needs and emotions.",1
"Empathy computing is a developing area of research that combines artificial intelligence (AI) and big data technology to forecast, detect, simulate, and produce human empathy. This discipline expands upon psychological research by exploring the concepts, measures, brain underpinnings, and practical uses of empathy. It also utilizes cutting-edge computational methods to analyze and simulate empathy. This article provides a thorough evaluation of the existing studies on empathy computing and explores its future prospects from a psychological standpoint. The objective is to support fundamental research and real-world implementations in this domain. The current research on empathy computing can be classified into four distinct themes, each focusing on different objectives and employing various methodologies. Empathy computing focuses on the analysis and understanding of empathy using computers. This undertaking can be further categorized into two distinct groups: (1) individual empathy evaluation, which centers on scrutinizing individual empathetic characteristics, and (2) empathetic content categorization, which centers on studying empathetic attributes in texts rather than individuals. Additionally, research also concentrates on the simulation and expression of empathy through computing. This encompasses the creation of empathetic response systems and the advancement of generative empathetic dialogue systems. The former offers users a restricted set of predetermined rule-based responses and feedback to convey empathy, whereas the latter use artificial intelligence to automatically develop a diverse array of sympathetic dialogues without depending on predetermined rules. These four research streams are distinct but also work well together. Furthermore, as research advances, new avenues will continue to arise, such as enhancing the empathetic abilities of computers through brain-computer interface technology. While empathy computing research is still in its nascent stages, it has demonstrated potential for groundbreaking applications in areas such as mental health, education, business services, and public management. As artificial intelligence becomes more common, fields that need a lot of human-computer contact are likely to become the key areas where this interaction takes place. Consequently, they become the primary use cases for empathy computing. Empathy computing can be utilized in the field of mental health to automatically assess and improve therapists' empathetic skills. Furthermore, it has the capability to offer individualized compassionate assistance and direction through chatbots powered by artificial intelligence. Empathy computing in education can enhance the learning process through the utilization of empathetic AI instructors. Within the commercial sector, it allows firms to provide customized customer experiences, thereby improving happiness and promoting loyalty through the creation of empathetic conversations. Empathy computing can be employed in public management to generate discourse that is empathetic in order to counterbalance negative speech. Furthermore, it enables policymakers to effectively and compassionately address the demands and inquiries of individuals, so promoting trust and confidence in the government. These four scenarios demonstrate the extensive range of possible uses for empathy computing. Nevertheless, the current impracticability of relying solely on computers to carry out sympathetic duties is mostly attributed to safety and ethical considerations. However, it is imperative to establish a partnership between humans and computers. Empathy computing serves as a groundbreaking frontier, offering not only means to quantitatively and comprehensively assess empathy on a bigger scope, but also enhancing the theoretical framework of empathy research. This study expands upon conventional research on empathy in interpersonal relationships to investigate its growing expressions in human-AI relationships. This extension presents new inquiries into the widespread existence of empathy and its possible development in human-computer interaction. Empathy computing has the potential to become a fundamental element of a comprehensive theory of empathy that includes many types of relationship dynamics, spanning from interactions between humans to interactions between humans and machines, and even more. For a thorough understanding of empathy and its effective promotion in an intelligent society, it is advantageous to concentrate future research on creating comprehensive theoretical models of empathy computing, constructing dependable datasets that encompass psychological and behavioral traits related to empathy, and validating and improving empathy computing research using a human-centered approach. Psychologists are essential in guiding, assessing, and enhancing research and practice in this subject. The partnership between researchers in psychology and computer science is crucial to guarantee that AI acquires empathy in a proficient and ethical manner, ultimately promoting the wellness of individuals in the future intelligent society.","Empathy computing is an emerging research field that integrates artificial intelligence (AI) and big data technology to predict, identify, simulate, and generate human empathy. This field builds upon psychological studies in terms of concepts, measurements, neural foundations, and applications of empathy, and employs innovative computing approaches for analyzing and simulating empathy. This article critically reviews current research on empathy computing and discusses its future directions from a psychological perspective, with the aim of facilitating foundational research and practical applications in this field.
The current research on empathy computing can be categorized into four themes based on different purposes and methods. On one hand, empathy computing primarily aims to analyze and comprehend empathy using computers. This endeavor can be further divided into two categories: (1) individual empathy assessment, which focuses on analyzing individual empathetic traits, and (2) empathetic content classification, which focuses on analyzing empathetic features in texts rather than individuals. On the other hand, research also focuses on simulating and expressing empathy through computing, which includes (3) the design of empathetic response systems and (4) the development of generative empathetic dialogue systems. The former provides users with a limited number of predefined rule-based responses and feedback to express empathy, while the latter utilizes AI to automatically generate a wide range of empathetic dialogues without relying on predefined rules. These four research streams are relatively independent yet complementary. Moreover, as research progresses, new directions will continue to emerge, such as improving the empathic capabilities of computers through brain-computer interface technology.
Although research on empathy computing is still in its early stages, it has shown potential for innovative applications in scenarios such as mental health, education, business services, and public management. With the increasing prevalence of artificial intelligence, these fields, which involve substantial interpersonal interactions, are positioned to become the primary domains for human-computer interaction. As a result, they emerge as the key application scenarios for empathy computing. In the realm of mental health, empathy computing can assist in automatically evaluating and enhancing therapists' empathetic abilities. Additionally, it can provide personalized empathetic support and guidance through AI-driven chatbots. In the field of education, empathy computing can facilitate the learning process by employing empathetic AI tutors. Within the business sector, it enables organizations to deliver tailored customer experiences, thereby enhancing satisfaction and fostering loyalty through the generation of empathic dialogues. In public management, empathy computing can be used to generate empathetic discourse to counteract negative speech. Additionally, it facilitates policymakers to respond empathetically to citizens' needs and inquiries, thereby fostering trust between the government and the public. These four scenarios illustrate the vast potential applications of empathy computing. However, due to concerns related to safety and ethics, complete reliance on computers to perform empathetic tasks is currently not feasible. Instead, a collaboration between humans and computers is necessary.
Empathy computing represents a transformative frontier, not only providing methods to measure and analyze empathy automatically on a larger scale but also enriching the theoretical landscape of empathy research. It extends traditional studies on empathy in interpersonal relationships to explore its emerging manifestations in human-AI relationships. This expansion raises novel questions about the universality of empathy and its potential evolution in human-computer interaction. Empathy computing holds the promise of serving as a cornerstone for a unified theory of empathy that encompasses diverse relationship dynamics, ranging from human-human to human-machine interactions and beyond. It is beneficial for comprehensively understanding empathy and effectively promoting it in the context of an intelligent society.
Future research should focus on developing integrated theoretical models of empathy computing, establishing reliable psychological and behavioral datasets of empathy-related characteristics, and validating and refining empathy computing research through a human-centered approach. Psychologists play indispensable roles in leading, evaluating, and optimizing research and practice in this field. The collaboration of scholars in psychology and computer science is imperative to ensure that AI learns empathy effectively and ethically, thereby fostering people’s wellbeing in the forthcoming intelligent society.",1
"This study aimed to examine the level of empathy displayed during interactions between human participants and chatbots among computer science students at Uppsala University, Sweden. This study investigated participants' perceptions of anthropomorphic chatbots as either machines or humans, the occurrence of verbal abuse in human-chatbot encounters, and the influence of gender dynamics on expectations of chatbot helpfulness. A qualitative data collection was carried out using a semi-structured interview style including five students. The data was evaluated manually using thematic analysis. The study's findings indicate that empathy exists in human chatbot interaction, irrespective of participants' perception of anthropomorphic chatbots as either humans or computers. Nevertheless, the overall level of empathy tends to be low as participants become frustrated when they are displeased with the chatbot's response. They often depart the chatbot without expressing their frustration and subsequently forget about it, returning at a later time with different queries. The study additionally demonstrates that participants anticipate greater assistance and courtesy when chatbots are more inclined to possess feminine characteristics.","This study was conducted to investigate the empathy between human chatbot interactions among computer science students at Uppsala University, Sweden. This was done by exploring how participants perceive anthropomorphic chatbots as machines or humans, the existence of verbal abuse during human chatbot interactions, and the expectation of chatbot helpfulness depending on gender dynamics. A semi-structured interview methodology with five students was conducted for qualitative data collection. The collected data was manually analyzed using thematic analysis. The results of this study found that there is empathy in human chatbot interaction, regardless of whether participants perceive anthropomorphic chatbots as humans or machines. However, the level of empathy is generally low as participants frustrate when they are dissatisfied with the response of chatbots and exit the chatbots without expressing their frustration, and they usually forget their frustration and come again with other questions another time. The study also shows that participants might expect more help and politeness if chatbots are more likely to be female.",1
"Conversational Agents (CAs), such as ELIZA and Alexa, have been intentionally created to evoke or display empathy. Empathy has the potential to enhance the ability of technology to meet human needs, yet it can also be misleading and sometimes exploitative. This study aims to define and analyze empathy in interactions with conversational agents (CAs). It emphasizes the significance of differentiating between expressions of empathy between two people and those between a human and a CA. In order to achieve this objective, we methodically stimulate conversational agents supported by extensive language models (LLMs) to exhibit empathy towards 65 unique human identities. Additionally, we analyze and contrast the many ways in which different LLMs demonstrate or simulate empathy. Our research reveals that CAs engage in subjective evaluations of certain identities and may promote identities associated with detrimental ideas, such as Nazism and xenophobia. Furthermore, a computational method for comprehending empathy demonstrates that while CAs are capable of exhibiting empathy, they struggle in accurately interpreting and investigating a user's experience, which is in contrast to human beings.","From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.",1
"Health and well-being sectors are increasingly utilizing interactive software agents, such as chatbots. In applications where agents interact with users in interpersonal discussions, such as coaching, providing comfort, or behavior-change interventions, there is a growing demand for understanding the empathetic capacities of these agents. Currently, there are no existing instruments capable of performing that task. To comprehend empathic capacities in interactive software agents, it is essential to possess a clear and exact understanding of empathy. The literature explores multiple interpretations of empathy, although a formal definition remains elusive due to the lack of unanimity. The text presents the development of a formal definition, or ontology, of empathy in interactive agents for health and well-being. This is achieved through a thorough literature survey and qualitative study of contemporary efforts. In this study, we demonstrate the efficacy of a formal definition by utilizing it as a means of evaluating empathy in two advanced health and well-being chatbots, namely Replika and Wysa. Our research indicates that our definition accurately encompasses the essential requirements for evaluating empathy in interactive agents, and how it might reveal and elucidate patterns in evolving perceptions of empathy across time. The concept, implemented in Web Ontology Language (OWL), can be used as an automated tool to enable systems to identify empathy in interactions. This can include an interactive agent evaluating its own empathetic performance or an intelligent system analyzing the empathic competence of its interlocutors.","Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors.",1
"The improvement in the capabilities of large language models (LLMs) has prompted several academics to suggest the potential development of theory of mind (ToM) in artificial intelligence (AI). LLMs possess the ability to ascribe beliefs, goals, intentions, and emotions, and they will enhance their precision over time. Instead of using the conventional human approach of empathy, they acquire the ability to ascribe mental states by identifying linguistic patterns in a dataset that usually does not involve that specific individual. We inquire whether the lack of empathy in LLMs prevents them from respecting an individual's entitlement to be treated differently, namely, from forming evaluations of character and forecasts of conduct that demonstrate suitable consideration for a person's uniqueness. Can LLMs genuinely entertain the possibility that an individual's case is distinct due to internal mental states like as beliefs, goals, and intentions, or are they constrained to evaluate the case solely based on its resemblances to others? We suggest that the use of empathy is particularly important for recognizing the right to be unique, which is separate from the importance of being able to accurately predict outcomes, in which LLMs excel. In conclusion, we examine the inherent or purely practical worth of employing empathy to examine extraordinary circumstances, and we present theoretical and observational approaches to further explore this inquiry.","Advances in the performance of large language models (LLMs) have led some researchers to propose the emergence of theory of mind (ToM) in artificial intelligence (AI). LLMs can attribute beliefs, desires, intentions, and emotions, and they will improve in their accuracy. Rather than employing the characteristically human method of empathy, they learn to attribute mental states by recognizing linguistic patterns in a dataset that typically do not include that individual. We ask whether LLMs' inability to empathize precludes them from honoring an individual's right to be an exception, that is, from making assessments of character and predictions of behavior that reflect appropriate sensitivity to a person's individuality. Can LLMs seriously consider an individual's claim that their case is different based on internal mental states like beliefs, desires, and intentions, or are they limited to judging that case based on its similarities to others? We propose that the method of empathy has special significance for honoring the right to be an exception that is distinct from the value of predictive accuracy, at which LLMs excel. We conclude by considering whether using empathy to consider exceptional cases has intrinsic or merely practical value and we introduce conceptual and empirical avenues for advancing this investigation.",1
"As AI systems grow more prevalent in our world, the likelihood of encountering contentious use cases that have a big impact on people's lives increases. Therefore, the growing problem lies in raising awareness about AI prejudice that has the potential to impact impoverished populations. In order to investigate the impact of Virtual Reality on empathy, we conducted a controlled experiment in a laboratory setting. Participants were exposed to a biased Wizard of Oz AI while assuming different personas that differed in their ability to achieve high financial credit scores based on age and gender. Our study revealed that when participants assumed different identities in virtual reality (VR), they experienced a notable increase in empathy towards the characters they embodied. Additionally, they judged the artificial intelligence (AI) as much less fair when compared to a baseline condition where they just imagined being these characters. Moreover, we analyze disparities between embodied personas and examine qualitative findings to obtain a deeper understanding of how participants develop their mental models.","In a world increasingly driven by AI systems, controversial use cases for AI that significantly affect people’s lives become more likely scenarios. Hence, increasing awareness of AI bias that might affect underprivileged groups becomes an increasing challenge. As Virtual Reality has previously been shown to increase empathy through immersive perspective-taking, we conducted a laboratory study in which participants were confronted with a biased Wizard of Oz AI while embodying personas that varied widely in their ability to achieve high financial credit scores due to their age and gender. We found that participants embodying personas in VR felt significantly more empathy toward the characters they embodied and rated the AI as significantly less fair compared to a baseline condition in which they imagined to be these characters. Furthermore, we investigate differences between embodied personas and discuss qualitative results to gain insight into the participant’s mental model creation.",1
"This study explores the complex connections between Emotional Intelligence (EI), Artificial Intelligence (AI), and Investment Decisions (ID) in the changing field of financial decision-making. Our research aims to examine how human emotional intelligence directly affects investment decisions and how artificial intelligence (AI) plays a role in moderating this process. We strive to understand the intricate relationship between human cognition and AI technology. By doing empirical study, we have discovered that EI has a direct impact on ID and also influences it indirectly through AI-mediated pathways. The results emphasize the crucial significance of emotional awareness in the decision-making process of investors, which is further enhanced by the technological capabilities of artificial intelligence (AI). It indicates that the majority of investors are swayed by the recognized emotional intelligence when making investment choices. In addition, AI has a significant influence on investors' decision-making process in the context of investing. However, AI only partially moderates the connection between emotional intelligence and investment decisions. This nuanced comprehension offers useful perspectives for financial professionals, politicians, and researchers, highlighting the necessity for comprehensive approaches that incorporate emotional and technological aspects in navigating the complexities of contemporary investment environments. This study adds to the current discussion about the mutually beneficial connection between human intuition and artificial intelligence in financial decision-making, highlighting their growing importance in investments.","In the evolving landscape of financial decision-making, this study delves into the intricate relationships among Emotional Intelligence (EI), Artificial Intelligence (AI), and Investment Decisions (ID). By scrutinizing the direct influence of human emotional intelligence on investment choices and elucidating the mediating role of AI in this process, our research seeks to unravel the complex interplay between minds and machines. Through empirical analysis, we reveal that EI not only directly impacts ID but also exerts its influence indirectly through AI-mediated pathways. The findings underscore the pivotal role of emotional awareness in investor decision-making, augmented by the technological capabilities of AI. It suggests that most investors are influenced by the identified emotional intelligence when making investment decisions. Furthermore, AI substantially impacts investors' decision-making process when it comes to investing; nevertheless, AI partially mediates the relationship between emotional intelligence and investment decisions. This nuanced understanding provides valuable insights for financial practitioners, policymakers, and researchers, emphasizing the need for holistic strategies that integrate emotional and technological dimensions in navigating the intricacies of modern investment landscapes. As the synergy between human intuition and artificial intelligence becomes increasingly integral to financial decision-making, this study contributes to the ongoing discourse on the symbiotic relationship between minds and machines in investments",1
"Empathy is a distinct ethical dimension of human conduct. The global workplace, which involves employee stakeholders, encompasses distinct behavioral and ethical factors, including the importance of human empathy. Additionally, the human elements of workplaces fall under the purview of human resources and managerial supervision in corporate companies. Human emotions and interactions are complex due to the expectations and interactions between employees and employers, as well as work practices and the results of employees' work routines. Business ethics, human resources, and risk management strategies are inherent parts of organizations. The growing comprehension of AI-driven business models highlights the necessity of examining the ethical implications of AI's effects on employees in the workplace. This study examines the ethical aspects of AI ideation, development, and deployment in business-employee relations practices. It goes beyond a compliance perspective and offers additional workplace considerations. Empathy is focused on understanding and sharing the objectives of other individuals. Therefore, it is essential to provide ethical guidelines on the role of AI in the workplace and its effects on employees. Furthermore, this study employs a cognitive perspective of empathy and specifically examines artificial morality in relation to the ethical issues, consequences, and procedures of AI advancement, implementation, and workplace protocols that could potentially affect employees across various corporate domains.","Empathy is a specific moral aspect of human behavior. The global workplace, and thereby a consideration of employee stakeholders, includes unique behavioral and ethical considerations, including a consideration of human empathy. Further, the human aspects of workplaces are within the domain of human resources and managerial oversight in business organizations. As such, human emotions and interactions are complicated by daily work related expectations, employee/employer interactions and work practices, and the outcomes of employees’ work routines. Business ethics, human resources, and risk management practices are endemic aspects within workplaces. Increasingly, the understanding of models of AI-reliant business practices underscores the need for the consideration of the ethical aspects of AI impacts on employees in the workplace. This paper explores a systematic ethical lens of the opportunities and the risks of AI ideation, development, and deployment in business-employee relations practices beyond a compliance mindset, and that introduces a further set of workplace considerations. Empathy is concerned with human intentions. As such, attributive ethical indications of the role of AI in the workplace and its impacts on employees is necessary. Moreover, this paper uses a cognitive lens of empathy and focuses on artificial morality related to the ethical concerns, implications, and practices of AI development, deployment, and workplace practices that may impact employees in a variety of business aspects.",1
"Integrating empathy into healthcare chatbots is seen as a viable approach to evoke a feeling of human warmth. Nevertheless, current research often fails to consider the multifaceted nature of empathy, resulting in a limited comprehension of whether manufactured empathy is experienced in a similar manner to interpersonal empathy. This research contends that the implementation of experiential manifestations of empathy may result in unforeseen adverse effects due to their potential inauthenticity. Alternatively, offering instrumental assistance may be more appropriate for simulating artificial empathy, as it is more compatible with computer-based frameworks used in chatbots. Two empirical investigations utilizing healthcare chatbots investigate the impact of empathetic (experiencing with), sympathetic (experiencing for), and behavioral-empathetic (empathetic aiding) versus non-empathetic responses on the perception of warmth, perception of authenticity, and their subsequent effects on trust and behavioral intentions. The findings indicate that the presence of empathy, regardless of its type, increases the perception of warmth, leading to greater trust and intention to use. As predicted, the chatbot's perceived authenticity is diminished by compassionate and sympathetic reactions, hence negating the favorable impact shown in both tests. A third study fails to reproduce this counterproductive impact in interactions between humans. This research emphasizes that empathy is not evenly distributed in human-bot interactions. It also presents the idea of 'perceived authenticity' and shows that uniquely human characteristics can have a negative effect by seeming inauthentic while interacting with chatbots.","Implementing empathy to healthcare chatbots is considered promising to create a sense of human warmth. However, existing research frequently overlooks the multidimensionality of empathy, leading to an insufficient understanding if artificial empathy is perceived similarly to interpersonal empathy. This paper argues that implementing experiential expressions of empathy may have unintended negative consequences as they might feel inauthentic. Instead, providing instrumental support could be more suitable for modeling artificial empathy as it aligns better with computer-like schemas towards chatbots. Two experimental studies using healthcare chatbots examine the effect of empathetic (feeling with), sympathetic (feeling for), and behavioral-empathetic (empathetic helping) vs. non-empathetic responses on perceived warmth, perceived authenticity, and their consequences on trust and using intentions. Results reveal that any kind of empathy (vs. no empathy) enhances perceived warmth resulting in higher trust and using intentions. As hypothesized, empathetic, and sympathetic responses reduce the chatbot's perceived authenticity suppressing this positive effect in both studies. A third study does not replicate this backfiring effect in human-human interactions. This research thus highlights that empathy does not equally apply to human-bot interactions. It further introduces the concept of ‘perceived authenticity’ and demonstrates that distinctively human attributes might backfire by feeling inauthentic in interactions with chatbots.",1
"Due to the swift advancement of artificial intelligence, a growing number of businesses are depending on the precision and effectiveness of deep learning algorithms. However, because of the incomprehensibility and opaque nature of deep neural networks, we can only receive outcomes without understanding the underlying rationale behind them. Some factions within the field of deep learning-based technologies are skeptical and resistant towards that. When it comes to emotion analysis applied in business and public opinion monitoring, decision-makers often struggle to have confidence in the results generated by computers that are supposed to be devoid of emotions, unless they are provided with an explanation. Mathematical-based explanation techniques frequently conceptualize emotion analysis as a categorization task. However, emotion should be distinguished from other kinds of tasks due to its reliance on human-specific elements and logic. This study presents a framework for explaining emotion analysis that is based on psychological theories that specifically focus on the stimulus aspect of classic emotion theories. This framework prioritizes the examination of the cause and stimulus of emotions as the rationale for deep learning-based emotion analysis. It consists of two primary elements: the extraction of the emotion cause and the visualization of words that trigger emotions.","With the rapid development of artificial intelligence, there is an increasing number of industries relying on the accuracy and efficiency of deep learning algorithms. But due to the inexplicability and black box effect of deep neural networks, we can only obtain results without knowing the applied reasoning behind them. That engenders scepticism and resistance from some quarters of deep learning-based technologies. In the context of emotion analysis used in business and public opinion monitoring, it is sometimes difficult for decision-makers to trust the outcome without explanation from the supposedly emotionless machines. There are mathematical-based explanation methods, and they often generalise emotion analysis as a classification task. Still, emotion should be different from other task categories because the generation of emotion involves human-specific factors and logic. This paper proposes an emotion analysis explanation framework that is grounded in psychological theories focusing on the stimulus from classic emotion theories. This proposed framework emphasises considering the cause and trigger of emotions as the explanation for the deep learning-based emotion analysis, and it includes two main components: the extraction of the emotion cause and the visualisation of emotion-triggering words.",1
"Artificial intelligence chatbots have become prevalent in the tourism business due to their cost-effectiveness and effectiveness. Nevertheless, academics have not devoted much attention to the impact of emotional expressions of chatbots on service outcomes. Utilizing the framework of expectation violations theory, we conducted three experiments to investigate the impact of emotional expressions displayed by chatbots on customer satisfaction. These studies were conducted within the context of providing tourist attraction suggestions. Chatbots' display of empathy towards customers might enhance customer satisfaction by minimizing instances where customer expectations are not met. Specifically, the direction of consumers towards their goals, the degree to which chatbot avatars resemble humans, and the type of relationship between customers and chatbots can influence the impact of emotional expression on expectancy violation. These findings contribute to the progress of research on the emotional expressions of chatbots and offer crucial insights for the implementation of chatbots in customer care within the tourism industry.","Artificial intelligence chatbots have invaded the tourism industry owing to their low cost and high efficiency. However, the influence of emotional expressions of chatbots on service outcomes has not received much attention from researchers. Drawing upon expectancy violations theory, we explored how emotional expressions of chatbots affect customer satisfaction using three experiments in the context of tourist attraction recommendations. Chatbots' expressions of concern for customers can improve customer satisfaction by reducing expectancy violations. In particular, customer's goal orientation, the human-likeness of chatbot's avatars, and the relationship type between customers and chatbots can moderate the negative relationship between emotional expression and expectancy violation. These findings advance research on the emotional expressions of chatbots and provide critical insights for deploying chatbots in customer service in the tourism industry.",1
"This chapter provides a comprehensive analysis of the correlation between artificial intelligence and emotions in the field of education in Latin America and the Caribbean. The PRISMA systematic review approach was employed to provide an overview of the current state of research on this topic, considering theories, methodologies, countries, and educational levels. A total of fifteen studies, which specifically concentrate on Brazil and Colombia, university-level education, students as the primary subject of analysis, and employ approaches that integrate facial recognition, psychology, and software, were ultimately chosen for publication. The aim is to enhance the depth of research in several areas by incorporating different theories and approaches.","This chapter presents a systematic review on the relationship between artificial intelligence and emotions in education in Latin America and the Caribbean. The PRISMA systematic review methodology was used to describe the state of the situation of research on this topic, taking into account theories, methodologies, countries, and educational levels. Fifteen published articles were finally selected, focusing on Brazil and Colombia, university level, students as unit of analysis, methodologies based on facial recognition, psychology and software combined. It is hoped to deepen the research in other disciplines, with other theories and methodologies.",1
"This paper presents a study that uses artificial intelligence (AI) to apply computer vision algorithms for identifying human emotions in video recordings while users interact with various visual stimuli. The objective of the research is to develop software that can detect emotions by utilizing artificial intelligence algorithms and image processing pipelines to recognize face expressions of users. The procedure entails evaluating users using visual stimuli and facilitating the application of computer vision algorithms that are in line with psychology theories that define emotions and their discernible characteristics. The study showcases the practicability of using convolutional neural networks (CNN) and software development and training methods based on facial expressions to recognize emotions. The findings emphasize the successful identification of emotions. However, in order to enhance precision, it is necessary to provide further training for settings that involve a wider range of images and to develop additional algorithms that can differentiate closely related emotional patterns. The discussion and conclusions highlight the inherent capabilities of artificial intelligence. The utilization of computer vision algorithms in emotion detection allows for valuable insights into software development, continuous training, and the dynamic nature of emotion identification technologies. Additional training is required for situations involving a wider range of photos, coupled with the development of algorithms that can accurately differentiate between facial expressions that closely resemble one other in terms of emotional patterns. This will improve the level of certainty and accuracy.","This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. The discussion and conclusions emphasize the potential of A.I. and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy.",1
"Since the 1950s, numerous clinical instances have provided evidence of the efficacy of art in rehabilitative therapy and psychiatric therapies. The progress of artificial intelligence technology has led to the development of AI painting software that utilizes the Stable Diffusion algorithm paradigm. This software allows for the production of images by using prompts and receiving feedback. Consequently, the potential of AI painting software to have a beneficial influence on human emotions is a crucial consideration for its use in art therapy. This study monitors and quantifies the emotional fluctuations in patients prior to and following their utilization of the AI painting software Stable Diffusion WebUI, employing techniques for measuring emotional lexicon. Based on the empirical evidence from this project, it has been observed that artificial intelligence painting has the ability to elicit a favorable impact on human emotions. This outcome presents a novel opportunity for the fusion of artificial intelligence and art therapy research. On one side, it enables the comprehensive advancement of specialized artificial intelligence painting software that is specifically tailored as a dedicated tool for art therapy, a type of AI software used for creative healing. Conversely, it promotes additional investigation into the efficacy of traditional painting compared to AI-assisted painting in the field of art therapy, with the goal of examining the fundamental principles and mechanisms of art therapy.","Since the 1950s, a significant number of clinical cases have confirmed the effectiveness of art in rehabilitation therapy and psychological interventions. With the advancement of artificial intelligence technology, AI painting software based on the Stable Diffusion algorithm model enables image creation through prompts and feedback. Therefore, whether AI painting software can positively impact human emotions becomes a critical factor for its application in art therapy. This study tracks and measures the emotional changes in patients before and after using the AI painting software Stable Diffusion WebUI using emotional vocabulary measurement methods. According to the experimental data of this project, artificial intelligence painting can leave a positive impression on human emotions. This result opens a new window for the integration of artificial intelligence with art therapy research. On one hand, it allows for the in-depth development of guided artificial intelligence painting software specifically designed as a dedicated tool for art therapy a form of AI software for artistic healing. On the other hand, it encourages further research into the effectiveness of traditional painting versus AI-assisted painting in art therapy, aiming to explore the underlying principles and mechanisms of art therapy.",1
"INTRODUCTION: In recent times, there has been a merging of Artificial Intelligence with neuroscience, specifically in the examination of the brain and the creation of therapies for neurological illnesses. Artificial neural networks and deep learning offer significant understanding of neural processing and brain functionality. Current study endeavors to elucidate the mechanisms by which brain processes impact an individual's subjective well-being. OBJECTIVES: To assess the correlation between neuroscience and happiness by examining the progress made in Artificial Intelligence. PROCEDURE: A bibliometric study was conducted using publications retrieved from the Scopus database between 2013 and 2023. Additionally, the VOSviewer software was employed for data processing. The study yielded a total of 603 publications, indicating that the United States (184), United Kingdom (74), and China (73) have the highest scientific output. The Co-occurrence - Author Keywords analysis produces three groups. The initial cluster, denoted by the color red, pertains to the use of Artificial Intelligence in forecasting happiness. The subsequent cluster, represented by the color green, is connected to the implementation of Artificial Intelligence tools in the field of neuroscience. Lastly, the third cluster, indicated by the color blue, is concerned with the intersection of neuroscience and psychology. CONCLUSION: Neuroscience research has made substantial advancements in comprehending mental functions such as emotions and consciousness. Neuroscience has embraced the concept of happiness and is now adopting a methodology that utilizes Artificial Intelligence to gather empirical data in order to comprehend individuals' well-being.","INTRODUCTION: In recent years, there has been a convergence between Artificial Intelligence and neuroscience, particularly in studying the brain and developing treatments for neurological disorders. Artificial neural networks and deep learning provide valuable insights into neural processing and brain functioning. Recent research tries to explain how neural processes influence an individual's happiness. OBJECTIVES: To evaluate the interaction between neuroscience and happiness based on the advances in Artificial Intelligence. METHODS: A bibliometric analysis was performed with articles from the Scopus database in 2013-2023; likewise, the VOSviewer was used for information processing. RESULTS A total of 603 articles were obtained, and it is evident that the most significant scientific production is centered in the United States (184), United Kingdom (74), and China (73). Three clusters are generated from the Co-occurrence - Author Keywords analysis. The first cluster, red, is related to Artificial Intelligence applications for predicting happiness; the second cluster, green, is associated with Artificial Intelligence tools in neuroscience; and the third cluster, blue, is related to neuroscience in psychology. CONCLUSION: Neuroscience research has made significant leaps in understanding mental processes such as emotions and consciousness. Neuroscience has encountered happiness and is opening up to an approach that seeks evidence to understand people's well-being supported by Artificial Intelligence.",1
"The endeavor to develop cognitive architectures influenced by biology, known as biologically inspired cognitive architectures (BICA), has led to substantial progress in the fields of artificial intelligence (AI) and artificial general intelligence (AGI). Nevertheless, the majority of current BICA models are deficient in incorporating a crucial element of human intelligence: emotions and feelings. This study investigates the creation and application of a cognitive architecture that incorporates emotions, replicating the way humans process emotions, within a computer framework. The Emotion-Integrated Cognitive Architecture (EICA) we propose draws inspiration from recent discoveries in cognitive psychology, neurobiology, neuroscience, and affective computing. The objective of EICA is to incorporate emotional processing into the heart of the AI system, allowing for the development of resilient, versatile, and adaptive AI agents capable of responding to intricate and ever-changing surroundings with emotional intelligence similar to that of humans. The EICA model utilizes advancements in brain imaging and recording methodologies to extract knowledge from the neurological foundation of emotions in humans. The architecture integrates systems for producing, recognizing, and regulating emotions, enabling AI entities to perceive, interpret, and react to emotions in themselves and others. We introduce the notion of EICA, outlining its modular framework and its interplay with other cognitive components. In addition, we offer case studies that demonstrate the successful integration of EICA in several AI applications, including virtual assistants and adaptive robotics. This research is a huge advancement in the computational replication of human emotional intelligence, bringing us closer to achieving the BICA Challenge. By incorporating emotions and sensations into AI systems, we come closer to fully fulfilling the potential of mutual comprehension between artificial and organic intelligences.","The pursuit of biologically inspired cognitive architectures (BICA) has driven significant advancements in artificial intelligence (AI) and artificial general intelligence (AGI). However, most existing BICA models lack a critical aspect of human intelligence: emotions and feelings. This research explores the development and implementation of an emotion-integrated cognitive architecture that mimics human emotional processing within a computational framework. Our proposed architecture, Emotion-Integrated Cognitive Architecture (EICA), is inspired by the latest findings in cognitive psychology, neurobiology, neuroscience and affective computing. EICA aims to integrate emotional processing into the core of the AI system, enabling robust, flexible, and adaptable AI agents that can respond to complex and dynamic environments with human-like emotional intelligence. The EICA model leverages advances in brain imaging and recording techniques to draw insights from the neural basis of emotions in humans. The architecture incorporates emotion-generating, recognition, and regulation mechanisms, allowing AI agents to perceive, interpret, and respond to emotions in themselves and others. We present the concept of EICA, including its modular structure and interaction with other cognitive components. We also provide case studies showcasing EICA's successful implementation in various AI applications, such as virtual assistants and adaptive robotics. This research represents a significant step towards achieving the BICA Challenge by advancing the computational replication of human emotional intelligence. By integrating emotions and feelings into AI systems, we move closer to realizing the full potential of bi-directional understanding between artificial and biological intelligences.",1
"Network news serves as a crucial means for netizens to acquire social knowledge. The abundance of news content impedes netizens from accessing crucial information. Named entity recognition technology, when applied in an artificial setting, can accurately classify information such as location names and dates inside text data. This article integrates named entity recognition and deep learning technology. More precisely, the suggested technique presents an automated method for labeling Chinese entity triggers and a Named Entity Recognition (NER) model that may attain high precision using a little amount of training data. The approach simultaneously trains sentence and trigger vectors using a trigger-matching network. The trigger vectors are then used as attention queries for future sequence annotation models. In addition, the suggested approach utilizes entity labels to accurately identify newly coined terms in web news. This allows for the modification of the set of words that are considered sensitive and the ability to adjust the number of words within that set. Furthermore, it expands the web news word sentiment lexicon, enhancing the ability to observe sentiment. The experimental results show that the suggested model performs better than the standard BiLSTM-CRF model. It achieves greater performance using only 20% of the training data set, compared to the conventional model which requires 40% of the training data set. Furthermore, the loss function curve demonstrates that my model achieves superior accuracy and faster convergence speed compared to the model being compared. Ultimately, my model attains a mean accuracy rate of 97.88% in detecting sentiment viewpoints.","Network news is an important way for netizens to get social information. Massive news information hinders netizens to get key information. Named entity recognition technology under artificial background can realize the classification of place, date and other information in text information. This article combines named entity recognition and deep learning technology. Specifically, the proposed method introduces an automatic annotation approach for Chinese entity triggers and a Named Entity Recognition (NER) model that can achieve high accuracy with a small number of training data sets. The method jointly trains sentence and trigger vectors through a trigger-matching network, utilizing the trigger vectors as attention queries for subsequent sequence annotation models. Furthermore, the proposed method employs entity labels to effectively recognize neologisms in web news, enabling the customization of the set of sensitive words and the number of words within the set to be detected, as well as extending the web news word sentiment lexicon for sentiment observation. Experimental results demonstrate that the proposed model outperforms the traditional BiLSTM-CRF model, achieving superior performance with only a 20% proportional training data set compared to the 40% proportional training data set required by the conventional model. Moreover, the loss function curve shows that my model exhibits better accuracy and faster convergence speed than the compared model. Finally, my model achieves an average accuracy rate of 97.88% in sentiment viewpoint detection.",1
"This paper conducts a preliminary investigation into the expression of emotions and the communication of information in English text. It categorizes the expression of emotions and the communication of information in English text based on the relationship between human emotions and values. Furthermore, it outlines the distinctive features of English emotion expression and information communication. Furthermore, the proposal suggests utilizing artificial intelligence technology to develop an analytical model for English text emotion and information transmission. This will be achieved by employing the BiLSTM neural network. In order to efficiently handle the attributes of English text, it is essential to encode the emotional information of the text. By utilizing the BiLSTM neural network, the emotional features of English text can be extracted and the issue of emotional feature loss can be addressed through the implementation of a loss function. Next, the crawler tool is utilized to acquire the dataset from the Chinese English module within the MOOC of Chinese universities. The evaluation indexes are established based on the model's performance, and subsequently, the English text's emotional expression and information conveyance are analyzed through experimentation. The findings indicate that the BiLSTM-based neural network outperforms the original CNN, LSTM, and T-LSTM in the task of text emotion expression and information conveyance. The accuracy rate consistently remains above 0.925. Additionally, the impact on the English dataset is slightly superior to that on the Chinese dataset. The objective of this study is to improve the instruction of the English language and facilitate effective communication between Chinese and international cultures.","This paper firstly researches English text emotion expression and information communication, classifies English text emotion expression and information communication according to the human emotion-value relationship, and summarizes the characteristics of English emotion expression and information communication. Secondly, using artificial intelligence technology, it is proposed to construct an analysis model for English text emotion and information communication using the BiLSTM neural network. To deal with the characteristics of English text quickly and efficiently, it is necessary to encode the emotional information of English text, and based on encoding, the BiLSTM neural network is applied to extract the emotional features of English text and solve the problem of the loss of emotional features through the loss function. Then, the crawler tool is used to obtain the dataset from the Chinese English module under the MOOC of Chinese universities, and the evaluation indexes are set according to the model’s performance, followed by the experimental analysis of the English text emotion expression and information conveyance. The results show that compared with the original CNN, LSTM, and T-LSTM, the BiLSTM-based neural network performs better in the task of text emotion expression and information conveyance, with the accuracy rate staying above 0.925, and the effect on the English dataset is a bit better than that on the Chinese dataset. This study aims to enhance English teaching and communication between Chinese and foreign cultures.",1
"The objective of Multimodal Emotion Recognition in Conversations (ERC) is to detect and classify the emotions expressed in each phrase inside a video of a discussion. Present endeavors face difficulties in achieving a balance between the contextual dependencies inside and across speakers while addressing interactions within the same mode. The balance described here is crucial because it includes both the modeling of self-dependency, where a speaker's own emotions impact them, and the modeling of interpersonal dependencies, where a speaker is influenced by the emotions of others. Moreover, there are difficulties in dealing with cross-modal interactions that entail content with contradictory emotions across several modalities. In order to tackle this problem, we propose the implementation of an adaptive interactive graph network (IGN) known as AdaIGN. This network utilizes the Gumbel Softmax technique to dynamically choose nodes and edges, hence improving interactions inside and across different modes. In contrast to undirected graphs, we employ a directed IGN (Interactive Graph Network) to ensure that future utterances do not influence the current one. Our proposal involves the implementation of Node- and Edge-level Selection Policies (NESP) to provide guidance for selecting nodes and edges. Additionally, we introduce a Graph-Level Selection Policy (GSP) to combine the utterance representation from the original IGN and the NESP-enhanced IGN. Furthermore, we have developed a task-specific loss function that gives priority to text modality and intra-speaker context selection. In order to decrease the computational complexity, we employ pre-determined pseudo labels generated by self-supervised techniques to conceal irrelevant utterance nodes for selection. Empirical evidence demonstrates that AdaIGN surpasses state-of-the-art techniques on two widely used datasets. The code will be accessible on the GitHub repository at https://github.com/TuGengs/AdaIGN.","Multimodal Emotion Recognition in Conversations (ERC) aims to identify the emotions conveyed by each utterance in a conversational video. Current efforts encounter challenges in balancing intra- and inter-speaker context dependencies when tackling intra-modal interactions. This balance is vital as it encompasses modeling self-dependency (emotional inertia) where speakers' own emotions affect them and modeling interpersonal dependencies (empathy) where counterparts' emotions influence a speaker. Furthermore, challenges arise in addressing cross-modal interactions that involve content with conflicting emotions across different modalities. To address this issue, we introduce an adaptive interactive graph network (IGN) called AdaIGN that employs the Gumbel Softmax trick to adaptively select nodes and edges, enhancing intra- and cross-modal interactions. Unlike undirected graphs, we use a directed IGN to prevent future utterances from impacting the current one. Next, we propose Node- and Edge-level Selection Policies (NESP) to guide node and edge selection, along with a Graph-Level Selection Policy (GSP) to integrate the utterance representation from original IGN and NESP-enhanced IGN. Moreover, we design a task-specific loss function that prioritizes text modality and intra-speaker context selection. To reduce computational complexity, we use pre-defined pseudo labels through self-supervised methods to mask unnecessary utterance nodes for selection. Experimental results show that AdaIGN outperforms state-of-the-art methods on two popular datasets. Our code will be available at https://github.com/TuGengs/AdaIGN.",1
"Tumor segmentation in breast ultrasound (US) pictures is a crucial concern in the field of medical imaging. The segmentation and categorization of abnormalities pose challenges for even experienced radiologists due to the subpar quality of US pictures and the diverse specifications of US machines. The research presents a new AI-based hybrid model for US segmentation that achieves high accuracy, uses minimal datasets, and can handle unfamiliar data. This program is suitable for performing diagnostics and conducting US-guided biopsies. An innovative and resilient hybrid methodology that integrates deep learning (DL) and multi-agent artificial life (AL) has been presented. The algorithms are validated using three datasets from the United States. The solution surpasses 14 chosen cutting-edge algorithms when applied to US photos with intricate geometry and a significant amount of noise. The research presents a novel categorization of the photos and conducts experiments to assess the boundaries of deep learning. The model has undergone training and validation using a dataset consisting of 1264 ultrasound pictures. The photos are stored in the JPEG and PNG file formats. The patients' ages span from 22 to 73 years. The set of 14 benchmark algorithms encompasses deformable forms, edge linking, superpixels, machine learning, and deep learning methodologies. The evaluations employ eight-region measures that assess shape and contour. The proposed method, DL-AL, achieves outstanding results in terms of the dice coefficient (region) and the relative Hausdorff distance H3 (contour-based). Specifically, for images with the easiest complexity level, the dice coefficient is 0.96 and the Hausdorff distance is 0.26. For images with medium complexity, the dice coefficient is 0.91 and the Hausdorff distance is 0.82. Lastly, for images with the hardest complexity level, the dice coefficient is 0.90 and the Hausdorff distance is 0.84. All other measures exhibit a consistent pattern. The DL-AL surpasses the second best method (based on Unet) by a margin of 10-20%. The approach has also undergone a range of non-traditional examinations. The model underwent training using images of low complexity and was subsequently applied to the whole dataset of images. The following is a summary of these outcomes. (1) The training process only utilized images with minimal complexity, with 68% of the images being unknown. The performance metrics for this training were a Dice score of 0.80 and an H3 score of 2.01. (2) The training process included low and medium complexity images, with 51% of them being unknown. The evaluation metrics for these images were Dice = 0.86 and H3 = 1.32. (3) The training process utilized images of several difficulty levels, including low, medium, and hard. Approximately 35% of the images used were unknown. The performance metrics for this training process were a Dice coefficient of 0.92 and an H3 score of 0.76. The tests demonstrate a notable superiority of DL-AL compared to 30%.","Segmentation of tumors in ultrasound (US) images of the breast is a critical issue in medical imaging. Due to the poor quality of US images and the varying specifications of US machines, segmentation and classification of abnormalities present difficulties even for trained radiologists. The paper aims to introduce a novel AI-based hybrid model for US segmentation that offers high accuracy, requires relatively smaller datasets, and is capable of handling previously unseen data. The software can be used for diagnostics and the US-guided biopsies. A unique and robust hybrid approach that combines deep learning (DL) and multi-agent artificial life (AL) has been introduced. The algorithms are verified on three US datasets. The method outperforms 14 selected state-of-the-art algorithms applied to US images characterized by complex geometry and high level of noise. The paper offers an original classification of the images and tests to analyze the limits of the DL. The model has been trained and verified on 1264 ultrasound images. The images are in the JPEG and PNG formats. The age of the patients ranges from 22 to 73 years. The 14 benchmark algorithms include deformable shapes, edge linking, superpixels, machine learning, and DL methods. The tests use eight-region shape- and contour-based evaluation metrics. The proposed method (DL-AL) produces excellent results in terms of the dice coefficient (region) and the relative Hausdorff distance H3 (contour-based) as follows: the easiest image complexity level, Dice = 0.96 and H3 = 0.26; the medium complexity level, Dice = 0.91 and H3 = 0.82; and the hardest complexity level, Dice = 0.90 and H3 = 0.84. All other metrics follow the same pattern. The DL-AL outperforms the second best (Unet-based) method by 10–20%. The method has been also tested by a series of unconventional tests. The model was trained on low complexity images and applied to the entire set of images. These results are summarized below. (1) Only the low complexity images have been used for training (68% unknown images): Dice = 0.80 and H3 = 2.01. (2) The low and the medium complexity images have been used for training (51% unknown images): Dice = 0.86 and H3 = 1.32. (3) The low, medium, and hard complexity images have been used for training (35% unknown images): Dice = 0.92 and H3 = 0.76. These tests show a significant advantage of DL-AL over 30%",1
"Artificial intelligence (AI) has become a powerful and influential factor in multiple industries, such as medicine and healthcare. Language models such as ChatGPT demonstrate the capabilities of AI by producing text that closely resembles human language when given cues. ChatGPT's versatility shows potential for transforming medical practices, enhancing patient care, and improving interactions between healthcare professionals, patients, and data. ChatGPT efficiently spreads crucial information in the field of pandemic management. It functions as a digital assistant during surgical consultations, assists dental offices, streamlines medical education, and aids in illness diagnostics. 82 papers were classified into eight main categories: G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and disease areas, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse, and medical images, G7: doctors and nurses, and G8: tools, devices, and administration. Striking a balance between the function of AI and human judgment continues to be a difficulty. A systematic literature review conducted using the PRISMA approach examined the transformational capabilities of artificial intelligence (AI) in healthcare. The review specifically focused on the various uses, limitations, motivation, and problems of ChatGPT in this field. Ultimately, the varied medical uses of ChatGPT highlight its capacity for groundbreaking advancements, making it an invaluable tool for students, scholars, and healthcare researchers. Moreover, this study functions as a comprehensive manual, providing support and guidance to students, scholars, and researchers in the domain of medicine and healthcare.","Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI’s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.",1
"Artificial neural networks are now seen as viable models for simulating human language processing due to their computational feasibility. One significant critique of these models is that they are trained on a far larger amount of data compared to what humans typically get during language acquisition. In this study, we employ two complimentary methodologies to investigate the impact of training data quantity on the models' capacity to accurately replicate human fMRI responses to phrases. Initially, we assess GPT-2 models that have been trained on varying amounts of words (1 million, 10 million, 100 million, or 1 billion) by comparing their performance against an fMRI benchmark. The 100-million-word model is considered developmentally credible because it is trained on a similar quantity of data that children are predicted to be exposed to throughout their first 10 years of life. Next, we evaluate the efficiency of a GPT-2 model that has been trained on a dataset containing 9 billion tokens. We want to achieve the best possible performance in predicting the next word in a sentence, as measured by a human benchmark. This evaluation is conducted at several phases throughout the training process. Both approaches demonstrate that models trained on a realistic quantity of data already attain almost optimal performance in capturing fMRI responses to phrases. In addition, a lower perplexity, which is a measure of how well a model can predict the next word, is linked to a stronger alignment with human data. This implies that models that have undergone extensive training and can accurately predict the next word also develop sentence representations that are predictive of human fMRI responses. These data demonstrate that the models' predictive power requires some training, but a realistic quantity of training, approximately 100 million words, may be sufficient.","Artificial neural networks have emerged as computationally plausible models of human language processing. A major criticism of these models is that the amount of training data they receive far exceeds that of humans during language learning. Here, we use two complementary approaches to ask how the models’ ability to capture human fMRI responses to sentences is affected by the amount of training data. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally plausible in terms of the amount of training data given that this amount is similar to what children are estimated to be exposed to during the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to reach state-of-the-art next-word prediction performance on the human benchmark at different stages during training. Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing fMRI responses to sentences. Further, (ii) lower perplexity—a measure of next-word prediction performance—is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. In tandem, these findings establish that although some training is necessary for the models’ predictive ability, a developmentally realistic amount of training (~100 million words) may suffice.",1
"This study investigates the ethical dilemmas and regulatory mechanisms around Artificial Intelligence (AI) with regards to data integrity and its impact on social dynamics. A cross-sectional survey approach was used to collect primary data from 650 AI practitioners in different sectors, including developers, data scientists, ethicists, and policymakers. The study examined the associations between regulatory compliance, ethical awareness, professional training, and expertise in AI practice with the efficacy of AI installation and data integrity. The results showed a significant and positive relationship between increased levels of adherence to regulations and the perceived success of implementing artificial intelligence. Additionally, there was a favorable association between awareness of AI ethics and the assurance of data integrity. Furthermore, a notable correlation was found between receiving professional education in artificial intelligence and the favorable influence it has on social interactions. Nevertheless, although there is a favorable relationship between experience in the AI sector and data integrity, the connection is not very strong. This suggests that having experience alone is not enough to guarantee good AI practices. The study emphasizes the significance of ethical considerations, legal frameworks, and professional training in influencing the development of AI and its impact on society. There is a strong emphasis on the requirement for regulatory frameworks that are dynamic, adaptive, and inclusive. These frameworks should be able to connect AI practices with societal values and ethical norms. Potential areas for future research involve investigating AI ethics and governance within various cultural contexts, as well as examining the influence of new technologies such as quantum computing on AI ethics.","This study examines the ethical challenges and regulatory dynamics of Artificial Intelligence (AI) in relation to data integrity and its influence on social dynamics. Employing a cross-sectional survey approach, primary data was collected from 650 AI practitioners across various sectors, encompassing developers, data scientists, ethicists, and policymakers. The study investigated the correlations between regulatory compliance, ethical awareness, professional training, and experience in AI practice with the effectiveness of AI implementation and data integrity. The findings revealed a strong positive correlation between higher levels of regulatory compliance and perceived effectiveness in AI implementation, as well as between AI ethics awareness and data integrity assurance. Moreover, a significant relationship was observed between professional training in AI and its positive impact on social dynamics. However, experience in the AI field, while positively correlated, showed a weaker link to data integrity, indicating that experience alone is insufficient for ensuring effective AI practices. The study highlights the importance of ethical considerations, regulatory frameworks, and professional training in shaping AI development and its societal implications. The need for dynamic, adaptable, and inclusive regulatory frameworks that can align AI practices with societal values and ethical norms is emphasized. Future research directions include exploring AI ethics and regulation in diverse cultural contexts and the impact of emerging technologies like quantum computing on AI ethics.",1
"The progress in artificial intelligence (AI) is leading to a growing resemblance in the way AI systems or AI-based robots perform and communicate compared to humans. The questions they pose are as follows: 1. Is it feasible to speak with, comprehend, and perhaps empathetically perceive artificial agents? Whether we should attribute genuine subjectivity and therefore quasi-personal status to them after they reach a certain level of simulation. The increasing dissolution of the distinction between simulated and real encounters will have a significant impact. In order to comprehend others, it is essential to acknowledge the subjectivity of our counterparts, which enables the experience of shared emotions and a collective intentionality. This paper argues that these factors are crucial for understanding the consequences of this phenomenon. This assumption is ultimately grounded on the underlying belief in a common way of living, referred to as ""conviviality."" The potential for future artificial agents to fulfill these requirements is disproven based on the principles of embodied and enactive cognition, which connect subjectivity and consciousness to the vitality of an organism. Even if subjectivity is fundamentally unattainable for artificial agents, the differentiation between simulated and genuine subjectivity may still become less clear. In this discussion, we specifically examine potential outcomes, with a particular focus on the utilization of virtual psychotherapy as an illustrative case. Ultimately, the study argues in favor of adopting a thoughtful approach when discussing artificial systems and emphasizes the importance of avoiding a deliberate pretense of subjectivity.","Advances in artificial intelligence (AI) create an increasing similarity between the performance of AI systems or AI-based robots and human communication. They raise the questions:
1. whether it is possible to communicate with, understand, and even empathically perceive artificial agents;
2. whether we should ascribe actual subjectivity and thus quasi-personal status to them beyond a certain level of simulation;
3. what will be the impact of an increasing dissolution of the distinction between simulated and real encounters.
(1) To answer these questions, the paper argues that the precondition for actually understanding others consists in the implicit assumption of the subjectivity of our counterpart, which makes shared feelings and a we-intentionality possible. This assumption is ultimately based on the presupposition of a shared form of life, conceived here as �conviviality.�
(2) The possibility that future artificial agents could meet these preconditions is refuted on the basis of embodied and enactive cognition, which links subjectivity and consciousness to the aliveness of an organism.
(3) Even if subjectivity is in principle impossible for artificial agents, the distinction between simulated and real subjectivity might nevertheless become increasingly blurred. Here, possible consequences are discussed, especially using the example of virtual psychotherapy. Finally, the paper makes case for a mindful appproach to the language we use to talk about artificial systems and pleads for preventing a systematic pretense of subjectivity.",1
"This article explores the recent progress and growing media coverage of artificial intelligence. Eliezer Yudkowsky, a prominent player in the field of artificial intelligence alignment, is dedicated to bridging the gap between public views and rationalist viewpoints on artificial intelligence technology. This analysis examines his anticipated plan of action for artificial intelligence as described in his unpublished document titled ""AGI Ruin: A List of Lethalities."" This is accomplished by striving to comprehend the notion of intelligence itself and establishing a practical and logical definition of that concept. The concept of intelligence is then employed to analyze the relevance of modern artificial intelligence capabilities and advancements to these technologies. This study concludes that current artificial intelligence systems possess a certain degree of intelligence. Nevertheless, it contends that artificial intelligence systems, whether weak or strong, that lack human-defined objectives, would not inherently present existential risks to humanity. This challenges the concept of aligning artificial intelligence and raises doubts about the validity of Nick Bostrom's Orthogonality Thesis. Moreover, the potential for generating synthetic life by combining several modules, each simulating a distinct cognitive function, is being examined.","This paper navigates artificial intelligences recent advancements and increasing media attention. A notable focus is placed on Eliezer Yudkowsky, a leading figure within the domain of artificial intelligence alignment, who aims to bridge the understanding gap between public perceptions and rationalist viewpoints on artificial intelligence technology. This focus analyzes his predicted course of action for artificial intelligence outlined within his unpublished paper AGI Ruin: A List of Lethalities. This is achieved by attempting to understand the concept of intelligence itself and identifying a reasonable working definition of that concept. The concept of intelligence is then applied to contemporary artificial intelligence capabilities and developments to understand its applicability to the technologies. This paper finds contemporary artificial intelligence systems are, to some extent, intelligent. However, it argues that both weak and strong artificial intelligence systems, devoid of human-defined goals, would not inherently pose existential threats to humanity, challenging the notions of artificial intelligence alignment, bringing into question the validity of Nick Bostroms Orthogonality Thesis. Furthermore, the possibility of artificial life created through the method of assembling various modules each emulating a separate mind function is discussed.",1
"The remarkable powers of living beings stem from the manner in which their bodies manifest autonomy. Living organisms integrate computational or cognitive intelligence with physical intelligence by means of body morphology, material multifunctionality, and mechanical compliance, at various levels of organization. Although soft robotics has made progress in developing and creating physically intelligent bodies, including information-processing abilities for computational intelligence is still difficult. Hence, the construction of soft robots is now restricted by limits in perception and control. Achieving complete independence in autonomy would necessitate a purposeful alignment in the joint development of novel materials, manufacturing techniques, and control strategies for soft robots. Here, a novel viewpoint is proposed: researchers should only employ tasks to impose limitations on the design of soft robots, namely in terms of materials and information. A proposed conceptual framework introduces a task-first design paradigm that bypasses limits imposed by control mechanisms. This framework enables the efficient utilization of the combined material and information processing abilities of soft matter for the creation of agents capable of performing specific tasks. Special emphasis is given to the scale dependency of solutions. Lastly, this article discusses potential research prospects for attaining autonomy in upcoming soft robots, ranging in size from elephant trunks to paramecia.","The impressive capabilities of living organisms arise from the way autonomy is materialized by their bodies. Across scales, living beings couple computational or cognitive intelligence with physical intelligence through body morphology, material multifunctionality, and mechanical compliance. While soft robotics has advanced the design and fabrication of physically intelligent bodies, the integration of information-processing capabilities for computational intelligence remains a challenge. Consequently, perception and control limitations have constrained how soft robots are built today. Progress toward untethered autonomy will require deliberate convergence in how the field codevelops new materials, fabrication methods, and control strategies for soft robots. Here, a new perspective is put forward: that researchers should use tasks alone to impose material and information constraints on soft robot design. A conceptual framework is proposed for a task-first design paradigm that sidesteps limitations imposed by control strategies. This framework allows emergent synergies between material and information processing properties of soft matter to be readily exploited for task-capable agents. Particular attention is paid to the scale dependence of solutions. Finally, an outlook is presented on emerging research opportunities for achieving autonomy in future soft robots as large as elephant trunks and as small as paramecia.",1
"This paper introduces the concept of self-reproduction in Artificial Life and its application to computer animation. An Artificial Fish model that can reproduce itself, based on gene control, is proposed and constructed. The chromosome of the Artificial Fish contains the genetic information that determines its phenotype. According to this paradigm, hereditary rules are provided. Artificial Fish have the ability to reproduce and grow inside a virtual marine environment that is under the precise control of a gene model and set of regulations. Artificial behaviors encompass both predetermined behaviors and indeterminate behaviors. Artificial Intelligence-based cognitive models are proposed and developed to regulate the actions of artificial fish at a high level. The simulation program is created using the models provided earlier. These efforts laid the foundation for enhancing the efficiency and automation of artificial fish animation.","In this paper, Self-Reproduction characteristic of Artificial Life is introduced to computer animation. A Self-Reproduction model of Artificial Fish based on gene control is put forward and built. Based on Artificial Fish's phenotype, the contents of its chromosome are given. Based on this model, heredity rules are given. Artificial Fish could reproduce and grow in the virtual marine environment freely controlled by the gene model and rules. Artificial behaviors include predefined behaviors and nondeterminate behaviors. Cognitive models based on Artificial Intelligence is put forward and built to control behaviors of artificial fish in high level. Simulation program is designed and developed based on all these models built above. These made groundwork to improve the efficiency and automatic level of artificial fish animation.",1
"This paper explores the ideas of ""Life,"" ""Artificial Life,"" and ""Generalized Artificial Life,"" as well as the question of whether Artificial Life can be considered actual Life.","In this paper, the concepts of ""Life"", ""Artificial Life"" and ""Generalized Artificial Life"" and the problem ""Is Artificial Life true Life?"" are discussed.",1
"This study presents an experiment including the utilization of an Artificial Life competitive game to replicate an environment for teaching Artificial Intelligence (AI) to computer science engineering students in an unstructured and informal manner. The game has a virtual Petri dish in which two colonies of microorganisms, represented as software agents, must compete for survival. In order to accomplish this objective, the participants must employ survival tactics for their agents, which encompass combat methods and fundamental reproduction guidelines to overcome the entire artificial environment. The contest's technical foundations and the artificial life model's description are provided in thorough detail. This text discusses the pedagogical experience gained from developing the contest, as well as the resulting learning experience. The learning experience has produced enthusiasm among students and has aided in the construction of mental models for potential AI algorithms.","This work reports an experience in using an Artificial Life competitive game that simulates an artificial life environment for unstructured and informal Artificial Intelligence (AI) teaching to students from computer science engineering careers. The game consists of a simulated Petri dish where two colonies of microorganisms-software agents-must struggle to survive. To achieve this goal, the participants must implement surviving strategies for their agents, which include fighting strategies and basic reproduction rules to prevail over all the artificial environment. The technical bases of the contest as well as a description of the artificial life model are explained in detail. The pedagogical experience acquired in the contest development is discussed, as well as the resulting learning experience, which generated students enthusiasm and has helped them to develop mental models of possible AI algorithms.",1
"Fuzzy logic is a highly effective method for optimizing power flow solutions, especially in the setting of deregulated power systems. The use of fuzzy logic controls allows for the determination of the optimal location of distribution generators (DGs), guaranteeing that reliability indices are recognized through optimal power flow solutions and fuzzy logic controllers to preserve system feasibility. Strategically positioning distribution generator units is vital in a deregulated power system to minimize power loss and improve overall system performance by reducing volatility. In a deregulated power system, it is crucial to have access to optimal power flow algorithms in order to detect areas of vulnerability, particularly within transmission companies. Both the transmission and distribution networks should be suitably modified to minimize congestion within their respective organizations. The aggregator is responsible for evaluating the efficiency of the electricity system by analyzing data provided by distribution and transmission businesses operating within the deregulated power system.","﻿Fuzzy logic emerges as a powerful tool for optimizing power flow solutions, particularly in the context of deregulated power systems. By employing fuzzy logic controls, the ideal placement of distribution generators (DGs) can be determined, ensuring the reliability indices are identified through optimal power flow solutions and fuzzy logic controllers to maintain system feasibility. In a deregulated power system, strategic placement of distribution generator units plays a crucial role in minimizing power loss and enhancing overall system performance by mitigating fluctuations. To identify areas of weakness, especially within transmission companies, accessing optimal power flow algorithms becomes essential in a deregulated power system. Both transmission and distribution networks should be appropriately adjusted to alleviate congestion within the respective companies. The aggregator must assess system performance, utilizing data obtained from distribution and transmission companies within the deregulated power system.",1
"This article examines the factors that contribute to technological disruptions in electrical systems and emphasizes various inherent drawbacks of protecting and automating components of electrical systems. The decline in the reliability of relay protection due to the shift from analog to digital protection systems is justified. The justification for employing fuzzy logic in protection systems is supported by the analysis of investigated examples. The practicality of incorporating fuzzy logic elements in protection devices and the automation of electrical systems for identifying different forms of short circuits are also substantiated. This article examines the prevalent forms of damage and shows the findings of simulating an electrical system with transformer coupling, in which various forms of asymmetrical short circuits were initiated. The behavior of the symmetrical components of short-circuit currents in the forward, reverse, and zero sequences is analyzed to understand their dynamics. Guidelines have been established to identify asymmetrical types of short circuits. A protection and automation operating algorithm utilizing fuzzy logic features has been created. The proposed algorithm for protection and automation will decrease the time required to identify the nature of the harm and activate protective measures.","﻿In this article, the causes of technological disturbances in electrical systems are considered, and several characteristic disadvantages of the protection and automation of elements of electrical systems are highlighted. The tendency to decrease the reliability of relay protection associated with the transition from analog to digital types of protection is substantiated. Based on the studied examples, the use of fuzzy logic in protections, the expediency of using fuzzy logic elements in protection devices, and the automation of electrical systems to identify types of short circuits are justified. This article analyzes the most common damages and presents the results of modeling an electrical system with transformer coupling, where all types of asymmetric short circuits were initiated. The dynamics of changes in the symmetrical components of short-circuit currents of the forward, reverse, and zero sequences are determined. Rules have been created for the identification of asymmetric types of short circuits. An algorithm of protection and automation operation using fuzzy logic elements has been developed. The proposed algorithm of protection and automation will reduce the time to determine the type of damage and trigger protections.",1
"The process of quantifying the usability expectation for an m-commerce mobile application using fuzzy logic principles involves testing the usability of the application. The usability of a mobile application is determined by assessing the user's expectations and preferences to assess their experience with the program. Fuzzy logic is consistently the most advantageous option for quantification. The usability expectation of an m-commerce mobile application is assessed using a fuzzy logic-based quantification method. This assessment considers the user's needs, preferences, and expectations to evaluate their overall user experience. Usability expectation encompasses the user's capacity to comprehend and engage with the application, the extent to which the application fulfills the user's expectations, and the overall level of happiness with the application. This technique facilitates the identification of areas that require improvement, allowing developers to implement essential modifications to enhance the user experience. This study introduces a framework for measuring usability and applies fuzzy logic to quantify the overall usability quality of an m-commerce mobile application. The proposed framework for measuring usability is founded on the Goal-Question-Metric (GQM) methodology. Its purpose is to offer a thorough and methodical method for designing metrics that evaluate the qualitative element of mobile phone applications. The framework has been created and evaluated in the context of mobile commerce (m-commerce) and offers a collection of quantifiable criteria to measure the quality of mobile applications for m-commerce according to a standard. The evaluation results can be utilized to enhance m-commerce mobile applications and guarantee the optimization of the user experience.","﻿Fuzzy logic-based quantification of usability expectation for an m-commerce mobile application is a process of measuring the usability of a mobile application by using fuzzy logic principles. The usability of any mobile application is used to find out the user experience of the mobile application by analyzing the user's expectations and preferences. Fuzzy logic always be the optimal choice for quantification. Fuzzy logic-based quantification of usability expectation assesses the user experience of an m-commerce mobile application by taking into account the user's needs, preferences, and expectations. Usability expectation also takes into account the ability of the user to understand and interact with the application, the degree to which the application meets the user's expectations, and the overall satisfaction with the application. This process helps to identify areas of improvement, enabling the developers to make necessary changes for a better user experience. This study presents to design of a usability metric framework and then quantifies the overall usability quality of an m-commerce mobile application with the help of fuzzy logic. The proposed usability metric framework is based on the Goal-Question-Metric (GQM) approach and is intended to provide a comprehensive and systematic approach to design metrics to assess the qualitative aspect of mobile phone applications. The framework has been developed and tested in an m-commerce context and provides a set of measurable criteria to quantify m-commerce mobile applications as per standard. The results of the evaluation can then be used to improve m-commerce mobile applications and to ensure that the user experience is optimized",1
"The performance of photovoltaic (PV) systems is directly influenced by changes in climate. The controller ensures that the maximum potential energy is converted to operate the pumping system under normal conditions. Fuzzy logic intelligent controllers have proven to be effective and applicable in engineering and applied science. This paper aims to demonstrate an experimental method for implementing fuzzy logic maximum power point tracking (MPPT) with a boost converter based on the Arduino Mega micro-controller. The objective is to maximize energy production in various weather conditions for a small-scale pumping system used in water and chemical fluid analysis in isolated areas. The system is equipped with a set of 20 solar photovoltaic (PV) panels, each with a power output of 20 watts (W). This work introduces a real-time approach for regulating and monitoring Maximum Power Point Tracking (MPPT) using MATLAB/Simulink and fuzzy logic. The method utilizes a low-cost Arduino Mega micro-controller and (LV25, LP55) sensors to operate a boost converter coupled to a solar panel and plastic pump.","﻿The performance of photovoltaic (PV) affected directly by climatic changes, The controller maintain maximum potential energy conversation to operate the pimping system at nominal conditions, fuzzy logic intelligent controllers are successfully suitable and applicable in engineering and applied science. The aim of this paper is present an experimental approach in Implementation of fuzzy logic maximum power point tracking (MPPT) with boost converter based on Arduino Mega micro-controller to maximize energy production in different weather condition applied to small scale pumping system for water and chemical fluid analyses in isolated area. The system is supplied by 20 (W) solar photovoltaic (PV) panel. This paper present a real-time MATLAB/Simulink fuzzy logic method controlling and monitoring MPPT application using an low cost Arduino Mega micro-controller combined with (LV25, LP55) sensors controlling boost converter interconnected with solar panel and plastic pump.",1
"This paper utilizes a fuzzy logic controller (FLC) to examine voltage stability in a photovoltaic (PV)-based direct current (DC) microgrid. The microgrid consists of many photovoltaic (PV) modules, a DC-DC converter, and various loads. Ensuring voltage stability in DC microgrids is a challenging task due to the extensive utilization of intermittent PV power. This paper presents a voltage control technique based on Fuzzy Logic Control (FLC). The technique utilizes input elements such as photovoltaic (PV) output power, duty cycle of the DC-DC converter, and load current to determine the most suitable action for maintaining the stability of the system's voltage. The performance of the FLC is evaluated by simulation, with the objective of ensuring its resilience to parameter changes and uncertainties. The simulation findings indicate that the proposed FLC-based control technique effectively preserves the voltage stability of the microgrid in several operational scenarios, such as fluctuations in solar irradiance and load variations. Furthermore, the FLC exhibits superior performance compared to alternative control approaches.","﻿This article employs a fuzzy logic controller (FLC) to investigate voltage stability in a PV-based DC microgrid. Several photovoltaic (PV) modules, a DC-DC converter, and loads make up the microgrid. Due to the widespread use of intermittent PV power, voltage stability is a crucial problem for DC microgrids and is difficult to accomplish. This study proposes an FLC-based voltage control technique that leverages input factors including PV output power, DC-DC converter duty cycle, and load current to identify the best course of action for preserving the system's voltage stability. The FLC's performance is assessed by simulation, and it is meant to be resilient to parameter fluctuations and uncertainties. The simulation results demonstrate that the suggested FLC-based control strategy successfully maintains the microgrid's voltage stability under a variety of operational circumstances, including changing solar irradiance and load variations. Moreover, the FLC performs better than other control methods.",1
"This study explores the complexities of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems that are defined by unlimited actuator faults and range limits. In order to tackle these problems, we make use of fuzzy logic systems (FLSs) and utilize adaptive techniques to estimate unfamiliar nonlinear functions and uncertain parameters that exist in robotic dynamics. During the process of exploring information, the challenges of avoiding collisions and maintaining connectedness are constantly present because of constraints in distance and visual perception. To address confined range obstacles effectively, we present a comprehensive barrier function and prescribed performance approach. In addition, robots minimize the number of controller executions and address any impact caused by infinite actuator failures by communicating with their leader when actuator faults occur. This communication is done using fewer network resources, while still ensuring uninterrupted tracking of the desired trajectory set by the leader. Using dynamic surface technology, we provide a decentralized adaptive event-triggering fault-tolerant (ETFT) formation control technique. All signals are guaranteed to be semi-global uniformly ultimately bounded (SGUUB). In conclusion, we prove the practical possibility of implementing the ETFT control approach for nonholonomic multirobot systems.","﻿This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. In this regard, we introduce a general barrier function and prescribed performance methodology to tackle constrained range impediments effectively. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. With the aid of the dynamic surface technology, we propose a decentralized adaptive event-triggering fault-tolerant (ETFT) formation control strategy. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems.",1
"Fuzzy inference systems (FISs) have been developed over an extended period, although employing FISs for high-dimensional issues remains a formidable undertaking. The most commonly employed T-norms for calculating the firing strengths are the product and minimum operators, with the former being favored due to its differentiability. However, in the case of high-dimensional issues, the product T-norm is susceptible to the issue of numeric underflow. Our main goal is to address the issue related to the utilization of T-norms in the construction of high-dimensional Fuzzy Inference Systems (HDFISs). To address the issue of numeric underflow, we create an HDFIS (Hierarchical Decision Fuzzy Inference System) called HDFIS-prod, specifically designed for the T-norm product operation. The primary innovation is in our proposal of an adaptive dimension-dependent membership function (DMF). Based on empirical observation, we have developed a technique called HDFIS-min that effectively handles super high-dimensional issues by utilizing the minimum T-norm. Both HDFIS-prod and HDFIS-min undergo testing on 18 datasets, with feature dimensions ranging from 1024 to 120450. The simulation findings indicate that both of them exhibit comparable performance in managing datasets with a large number of dimensions.","﻿Fuzzy inference systems (FISs) have been developed for many years but the use of FISs for high-dimensional problems is still a challenging task. The most frequently used T-norms for computing the firing strengths are product and minimum operators of which the former is often preferred because of its differentiability. However, for high-dimensional problems, the product T-norm suffers from the numeric underflow problem. Here, we primarily focus on addressing the problem that is associated with the use of the T-norms for designing high-dimensional FISs (HDFISs). For the product T-norm, we construct an HDFIS named HDFIS-prod, which easily escapes from the numeric underflow problem. The main novelty is that we propose an adaptive dimension-dependent membership function (DMF). For the minimum T-norm, an empirical observation led us to develop a mechanism that has the natural ability to deal with super high-dimensional problems, which results in another HDFIS named HDFIS-min. Both HDFIS-prod and HDFIS-min are tested on 18 datasets with feature dimensions varying from 1024 to 120450. The simulation results demonstrate that both of them have competitive performance on handling high-dimensional datasets.",1
"This article explores a solution to address the significant challenges associated with controlling induction machines, with the aim of achieving exceptional dynamic performance. Conventional direct torque control and indirect control with flux orientation suffer from certain limitations, including the presence of current harmonics, torque ripples, flux ripples, and extended rising time. This article presents a comparison analysis of earlier methodologies and the one that use fuzzy logic. The simulation results demonstrate that the utilization of fuzzy logic in the direct torque control approach yields superior performance by delivering accurate and rapid responses without any overshooting. Additionally, it effectively reduces fluctuations in both torque and flux at low switching frequencies. The showcased enhancements in dynamic performance enhance operational efficiency and reliability in industrial applications.","﻿This article examines a solution to the major problems of induction machine control in order to achieve superior dynamic performance. Conventional direct torque control and indirect control with flux orientation have some drawbacks, such as current harmonics, torque ripples, flux ripples, and rise time. In this article, we propose a comparative analysis between previous approaches and the one using fuzzy logic. Results from the simulation show that the direct torque control method using fuzzy logic is more effective in providing a precise and fast response without overshooting, and it eliminates torque and flux fluctuations at low switching frequencies. The demonstrated improvements in dynamic performance contribute to increased operational efficiency and reliability in industrial applications.",1
"The primary objective of this paper is to justify the methodological approach to evaluating personnel risks in enterprises by utilizing the fuzzy logic framework. This approach aims to identify issues related to personnel risk management and offer suitable recommendations for their resolution. The study is grounded on the established principles and essential works of both foreign and domestic scientists, statistical data, and our own research findings on the evaluation of human hazards in organizations. The study included many techniques including fuzzy set theory, comparative analysis, scientific abstraction, generalization of scientific experience, and a systematic and comprehensive methodology. The study presented a methodological methodology for evaluating the extent of people hazards in a company. Numerical experiments were carried out using a cohort of construction equipment manufacturers. The analysis of the results from assessing the level of personnel risks at enterprises has revealed the issues in managing personnel risks. The study focuses on hierarchical fuzzy data, specifically four groups of indicators for assessing the level of personnel risks: quantitative composition (F1), state of qualifications and intellectual potential (F2), staff turnover (F3), and motivational system (F4). Each indicator has a varying number of fuzzy coefficients, with twelve coefficients considered in this study (vi, i=1÷12). The indicators are defined as functions of fuzzy coefficients. F1 is determined by the values of v1, v2, and v3. F2 depends on the values of v4, v5, v6, and v7. F3 is calculated based on the values of v8, v9, and v10. Finally, F4 is determined by the values of v11 and v12. The output variable, Int, represents the personnel risk level and is determined by a functional relationship with the input variables F1, F2, F3, and F4. The personnel risk level is also expressed as a fuzzy value. The functions r, g, h, q, and f are unspecified functions of the provided variables. We possess proficient assessments of the modification in every input data, often categorized into three levels: Low (I), Medium (G), and High (E). The formalized information for each variable can be expressed as follows: . For a set of indicators, we can then state: . To utilize a fuzzy system and do computations using it, the system must possess the following structural components: membership functions for input and output variables, a rule base, and an output mechanism. The structural elements refer to the constituent parts that will be constructed during the construction of a fuzzy system. The developed mathematical model and its formalization using FST allow for the estimation of personnel risk levels at the firm, facilitating the justification of a range of measures to enhance its utilization efficiency. The developed fuzzy logical inference system can be regarded as intelligent since it incorporates components of computational intelligence, specifically the theory of fuzzy sets. The proposed methodology for evaluating personnel risks in enterprises, using fuzzy logic, offers a unique advantage over existing methods. It allows for the integration of both qualitative and quantitative indicators when assessing personnel risks and movement, leading to more effective decision-making in uncertain situations and reducing costs in adverse scenarios.","﻿The main idea of this paper is the substantiation of the methodological approach to the assessment of personnel risks of enterprises based on the application of the fuzzy logic apparatus in order to identify the problems of personnel risk management and provide appropriate recommendations for their solution. The methodological basis of the study is the classic provisions and fundamental works of foreign and domestic scientists, statistical data, the results of our research into the problems of assessing personnel risks of enterprises. The methods of fuzzy set theory, comparative analysis, scientific abstraction, generalization of scientific experience of modern theoretical research, systemcomplex approach were used. The study proposed a methodological approach to assessing the level of personnel risks of an enterprise; numerical experiments were conducted on the basis of a group of construction equipment manufacturers. Analysis of the results of assessing the level of personnel risks of enterprises made it possible to identify the problems of managing personnel risks at enterprises Statement of a mathematical problem: the work considers hierarchical fuzzy data, namely: four groups of indicators for assessing the level of personnel risks (quantitative composition – F1, state of qualifications and intellectual potential – F2, staff turnover – F3, motivational system – F4), each of the indicators has a different number of fuzzy coefficients (there are twelve of them in the current work – vi , i=1÷12). Indicators are functions of fuzzy coefficients: F1 = r(v1, v2, v3); F2 = g(v4,v5, v6, v7); F3 = h(v8, v9, v10,); F4=q(v11, v12). As an output variable, there is a functional – an integrated indicator Int = f(F1, F2, F3, F4) of the personnel risk level, which, in turn, is also a fuzzy value. Here, the functions r, g, h, q, f are unknown functions of the given variables. We have expert evaluations of the change in all input data; as a rule, they vary within three terms: Low (I), Medium (G), High (E). Formalized information on each variable can be written as , then for a group of indicators we have: . Using a fuzzy system and performing calculations with its help requires the system to have the following structural elements: membership functions of input and output variables, a rule base, and an output mechanism. These structural elements are the components that will be built when designing a fuzzy system. The built mathematical model and the method of its formalization on the basis of FST make it possible to estimate the level of personnel risk at the enterprise, which enables further substantiation of a set of measures to increase the efficiency of its use. The constructed system of fuzzy logical inference can be considered intelligent as it uses elements of computational intelligence, in particular, the theory of fuzzy sets. The proposed methodological approach to assessing the level of personnel risks of enterprises based on the apparatus of fuzzy logic allows, in contrast to existing ones, to integrate the consideration of both qualitative and quantitative indicators when assessing the level of personnel risks and personnel movement indicators and to significantly increase the efficiency of decision-making under conditions of uncertainty and reduce costs in the event of adverse situations.",1
"Real-world objects exhibit random perturbations that negatively impact the control process. To address this issue, modern methods of intelligent technology are used to design control systems for complex dynamic objects. These methods aim to compensate for the effects of external factors that possess random and partially uncertain properties. The paper discusses the synthesis of automatic control systems for dynamic objects using intelligent control theory. In this scenario, a neural network that relies on radial-basis functions is employed at every distinct interval to approximate the control system using neuro-fuzzy techniques. This enables the regulator settings to be adjusted in real-time. The radial basis function is specifically designed to provide an approximation for functions that are defined in the implicit form of pattern sets. The parameter configuration of the neuro-fuzzy regulator is achieved by the utilization of a genetic algorithm, which allows for more efficient calculation in order to determine the set parameters of the regulator. The parameters of the regulator are expressed as a vector, which makes it easier to apply them to objects with many dimensions. A evolutionary algorithm was employed to identify the ideal tuning parameters of the neuro-fuzzy regulator, which is known for its strong convergence and ability to detect global extrema. The neuro-fuzzy regulator is effective because it can provide quality control for a dynamic object even when there are random disturbances and ambiguity in the input data.","﻿Real-acting objects are characterized by the presence of various types of random perturbations, which significantly reduce the quality of the control process, which determines the use of modern methods of intellectual technology to solve the problem of synthesis of control systems of structurally complex dynamic objects, allowing to compensate the influence of external factors with the properties of randomness and partial uncertainty. The article considers issues of synthesis of the automatic control system of dynamic objects by applying the theory of intelligent control. In this case, a neural network based on radial-basis functions is used at each discrete interval for neuro-fuzzy approximation of the control system, allowing real-time adjustment of the regulator parameters. The radial basis function is designed to approximate functions defined in the implicit form of pattern sets. The neuro-fuzzy regulator's parameter configuration is accomplished using a genetic algorithm, enabling more efficient computation to determine the regulator's set parameters. The regulator's parameters are represented as a vector, facilitating their application to multidimensional objects. To determine the optimal tuning parameters of the neuro-fuzzy regulator, characterized by high convergence and the possibility of determining global extrema, a genetic algorithm was used. The effectiveness of the neuro-fuzzy regulator is explained by the possibility of providing quality control of the dynamic object under random perturbations and uncertainty of input data.",1
"Convenient internet access and rapid technological progress have led to an overwhelming amount of information and a wide range of choices, which has made decision-making highly challenging. A Recommender System (RS) is a promising system that aids users in decision-making by providing recommendations or predictions for product ratings. There are three primary types of RS that utilize either implicit or explicit feedback for recommendation: collaborative filtering, content-based filtering, and hybrid filtering. Ratings are a prevalent type of feedback, but product descriptions, reviews, photographs, audios, and videos are equally significant and can enhance the effectiveness of the conventional RS. These supplementary variables can greatly influence the performance of RS. Previously, traditional recommendation systems (RSs) relied on methods such as nearest neighbor or other machine learning models. However, with recent advancements in artificial intelligence and deep learning, RSs are now being created utilizing Convolutional Neural Networks (CNN). CNNs are able to effectively utilize additional information. This article not only compares CNN-based recommendation systems (RSs) based on common criteria, but also thoroughly explores the utilization of different types of auxiliary information in CNN-based RSs. The study also examines the attributes of the data, statistical information about the data, and additional supporting details found in various datasets that are accessible to the public. The paper also examines several assessment metrics for recommendation systems and presents readers with intriguing problems and ongoing research topics.","Easy internet access and technological advancements have resulted in information overload and a plethora of options, making decision-making extremely difficult. Recommender System (RS) is a potential solution for assisting users in making decisions by recommending or predicting product ratings. Three fundamental forms of RS that use implicit or explicit feedback for recommendation are collaborative, content-based, and hybrid filtering. Ratings are the most common form of feedback, but product descriptions, reviews, images, audios, and videos are also important and can help improve the performance of the traditional RS. These additional variables can have a significant impact on RS’s performance. Traditional RSs used approaches based on the nearest neighbor or other machine learning models, but thanks to recent advances in artificial intelligence and deep learning, RSs are now being developed using Convolutional Neural Networks (CNN), which can efficiently exploit auxiliary information. In addition to comparing CNN-based RSs on common grounds, this article provides a full examination of CNN-based RSs and how they might use various types of auxiliary information. The study also discusses data characteristics, data statistics, and auxiliary information in a variety of publicly available datasets. Different evaluation measures for RSs are also discussed, and readers are provided with interesting challenges and open research issues.",1
"Recently, due to the rapid advancements in science and technology, particularly in artificial intelligence and machine algorithms, the education system has started incorporating more tailored content in addition to its traditional roles. Conventional education systems frequently employ a standardized teaching method that fails to consider the distinct requirements and learning preferences of individual students. A machine learning-based education system can offer tailored learning materials and suggestions by analyzing individual students' learning history, interests, and abilities. This personalized approach aims to enhance learning outcomes. Additionally, machine learning algorithms can provide immediate feedback on student performance and adapt learning plans accordingly. This enhances the learning process by making it more dynamic and tailored to individual needs. Consequently, it can be utilized in all educational domains, encompassing language acquisition, mathematics, science, and so on. Enhancing the effectiveness of machine learning algorithms mostly relies on the enhancement of numerical optimization algorithms. Therefore, it is imperative to consolidate the optimization algorithms used in large-scale machine learning. This work aims to provide a comprehensive analysis of the current machine learning algorithms used in optimizing personalized education recommendation systems. It also presents the process of optimizing these algorithms.","In recent years, with the continuous progress and development of science and technology, especially the continuous development of artificial intelligence, machine algorithm and other technologies, the education system has also begun to carry out more personalized content from traditional functions. Traditional education systems often adopt a one-size-fits-all approach to teaching that does not take into account the unique needs and learning styles of each student. An education system personalized and optimized by machine learning algorithms can provide customized learning materials and recommendations based on each student's learning history, interests and abilities to improve learning outcomes, and machine learning algorithms can provide real-time feedback on student performance and adjust learning plans based on feedback. This makes the learning process more dynamic and personalized. It can therefore be applied to all types of education, including language learning, mathematics, science, etc. However, improving the efficiency of machine learning algorithms depends more on the improvement of numerical optimization algorithms, so it is necessary to summarize the optimization algorithms in large-scale machine learning. This paper tries to make a detailed overview of the existing machine learning algorithms in optimizing personalized education recommendation system, and introduces the algorithm optimization process.",1
"This paper provides a thorough examination of the existing body of literature on the study and implementation of machine learning (ML) methods in recommender systems (RS). The study's objective is to analyze current patterns, examine practical uses, and provide guidance to scholars in aligning their research endeavors in this field published between January and June of 2023. The findings are classified into many categories, such as education, healthcare, ML algorithms (namely auto-encoders and reinforcement learning), e-commerce, and digital journalism. The review emphasizes the improved precision of recommendations, greater ability to handle larger amounts of data, customization and understanding of context, various machine learning techniques, and approaches for dealing with new and sparse data. It also lays the groundwork for future developments in machine learning algorithms for recommendation systems, particularly in the context of manufacturing enterprises.","This paper presents a comprehensive literature review of the research and application of machine learning (ML) algorithms in recommender systems (RS). The study aims to identify recent trends, explore real-life applications, and guide researchers in positioning their research activities in this domain published in 2023 (Jan-June). The findings are categorized into different domains including education, healthcare, ML algorithms (auto-encoders and reinforcement learning), e-commerce, and digital journalism. The review highlights the enhanced recommendation accuracy, increased scalability, personalization and context awareness, diverse ML techniques, and strategies for handling cold start and data sparsity, and the foundation for future advancements in ML algorithms for RSs considering the application in manufacturing enterprises.",1
"Smart cities are the result of combining information and communication technology (ICT) with urban management in order to enhance the quality of life for people living in cities. Recommender systems, which provide personalized advice to urban residents, have become important contributors to this confluence. Their effective implementation in diverse aspects of urban life and their capacity to handle vast quantities of data produced in city environments has accelerated their importance as a vital technology in the advancement of urban planning. Our research involved doing a thorough examination of the Web of Science database, which yielded a total of 130 articles. After applying a relevancy filter, the number of articles was decreased to 86. The initial phase involved doing a bibliometric analysis using the SciMAT program to examine structural factors. Furthermore, a methodical examination of existing literature was conducted utilizing the PRISMA 2020 declaration. The results demonstrated the various mechanisms by which recommendations are screened in domains such as tourism, health, mobility, and transit. This research is considered an important discovery that has the potential to enhance the development and effectiveness of smart cities, laying a strong foundation for future research in this rapidly changing sector.","Smart cities represent the convergence of information and communication technologies (ICT) with urban management to improve the quality of life of city dwellers. In this context, recommender systems, tools that offer personalised suggestions to city dwellers, have emerged as key contributors to this convergence. Their successful application in various areas of city life and their ability to process massive amounts of data generated in urban environments has expedited their status as a crucial technology in the evolution of city planning. Our methodology included reviewing the Web of Science database, resulting in 130 articles that, filtered for relevancy, were reduced to 86. The first stage consisted of carrying out a bibliometric analysis with the objective of analysing structural aspects with the SciMAT tool. Secondly, a systematic literature review was undertaken using the PRISMA 2020 statement. The results illustrated the different processes by which recommendations are filtered in areas such as tourism, health, mobility, and transport. This research is seen as a significant breakthrough that can drive the evolution and efficiency of smart cities, establishing a solid framework for future research in this dynamic field.",1
"Remote healthcare solutions based on the Internet of Things (IoT) offer rapid and preventive medical treatments to individuals who are at danger. Nevertheless, forecasting cardiac disease is a complicated undertaking and diagnostic outcomes are seldom precise. A unique Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed to address this issue. It aims to provide before diagnosis, therapy, and nutrition recommendations for cardiac disorders. At first, the patient's physiological data are gathered remotely using four bio sensors: an ECG sensor, a pressure sensor, a pulse sensor, and a glucose sensor. An Arduino controller retrieves the gathered data from the IoT sensors in order to forecast and diagnose the illness. A cardiovascular disease prediction model is developed using the BiGRU (Bidirectional-Gated Recurrent Unit) attention model to diagnose and classify cardiovascular diseases into five distinct categories. The recommendation system utilizes classified data to provide cardiac patients with activity and dietary suggestions using a mobile application. The DEEP-CARDIO's performance is verified through the utilization of Cloud Simulator (CloudSim) using the real-time Framingham's and Statlog heart disease dataset. The DEEP CARDIO approach obtains an accuracy of 99.90%, whereas the MABC-SVM, HCBDA, and MLbPM methods reach accuracies of 86.91%, 88.65%, and 93.63% respectively.","Internet of Things (IoT) based remote healthcare applications provide fast and preventative medical services to the patients at risk. However, predicting heart disease is a complex task and diagnosis results are rarely accurate. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed for providing prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, the physiological data are collected from the patient’s remotely by using the four bio sensors such as ECG sensor, Pressure sensor, Pulse sensor and Glucose sensor. An Arduino controller receives the collected data from the IoT sensors to predict and diagnose the disease. A cardiovascular disease prediction model is implemented by using BiGRU (Bidirectional-Gated Recurrent Unit) attention model which diagnose the cardiovascular disease and classify into five available cardiovascular classes. The recommendation system provides physical and dietary recommendations to cardiac patients based on the classified data, via user mobile application. The performance of the DEEP-CARDIO is validated by Cloud Simulator (CloudSim) using the real-time Framingham’s and Statlog heart disease dataset. The proposed DEEP CARDIO method achieves an overall accuracy of 99.90% whereas, the MABC-SVM, HCBDA and MLbPM method achieves 86.91%, 88.65% and 93.63% respectively.",1
"The current endeavor in providing computing resources as a service to managers and consumers signifies a departure from computing as a product that is bought, to computing as a service that is provided to users over the internet from extensive data centers. Nevertheless, the emergence of cloud-based Internet of Things (IoT) and artificial intelligence (AI) has led to significant advancements in automating customer experiences across various domains, such as recommender systems (RS). Consequently, there is a growing demand for modifications to accommodate IoT devices, which play a central role in automation. This includes recent language models like ChatGPT and Bard, as well as technologies like nanotechnology. This study presents the marketing community with a new advancement in computing called IoT-driven fog computing (FC). While there have been several research studies on FC ""smart"" applications, none of them have focused on fog-based smart marketing domains like recommender systems. FC is regarded as an innovative computational system that can reduce latency and enhance bandwidth usage for autonomous consumer behavior applications that necessitate real-time data-driven decision making. This paper presents a theoretical framework for examining the impact of fog computing on consumer behavior. The objective is to encourage further research by utilizing the combination of fog computing and recommendation systems as an illustrative case. Our conceptualization of ""fog-based recommender systems"" presents new and challenging opportunities for academic research. Some of these opportunities are discussed in the later part of this paper. Keywords: fog computing, recommender system, internet of things (IoT), edge computing, artificial intelligence (AI), software defined networks (SDNs).","The latest effort in delivering computing resources as a service to managers and consumers represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to users over the internet from large-scale data centers. However, with the advent of the cloud-based IoT and artificial intelligence (AI), which are advancing customer experience automations in many application areas, such as recommender systems (RS), a need has arisen for various modifications to support the IoT devices that are at the center of the automation world, including recent language models like ChatGPT and Bard and technologies like nanotechnology. This paper introduces the marketing community to a recent computing development: IoT-driven fog computing (FC). Although numerous research studies have been published on FC “smart” applications, none hitherto have been conducted on fog-based smart marketing domains such as recommender systems. FC is considered a novel computational system, which can mitigate latency and improve bandwidth utilization for autonomous consumer behavior applications requiring real-time data-driven decision making. This paper provides a conceptual framework for studying the effects of fog computing on consumer behavior, with the goal of stimulating future research by using, as an example, the intersection of FC and RS. Indeed, our conceptualization of the “fog-based recommender systems” opens many novel and challenging avenues for academic research, some of which are highlighted in the later part of this paper.
Keywords: fog computing; recommender system; internet of things (IoT); edge computing; artificial intelligence (AI); software defined networks (SDNs)
ormation as well as personal and situational data [66].",1
"Purpose: The primary objective of the study was to examine the efficacy of recommender systems in the process of knowledge discovery. technique: The study utilized a desktop research technique. Desk research, often known as secondary data, refers to the collection of information that does not need fieldwork. Desk research mostly involves gathering data from pre-existing resources, making it a cost-effective strategy when compared to field research. The primary expenses associated with desk research include the time of the executive, telephone rates, and directories. Therefore, the study relied on previously published studies, reports, and statistics. The secondary data was readily available via internet journals and library resources. Analysis: The analysis indicates that there is a lack of context and methodology in the field of recommender systems in knowledge discovery. The research on the efficacy of recommender systems in knowledge discovery revealed that these systems played a crucial role in aiding users' exploration of extensive information repositories, allowing them to locate pertinent resources and enhance their knowledge. It was discovered that recommender systems utilizing sophisticated algorithms and personalized methodologies exhibited greater efficacy in producing pertinent recommendations customized to users' tastes and requirements. Moreover, the study emphasized the significance of promoting active user participation in the recommendation process by pointing out the positive relationship between user engagement measures and knowledge discovery outcomes. The identification of contextual information was also recognized as a pivotal component impacting the effectiveness of recommendations. In summary, the study emphasized the importance of constantly improving and optimizing recommender system algorithms in order to improve the outcomes of information discovery for consumers. The Social Learning theory, Information Foraging theory, and Cognitive Load theory can serve as foundational frameworks for future research on recommender systems in knowledge discovery, offering distinct and valuable insights. The study offered suggestions to improve the effectiveness of such systems. The proposal recommends the adoption of hybrid recommender systems, which integrate collaborative and content-based filtering techniques, in order to provide more precise and varied recommendations. Furthermore, the study highlighted the significance of including contextual data into recommendation algorithms in order to adapt recommendations according to situational circumstances. Moreover, it suggested the utilization of explainable AI methodologies to enhance transparency and user comprehension of recommendation procedures. Emphasizing the need of user engagement through active participation and feedback was also identified as vital. Additionally, promoting recommendation diversity is necessary to encourage exploration and the accidental discovery of new knowledge resources.","Purpose: The general purpose of the study was to investigate the effectiveness of recommender systems in knowledge discovery. Methodology: The study adopted a desktop research methodology. Desk research refers to secondary data or that which can be collected without fieldwork. Desk research is basically involved in collecting data from existing resources hence it is often considered a low cost technique as compared to field research, as the main cost is involved in executive’s time, telephone charges and directories. Thus, the study relied on already published studies, reports and statistics. This secondary data was easily accessed through the online journals and library. Findings: The findings reveal that there exists a contextual and methodological gap relating to recommender systems in knowledge discovery. The study on the effectiveness of recommender systems in knowledge discovery found that such systems played a pivotal role in facilitating users' exploration of vast information repositories, enabling them to uncover relevant resources and expand their knowledge. It found that recommender systems employing advanced algorithms and personalized techniques demonstrated higher effectiveness in generating relevant recommendations tailored to users' preferences and needs. Additionally, the study highlighted the positive correlation between user engagement metrics and knowledge discovery outcomes, emphasizing the importance of fostering active user participation in the recommendation process. Contextual information was also identified as a crucial factor influencing recommendation effectiveness. Overall, the study underscored the significance of continuous refinement and optimization of recommender system algorithms to enhance knowledge discovery outcomes for users. Unique Contribution to Theory, Practice and Policy: The Social Learning theory, Information Foraging theory and Cognitive Load theory may be used to anchor future studies on recommender systems in knowledge discovery. The study provided recommendations to enhance the efficacy of such systems. It suggested adopting hybrid recommender systems that combine collaborative and content-based filtering techniques to offer more accurate and diverse recommendations. Additionally, the study emphasized the importance of integrating contextual information into recommendation algorithms to dynamically adjust recommendations based on situational context. Furthermore, it recommended the use of explainable AI techniques to improve transparency and user understanding of recommendation processes. Maximizing user engagement through active participation and feedback was also highlighted as crucial, along with prioritizing recommendation diversity to foster exploration and serendipitous discovery of new knowledge resources.",1
"Artificial Intelligence (AI) is being extensively utilized in many Human Resources (HR) operations. The objective of this research is to get insight into the perspectives of various professionals from different organizations, including Project Managers, Managers, Supervisors, and Human Resource Managers, about the potential of artificial intelligence-based recommender systems in aligning job profiles with employee profiles. This study utilizes a Delphi study approach, which involves assembling a panel of experts who express their thoughts by scoring and commenting on a series of propositions. This research seeks to uncover the obstacles associated with matching employees to job profiles using artificial intelligence and machine learning tools, namely recommender systems. The study is based on the results of an online Delphi study and participant perspectives. This study examines the challenges associated with aligning staff profiles with job profiles, as well as the specific issues encountered by executives, human resource personnel, and supervisors, such as project managers, inside an organization. The study also provides insights into the possibility and viability of using artificial intelligence in the form of recommender systems. We also examine several propositions that address potential solutions and obstacles in matching employee profiles to job profiles inside an organization.","The application of Artificial Intelligence (AI) is significantly increasing in many Human Resources (HR) functions. This research aims to understand how diverse experts from distinct organisations, such as Project Managers, Managers, Supervisors and Human Resource Managers, perceive the potential of artificial intelligence-based recommender systems to match job profiles with employee profiles. This study employs a Delphi study-based methodology specifically, organising an expert panel that provides their opinions through their ratings and comments of a set of propositions. Based on the online Delphi study results and participant opinions, this research aims to identify the challenges related to employee-job profile matching through artificial intelligence and machine learning tools in the form of recommender systems. In this study, we have delved into the various challenges of matching employee profiles to job profiles and the current problems faced by executives, human resource personnel or supervisors such as project managers in an organisation. The study also sheds light on the potential or feasibility solutions of artificial intelligence in the form of recommender systems where we also test a couple of propositions that focus on potential solutions and various challenges for matching employee profiles to job profiles in an organisation.",1
"Facial Expression Recognition (FER) is employed in diverse domains, including education, gaming, robotics, healthcare, and other sectors. Facial expression techniques, such as an interactive robot equipped with Artificial Intelligence, have the ability to identify human faces, analyze the emotions of the individual it is engaging with, and subsequently utilize these emotions to select suitable responses. An application of face emotion detection is to select and play music that corresponds to the user's emotional state. In order to accomplish this, we can examine the user's facial expression to infer their emotions. Consequently, further research is needed to explore new emotion models, as current ones face difficulties in accurately assessing the relationship between music and facial emotions. This research employs a Convolution Neural Network (CNN) based deep learning approach to implement this type of task. Deep learning is superior than machine learning in its ability to evaluate unstructured data, movies, and other types of media with greater effectiveness. We have developed a live system in our research that is capable of accurately identifying human faces, evaluating human emotions, and providing music recommendations to users. The experimental investigation made use of the OAHEGA and FER-2013 datasets. We developed and instructed two emotion identification models by utilizing different mixes of these datasets. The accuracy of the proposed model is 73.02%. Our CNN algorithm has the capability to accurately forecast six distinct emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed technology can be employed in various locations where real-time facial identification is crucial.","Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.",1
"This paper suggests a cross-domain information fusion matrix decomposition algorithm to improve the accuracy of personalized recommendations in artificial intelligence recommendation systems, considering the difficulties of inter-domain information fusion and data sparsity in collaborative filtering algorithms. The study commences by gathering Douban movie rating data and social network information. In order to maintain the accuracy of the data, the procedure of Levenshtein distance detection is used to eliminate duplicate scores. Additionally, natural language processing technology is applied to extract keywords and topic information from social texts. In addition, graph convolutional networks are employed to transform user associations into feature vectors, while a distinctive thermal coding technique is employed to turn discrete user and movie information into binary matrices. In order to mitigate overfitting, the Ridge regularization technique is employed to systematically optimize the potential feature vectors. Subsequently, the weighted average and feature connection approaches are employed to amalgamate characteristics derived from various domains. In addition, the article integrates the item-based collaborative filtering algorithm with merging user characteristics in order to produce tailored recommendation lists. The research performs cross-domain information fusion optimization on four widely-used mathematical matrix decomposition strategies throughout the experimental phase. These algorithms include the alternating least squares method, non-negative matrix decomposition, singular value decomposition, and latent factor model (LFM). It contrasts these algorithms with the non-fused technique. The findings demonstrate a notable enhancement in the precision of scores, as seen by a decrease of 12.8% and 13.2% in the mean absolute error and root mean squared error, respectively, across all four algorithms. Moreover, with k=10, the mean F1 score attains 0.97, and the LFM algorithm's ranking accuracy coverage experiences a 54.2% rise. In summary, the integration of the mathematical matrix decomposition technique with cross-domain information fusion offers significant benefits in terms of accuracy, prediction performance, suggestion diversity, and ranking quality. Furthermore, it enhances the precision and variety of the recommendation system. By successfully tackling the obstacles of collaborative filtering through the incorporation of several methodologies, it greatly exceeds conventional models in terms of suggestion precision and diversity.","Given the challenges of inter-domain information fusion and data sparsity in collaborative filtering algorithms, this paper proposes a cross-domain information fusion matrix decomposition algorithm to enhance the accuracy of personalized recommendations in artificial intelligence recommendation systems. The study begins by collecting Douban movie rating data and social network information. To ensure data integrity, Levenshtein distance detection is employed to remove duplicate scores, while natural language processing technology is utilized to extract keywords and topic information from social texts. Additionally, graph convolutional networks are utilized to convert user relationships into feature vectors, and a unique thermal coding method is used to convert discrete user and movie information into binary matrices. To prevent overfitting, the Ridge regularization method is introduced to gradually optimize potential feature vectors. Weighted average and feature connection techniques are then applied to integrate features from different fields. Moreover, the paper combines the item-based collaborative filtering algorithm with merged user characteristics to generate personalized recommendation lists. In the experimental stage, the paper conducts cross-domain information fusion optimization on four mainstream mathematical matrix decomposition algorithms: alternating least squares method, non-negative matrix decomposition, singular value decomposition, and latent factor model (LFM). It compares these algorithms with the non-fused approach. The results indicate a significant improvement in score accuracy, with mean absolute error and root mean squared error reduced by 12.8% and 13.2% respectively across the four algorithms. Additionally, when k = 10, the average F1 score reaches 0.97, and the ranking accuracy coverage of the LFM algorithm increases by 54.2%. Overall, the mathematical matrix decomposition algorithm combined with cross-domain information fusion demonstrates clear advantages in accuracy, prediction performance, recommendation diversity, and ranking quality, and improves the accuracy and diversity of the recommendation system. By effectively addressing collaborative filtering challenges through the integration of diverse techniques, it significantly surpasses traditional models in recommendation accuracy and variety.",1
"Over the past few years, the scientific and academic community has been particularly interested in video games, specifically in studying and experimenting with Artificial General Intelligence (AGI). AGI experimental systems enable the analysis and study of the behavior of various pre-defined AI agents in a visual manner. This work introduces a new game engine called GAGI, which can be used as a platform for experimenting with AGI (Artificial General Intelligence). GAGI, functioning as a game engine, possesses the capability to develop and produce innovative 2D and 3D video games by utilizing the C++ programming language. Furthermore, GAGI offers users a distinctive platform for simulating and analyzing AI agents within the game that they have designed. Users have the ability to deploy many AI agents and engage with them in real time, enhancing their comprehension of the agents' interactions and behaviors. The suggested software's features are compared to those of widely-used game engines in the video games industry and the research community, emphasizing its advantages in terms of design capability and AI support. GAGI also provides the opportunity to replicate the studies, hence expanding the range of possibilities for the research community.","Video games have been in the focus of the research and academic community for the last few years, with the study and experimentation of Artificial General Intelligence (AGI) standing out. AGI experimentation platforms allow to analyze and study, in a visual way, the behavior of different AI agents previously defined. In this work a novel game engine, called GAGI, capable of serving as an AGI experimentation platform is presented. As a game engine, GAGI is able to design and create novel 2D and 3D video games using C++ programming language. Moreover, GAGI provides the user with a unique environment for simulating and studying AI agents inside the created game. Users can deploy multiple AI agents while interacting with them in real time, improving the understanding of their interactions and behaviors. The features of the proposed software is compared against others widely-used game engines in the video games industry as well as in the research community, highlighting the advantages in terms of design capability and AI support. GAGI also offers the possibility to reproduce the experiments, opening up multiple possibilities for the research community.",1
"Monte Carlo Tree Search (MCTS) is an effective empirical search method used for agent decision-making. It is particularly successful when combined with Deep Learning (DL) in mastering board games that were previously considered unbeatable. However, real-time video games do not seem to achieve the same level of success. This is because these games have a time restriction for exploration, which is a critical aspect. They are primarily meant for human users and therefore demand a substantial number of resources for simulation. In this research, we provide a surrogate-assisted Monte Carlo Tree Search (MCTS) method that is designed for commercial real-time video games. Our strategy involves using a deep-learning-based surrogate model to approximate the outcome of gameplay. Our work's main contribution lies in the development of a customized Monte Carlo Tree Search (MCTS) algorithm specifically tailored for real-time commercial video games. Our work can be seen as exploring a domain that previous research have not addressed, as commercial video games offer more intricate and dynamic gameplay to meet the demands of its consumers compared to non-commercial games. We assessed the effectiveness of our approach by performing a comparative experiment with different algorithms, including the conventional MCTS, within the context of a commercial real-time video game.","Monte Carlo Tree Search (MCTS) is a pronounced empirical search algorithm for agent decision-making, especially when enhanced by Deep Learning (DL), in mastering board games that were once thought to be unconquerable. However, it does not appear to be as equally successful in the domain of real-time video games, where the simulation time limit for exploration is a crucial factor, since they are generally designed to be played by human users and hence require a significant amount of resources for simulation. We in this paper propose a surrogate-assisted MCTS approach, specifically targeting commercial real-time video games by approximating the result of gameplay with a deep-learning-based surrogate model. The key contribution of our work is that we designed a modified MCTS for video games that are both commercial and processed in real-time. Since commercial video games include considerably more complex and dynamic gameplays to satisfy their market consumers, as opposed to their non-commercial analogs, our work can be regarded as having challenged the domain unattempted by precedent studies. We validated the performance of our method by conducting a comparative experiment with other algorithms, including the traditional MCTS, under the environment of a commercial real-time video game.",1
"The controversy surrounding the use of exergames in physical education (PE) courses and its impact on student performance in PE learning remains unresolved. This review examines the impact of exergames on student physical education (PE) learning and identifies the optimal circumstances for maximizing this impact. Following the PICOS method, two researchers conducted separate searches in the ProQuest, EBSCO, Web of Science (WoS), PubMed, Chinese National Knowledge Infrastructure (CNKI), Wanfang, and VIP databases. They assessed the quality of the literature using the Cochrane system evaluation manual and conducted a meta-analysis of the included studies. This analysis comprised a total of 16 randomized controlled trials with 2962 patients. The meta-analysis demonstrated that exergames had a significant positive impact on student performance in physical education learning. The standardized mean difference (SMD) was 0.45, with a 95% confidence interval (CI) of 0.27 to 0.63, and a p-value of less than 0.00001. Subgroup analysis revealed that introducing exergames in small kindergarten groups and maintaining them for a duration of 1-2 months led to improved outcomes.","﻿Whether the application of exergames in physical education (PE) courses can significantly improve student performance in PE learning is still controversial. This review explores the promoting effect of exergames on student PE learning and the conditions in which the effect of exergames can be maximized. Based on the PICOS method, two researchers independently searched the ProQuest database, EBSCO database, Web of Science (WoS) database, PubMed database, Chinese National Knowledge Infrastructure (CNKI) database, Wanfang database, and VIP database, evaluated the literature quality using the Cochrane system evaluation manual, and performed a meta-analysis of the included literature. A total of 16 randomized controlled trials involving 2962 subjects were included in this study. The meta-analysis showed that exergames effectively improved student performance in PE learning (SMD = 0.45, 95% CI: 0.27–0.63, P < 0.00001). Subgroup analysis indicated that better results could be achieved when exergames were introduced in small kindergarten classes and continued for 1–2 months.",1
"Artificial Intelligence (AI) is a transformative advancement that has become an integral part of our everyday lives and industrial processes. The rapid evolution of this technology holds the potential to bring about significant changes in a wide range of areas, including advanced industries and the daily lives of ordinary people. Artificial intelligence continuously enhances human experiences by influencing interactions and enhancing skills. Contemporary educational institutions utilize AI algorithms to track attendance using facial recognition technologies. In the future, the emergence of autonomous vehicles signifies the highest point of AI implementation, as vehicles depend solely on AI systems to navigate, identify traffic signals, and travel on roadways.","Artificial Intelligence (AI) stands as a pivotal innovation deeply ingrained in both our daily routines and industrial operations. Its rapid evolution promises transformative impacts across various sectors, from cutting-edge industries to the lives of ordinary individuals. AI constantly updates human experiences, shaping interactions and augmenting capabilities. For instance, contemporary educational institutions leverage AI algorithms for attendance tracking via facial recognition technology. Looking ahead, the advent of autonomous vehicles represents a pinnacle of AI application, where vehicles rely entirely on AI systems for navigation, detecting traffic signals, and navigating roads.",1
"International relations studies has consistently highlighted the significant influence of popular culture on public perceptions and political dynamics. This article examines the possibilities of military-themed video games and how they depict weaponized artificial intelligence (AI). In paradoxical depictions of AI weapons in video games, they are portrayed both as formidable enemies that pose existential threats to humanity in the game's storylines, and as easy targets that human protagonists effortlessly defeat during gameplay. These representations create distortions in the way humans interact with machines, which do not align with real-world scenarios. These distortions arise from the fact that videogames empower players with increased control over AI weaponry, allowing them to dominate and enjoy the gameplay. This contradicts the original purpose of these weapons, which is to reduce human control on real-world battlefields. We elucidate the production of these inaccurate depictions of AI weaponry by examining the entanglements between diverse human and non-human actors, utilizing the idea of translation from the Actor-Network Theory. These entanglements are driven by the objective of making video games widely marketable and financially lucrative. By doing this, we are aligning with game studies research that emphasizes the need to focus more on the commercial and playful aspects of video games. This will enable international relations academics to more effectively analyze how popular cultures can influence public perceptions and political situations.","International relations scholarship has long emphasized that popular culture can impact public understandings and political realities. In this article, we explore these potentials in the context of military-themed videogames and their portrayals of weaponized artificial intelligence (AI). Within paradoxical videogame representations of AI weapons both as insurmountable enemies that pose existential threats to humankind in narratives and as easy targets that human protagonists routinely overcome in gameplay, we identify distortions of human machine interaction that contradict real-world scenarios. These distortions revolve around videogames affording players enhanced human agency to dominate AI weapons to offer enjoyable gameplay, contradicting the same weapons being intended to diminish human agency on real-world battlefields. By leveraging the Actor-Network Theory concept of translation, we explain how these distorted portrayals of AI weapons are produced by entanglements between heterogeneous human and non-human actors that aim to make videogames mass-marketable and profitable. In so doing, we echo game studies research that calls for greater attention to the commercial and ludic dimensions of videogames so that international relations scholarship can better account for pop cultures bounded abilities to impact public understandings and political realities.",1
"In scientific areas like as biomechanics, genetics, ethology, and neurology, it is crucial to precisely monitor the behavior of animals throughout investigations, especially without using markers. Nevertheless, it has been challenging to derive exact positions from constantly changing backgrounds. We have recently introduced a collection of tools that are open-source and utilize a state-of-the-art algorithm to estimate the position of humans. Using this toolbox, users can train a deep neural network to effectively monitor user-defined features with tracking accuracy comparable to that of human labeling. The redesigned Python package now includes additional capabilities like as graphical user interfaces (GUIs), efficiency enhancements, and network refinement through active learning. To assist customers in developing a distinct and replicable analysis pipeline utilizing a graphical processing unit (GPU).","Accurately scientific disciplines, including biomechanics, genetics, ethology, and neurology, it is essential to accurately track the behavior of animals throughout studies, particularly without employing markers. However, it has proven difficult to extract precise stances from backgrounds that are always shifting. Recently, we unveiled an open-source toolset that makes use of a cutting-edge algorithm for estimating human position. With the help of this toolbox, users may train a deep neural network to accurately monitor user-defined features with tracking accuracy that rivals that of human labeling. We have added new features, including as graphical user interfaces (GUIs), efficiency improvements, and network refinement based on active learning, to this revised Python module. In order to help customers create a unique and repeatable analysis pipeline using a graphical processing unit (GPU).",1
"Ensuring the right amount of challenge in a game is crucial for maintaining player engagement. Dynamic Difficulty Adjustment (DDA) is a widely used method for enhancing player experience by automatically altering various features of the game. This paper examines the literature on processes used to adapt video game difficulty based on players' performance, emotions, or personality. To achieve this objective, we analyzed DDA research that utilized machine-learning methodologies, player modeling approaches, various data types to evaluate player states, testbed game genres, and applications. The data sources for this review consisted of journal and conference articles published until September 2022. The results indicate that the majority of research have demonstrated substantial impacts of DDA on factors such as pleasure, seamless experience, drive, involvement, and deep absorption. Furthermore, there has been a growing focus on incorporating machine-learning and player modeling approaches into the design of Dynamic Difficulty Adjustment (DDA) systems. Nevertheless, due to the escalating utilization of games in diverse fields, further investigation is necessary to have a deeper understanding of player preferences in order to effectively modify game characteristics. By performing additional research on players' cognitive traits, such as visual attention, working memory, and response time, it will be feasible to gain a deeper understanding of players' preferences.","Providing an appropriate difficulty level in a game is critical for keeping players engaged. Dynamic Difficulty Adjustment (DDA) is a common approach for optimizing player experience by automatically modifying game aspects. This paper reviews literature addressing mechanisms for adjusting video game difficulties in response to players performance, emotions, or personality. For this purpose, we examined DDA studies using employed machine-learning techniques, player modeling approaches, data types used to assess players states, testbed game genre, and application. Journal and conference articles published up to September 2022 served as the data sources in this review. The findings reveal that most studies have shown significant effects of DDA on parameters such as enjoyment, flow, motivation, engagement, and immersion. In addition, machine-learning and player modeling techniques have recently received more attention in the DDA design. However, given the ever-increasing use of games in various domains, more research is needed to understand player preferences better to adjust game parameters efficiently. By conducting further research into players cognitive characteristics, such as visual attention, working memory, and response time, it will be possible to understand players preferences better.",1
"Immersive video games offer a realistic learning environment for agriculture by imitating challenging real-life events. Nevertheless, there is a scarcity of actual information regarding their usefulness. This scoping review adheres to the PRISMA-ScR principles in order to provide a concise summary of the existing literature on serious video games used for agricultural learning. The review aims to identify research trends and pinpoint areas where further investigation is needed. We conducted a comprehensive search across nine significant research databases to identify publications on the use of serious video games for agricultural learning. The search was limited to papers published from January 2000 to July 2022. Two autonomous reviewers performed screening, data extraction, and synthesized the acquired data using a narrative technique. Out of the 3,297 papers initially found, only 0.58% (n = 19) were selected for the review. The majority of the games that received reviews were launched within the past five years, with a significant focus on the mobile platform. Their preferred method was a simulation-based technique, utilizing 2-D graphics and specifically tailored for individual players. The primary audience for these games is students, with a specific emphasis on agricultural production and sustainable agriculture. The studies frequently lacked specificity in their treatment of educational theories. The evaluation protocols largely focused on conducting pilot studies that emphasized the improvement of user experience and knowledge. The studies generally showed positive outcomes, including enhanced user experiences, increased knowledge, and changes in attitude and behavior. This study emphasizes the progress made in utilizing serious video games for agricultural education over a span of 20 years. Nevertheless, it emphasizes the necessity for more investigation into the influence of game components on user experience and efficacy. It is crucial to develop games that cater to minority players and address unique agricultural concerns. Additionally, it is important to improve the theoretical underpinnings and learning methodologies in this field. Thorough research designs are crucial for evaluating the effectiveness of games across short, medium, and extended periods of time.","Serious video games provide a immersive learning environment for agriculture by simulating real-life challenges scenarios. However, empirical evidence of their effectiveness is sparse. This scoping review follows PRISMA-ScR guidelines to summarize literature on serious video games for agricultural learning, highlighting research trends and identifying gaps. We systematically searched nine prominent research databases for papers on serious video games for agriculture learning published between January 2000 and July 2022. Two independent reviewers conducted screening, data extraction, and synthesized the collected data using a narrative approach. The initial search identified 3,297 articles, of which 0.58% ( n = 19) were included in the review. Most reviewed games were released in the last five years, with a predominant presence in the mobile platform. They commonly employed a simulation-based approach, featuring 2-D graphics and designed for single-player experiences. These games mainly target students, focusing on crop production and sustainable agriculture. Educational theories were often unspecified in the studies. Evaluation protocols primarily consisted of pilot studies, emphasizing user experience and knowledge enhancement. Positive outcomes, such as improved user experiences, knowledge, and attitude and behavior changes, were commonly observed in these studies. This study highlights advancements in using serious video games for agricultural learning over 20 years. However, it stresses the need for deeper exploration of game elements' impact on user experience and effectiveness. Creating games for underrepresented players and specific agricultural challenges is essential, as is enhancing theoretical foundations and learning approaches. Rigorous research designs are vital for assessing game effectiveness across short, medium, and long terms.",1
"As education and technology have advanced, teachers have come to recognize that games should have a purpose beyond just entertainment for children. Utilizing gamification in educational materials can lead to improved teaching results. Nevertheless, new resources that are connected to the topic are consistently appearing on the internet. A personalized recommendation strategy for educational video game resources based on knowledge graphs is developed to enhance the quality of recommendations. Firstly, feature extraction is carried out in an alternating manner on both the user side and the item side. Next, a hidden Markov model is shown using the dual end neighbor technique as a foundation. Given the user's temporal characteristics, the model is optimized. The optimized model considers both the enduring and immediate preferences of users and extracts their latent preferences. By doing experimental analysis, the hit rate index value of the designed model achieves a score of 0.7989. The broken line has a normalized cumulative gain value of 0.6045. The satisfaction rate for the suggestion of this model exceeds 89%. The duration of the operating process is 0.2863 seconds. The developed methodology may successfully achieve effective and top-notch suggestion of instructional video game resources, offering consumers a more convenient and efficient online experience.","With the development of education and technology, teachers have gradually realized that games should not be just a way for students to entertain themselves. Applying games to teaching resources can achieve better teaching outcomes. However, related resources are constantly emerging on the internet. To achieve higher quality recommendations, a personalized recommendation model for educational video game resources based on knowledge graphs is proposed. Firstly, feature extraction is performed alternately on the user side and the item side. Then a hidden Markov model is introduced on the basis of the dual end neighbor algorithm. Considering the temporal nature of the user, the model is optimized. The optimized model takes into account the long-term and short-term preferences of users and mines their potential preferences. Through experimental analysis, the hit rate index value of the designed model reaches 0.7989. The normalized cumulative gain value of the broken line is 0.6045. More than 89% of users are satisfied with the recommendation of this model. The running time is 0.2863s. The constructed model can achieve efficient and high-quality recommendation of educational video game resources, providing users with a more convenient and efficient online experience.",1
"The metaverse has arisen as a captivating new framework for the interaction between humans and computers, as well as for virtual collaboration. This study provides a thorough examination of the metaverse to fill the void in current research, where there is a scarcity of a survey that evaluates the characteristics of the metaverse and its fundamental components from a human-centered viewpoint. Initially, we compile a precise description of the metaverse by analyzing relevant literature and identifying its essential characteristics. Next, we present a comprehensive framework that covers the characteristics of metaverses, the technologies used for infrastructure, and the technologies used for input/output. This framework enables the creation of multi-sensory human-computer interaction and may be applied in various disciplines. This framework provides comprehensive explanations of its components, delivering valuable insights into the inherent characteristics of metaverses and the current technological preparedness level. Using this extensive research, we identify significant unresolved issues and suggest potential avenues that require additional exploration and investigation. This review offers crucial insights and acts as a vital resource for metaverse developers and academics aiming to progress this revolutionary new medium. It clarifies the goal for the metaverse and outlines the necessary building pieces to bring it to life.","The metaverse has emerged as an exciting new paradigm for human-computer interaction (HCI) and virtual collaboration. This paper presents a comprehensive review of the metaverse to address the gap in the existing literature where there is a lack of a survey that reviews the nature of the metaverse and its building blocks from a human-centric perspective. We first synthesize a definition of the metaverse from existing literature and delineate key affordances. We then introduce a detailed framework encompassing the metaverses nature, infrastructure technologies, and input/output technologies that facilitate multi-sensory HCI, alongside applications across diverse domains. The components within this framework are explained in depth, offering insights into the metaverses nature and the readiness level of current technologies. Based on this comprehensive analysis, we outline major open challenges and propose promising directions demanding further exploration and investigation. By clarifying the vision for the metaverse and characterizing the building blocks required to realize it, this review provides essential insights and serves as an invaluable resource for metaverse developers and researchers working to advance this transformative new medium.",1
"In recent years, the advent of artificial intelligence (AI), machine learning (ML), and deep learning (DL) technologies has brought about considerable changes in the lifestyle of modern society. Artificial intelligence is a complex technology that encompasses multiple dimensions and includes advanced algorithms, machine learning (ML), and deep learning (DL). In the near future, AI, ML, and DL are anticipated to offer automated gadgets to ophthalmologists, enabling them to diagnose ocular problems early and administer prompt therapy. Indeed, artificial intelligence (AI), machine learning (ML), and deep learning (DL) have been employed in the field of ophthalmology to authenticate disease diagnoses, interpret images, conduct corneal topographic mapping, and calculate intraocular lens measurements. Diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma are the three predominant factors leading to permanent loss of vision worldwide. Ophthalmic imaging offers a means to diagnose and objectively monitor the advancement of several pathologies, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), glaucoma, and other ophthalmic problems. In ophthalmic practice, there are two diagnostic imaging technologies commonly used: fundus digital photography and optical coherence tomography (OCT). It is worth mentioning that OCT has emerged as the predominant imaging technique in ophthalmology practices in developed countries. The increasing need for such images is driven by changes in population demographics and lifestyle, the lengthening of average lifespan, and the shifting prevalence of chronic disorders such as obesity, diabetes, DR, AMD, and glaucoma. Moreover, the scarcity of retina specialists and adequately educated human graders is a significant challenge in numerous nations. Therefore, due to the ongoing trends in population increase, it is unavoidable that the analysis of such photos will require a significant amount of time, financial resources, and is susceptible to mistakes made by humans. Hence, the identification and management of diabetic retinopathy (DR), age-related macular degeneration (AMD), glaucoma, and other eye illnesses using unmanned automated systems would be unavoidable in the coming years. We present a comprehensive analysis of how the current approaches of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) can potentially affect the early identification and management of diseases such as Diabetic Retinopathy (DR), Age-related Macular Degeneration (AMD), glaucoma, and other eye-related conditions.","The lifestyle of modern society has changed significantly with the emergence of artificial intelligence (AI), machine learning (ML), and deep learning (DL) technologies in recent years. Artificial intelligence is a multidimensional technology with various components such as advanced algorithms, ML and DL. Together, AI, ML, and DL are expected to provide automated devices to ophthalmologists for early diagnosis and timely treatment of ocular disorders in the near future. In fact, AI, ML, and DL have been used in ophthalmic setting to validate the diagnosis of diseases, read images, perform corneal topographic mapping and intraocular lens calculations. Diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma are the 3 most common causes of irreversible blindness on a global scale. Ophthalmic imaging provides a way to diagnose and objectively detect the progression of a number of pathologies including DR, AMD, glaucoma, and other ophthalmic disorders. There are 2 methods of imaging used as diagnostic methods in ophthalmic practice: fundus digital photography and optical coherence tomography (OCT). Of note, OCT has become the most widely used imaging modality in ophthalmology settings in the developed world. Changes in population demographics and lifestyle, extension of average lifespan, and the changing pattern of chronic diseases such as obesity, diabetes, DR, AMD, and glaucoma create a rising demand for such images. Furthermore, the limitation of availability of retina specialists and trained human graders is a major problem in many countries. Consequently, given the current population growth trends, it is inevitable that analyzing such images is time-consuming, costly, and prone to human error. Therefore, the detection and treatment of DR, AMD, glaucoma, and other ophthalmic disorders through unmanned automated applications system in the near future will be inevitable. We provide an overview of the potential impact of the current AI, ML, and DL methods and their applications on the early detection and treatment of DR, AMD, glaucoma, and other ophthalmic diseases.",1
"Thanks to the remarkable progress in data aggregation and deep learning algorithms, artificial intelligence (AI) and machine learning (ML) are on the verge of revolutionizing the field of medicine. The discipline of orthopedics is well-suited to use the potential of big data, which can offer valuable insights to enhance various aspects of care delivered by orthopedic surgeons. This review aims to assess the latest and innovative literature on machine learning (ML) in the field of orthopedics and its potential implications for the future of musculoskeletal care.","With the unprecedented advancement of data aggregation and deep learning algorithms, artificial intelligence (AI) and machine learning (ML) are poised to transform the practice of medicine. The field of orthopedics, in particular, is uniquely suited to harness the power of big data, and in doing so provide critical insight into elevating the many facets of care provided by orthopedic surgeons. The purpose of this review is to critically evaluate the recent and novel literature regarding ML in the field of orthopedics and to address its potential impact on the future of musculoskeletal care.",1
"Industry 4.0 encompasses concepts and technology that promote the continuous growth of both small-scale and large-scale economic entities through the principles of interconnectedness, digitalization, and automation. Artificial intelligence is considered a significant facilitator for Smart Logistics and Smart Production activities in this particular environment. This study conducts a comprehensive analysis of the scientific literature on artificial intelligence, machine learning, and deep learning as they relate to the management of Smart Logistics in industrial businesses. In addition, the authors of the systematic literature review present a conceptual framework that offers valuable implications derived from recent research findings and insights. This framework can be used to guide and initiate future research endeavors in the field of artificial intelligence (AI), machine learning (ML), and deep learning (DL) in the context of Smart Logistics.","Industry 4.0 concepts and technologies ensure the ongoing development of micro- and macro-economic entities by focusing on the principles of interconnectivity, digitalization, and automation. In this context, artificial intelligence is seen as one of the major enablers for Smart Logistics and Smart Production initiatives. This paper systematically analyzes the scientific literature on artificial intelligence, machine learning, and deep learning in the context of Smart Logistics management in industrial enterprises. Furthermore, based on the results of the systematic literature review, the authors present a conceptual framework, which provides fruitful implications based on recent research findings and insights to be used for directing and starting future research initiatives in the field of artificial intelligence (AI), machine learning (ML), and deep learning (DL) in Smart Logistics.",1
"Machine learning (ML) is a branch of artificial intelligence that has the potential to revolutionize the twenty-first century. The rapid and recent advancements in both the design and algorithms of computers, as well as the expansion of datasets, have resulted in a significant increase in computer proficiency across various sectors. These encompass tasks such as operating a car, translating languages, developing chatbots, and achieving superior performance in complex board games like Go. In this article, we will examine the basic principles and algorithms that underlie machine learning and emphasize particular methods for learning and optimization. Next, we provide a concise overview of the various uses of machine learning in the field of medicine. Specifically, we present recent advancements in diagnostic accuracy and limitations in the areas of dermatology, radiology, pathology, and general microscopy.","Machine learning (ML) is a form of artificial intelligence which is placed to transform the twenty-first century. Rapid, recent progress in its underlying architecture and algorithms and growth in the size of datasets have led to increasing computer competence across a range of fields. These include driving a vehicle, language translation, chatbots and beyond human performance at complex board games such as Go. Here, we review the fundamentals and algorithms behind machine learning and highlight specific approaches to learning and optimisation. We then summarise the applications of ML to medicine. In particular, we showcase recent diagnostic performances, and caveats, in the fields of dermatology, radiology, pathology and general microscopy.",1
"In recent years, the fields of sophisticated robotics have been transformed by Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL). Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) are revolutionizing the domain of sophisticated robotics, enhancing the intelligence, efficiency, and adaptability of robots in intricate tasks and challenging settings. AI, ML, and DL are utilized in advanced robotics for various purposes such as autonomous navigation, object recognition and manipulation, natural language processing, and predictive maintenance. These technologies are likewise utilized in the advancement of collaborative robots (cobots) that can operate alongside humans and adjust to dynamic situations and tasks. Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) can be employed in sophisticated transportation systems to enhance passenger safety, optimize operational efficiency, and offer convenience to both passengers and transportation businesses. The utilization of AI, ML, and DL in manufacturing assembly robots is crucial as it enhances their efficiency, safety, and intelligence. Moreover, they possess a diverse array of uses in aviation administration, aiding airlines in enhancing efficiency, diminishing expenses, and elevating client happiness. Furthermore, artificial intelligence (AI), machine learning (ML), and deep learning (DL) can assist taxi firms in enhancing their services by offering improved efficiency and safety to clients. The study provides a comprehensive analysis of the latest advancements in Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) inside sophisticated robotics systems. It also explores the diverse range of uses these systems have in modifying robots. Additional research is recommended to explore the utilization of artificial intelligence (AI), machine learning (ML), and deep learning (DL) in advanced robotics systems. This will help bridge the gaps between current studies and published publications. By examining the utilization of artificial intelligence (AI), machine learning (ML), and deep learning (DL) in sophisticated robotic systems, it becomes feasible to analyze and adjust the capabilities of advanced robots across different applications with the aim of improving productivity in advanced robotic industries.","Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) have revolutionized the field of advanced robotics in recent years. AI, ML, and DL are transforming the field of advanced robotics, making robots more intelligent, efficient, and adaptable to complex tasks and environments. Some of the applications of AI, ML, and DL in advanced robotics include autonomous navigation, object recognition and manipulation, natural language processing, and predictive maintenance. These technologies are also being used in the development of collaborative robots (cobots) that can work alongside humans and adapt to changing environments and tasks. The AI, ML, and DL can be used in advanced transportation systems in order to provide safety, efficiency, and convenience to the passengers and transportation companies . Also, the AI, ML, and DL are playing a critical role in the advancement of manufacturing assembly robots, enabling them to work more efficiently, safely, and intelligently. Furthermore, they have a wide range of applications in aviation management, helping airlines to improve efficiency, reduce costs, and improve customer satisfaction. Moreover, the AI, ML, and DL can help taxi companies in order to provide better, more efficient, and safer services to customers. The research presents an overview of current developments in AI, ML, and DL in advanced robotics systems and discusses various applications of the systems in robot modification. Further research works regarding the applications of AI, ML, and DL in advanced robotics systems are also suggested in order to fill the gaps between the existing studies and published papers. By reviewing the applications of AI, ML, and DL in advanced robotics systems, it is possible to investigate and modify the performances of advanced robots in various applications in order to enhance productivity in advanced robotic industries.",1
"Artificial intelligence and machine learning have made significant advancements in commercial applications, including in picture recognition, natural speech processing, language translation, textual analysis, and self-learning. Progress in these areas has previously been slow, causing these talents to be closely associated with intelligence. Nevertheless, these commercial advancements have excelled only in single-task applications where it is acceptable to have imprecise outputs and occasional blatant errors. Anesthesiology is distinct in its approach and methodology. The concept encompasses the need for utmost dependability and a demanding sequence of understanding, physical execution, and reaction, rather than a solitary mental process. This paper provides a concise explanation of artificial intelligence and machine learning for anesthesiologists, focusing on how decision-making processes might arise from basic mathematical equations. The introduction of relevant clinical questions serves to exemplify how machine learning might potentially aid in their resolution, potentially ushering anesthesiology into an era of machine-assisted discovery.","Commercial applications of artificial intelligence and machine learning have made remarkable progress recently, particularly in areas such as image recognition, natural speech processing, language translation, textual analysis, and self-learning. Progress had historically languished in these areas, such that these skills had come to seem ineffably bound to intelligence. However, these commercial advances have performed best at single-task applications in which imperfect outputs and occasional frank errors can be tolerated. The practice of anesthesiology is different. It embodies a requirement for high reliability, and a pressured cycle of interpretation, physical action, and response rather than any single cognitive act. This review covers the basics of what is meant by artificial intelligence and machine learning for the practicing anesthesiologist, describing how decision-making behaviors can emerge from simple equations. Relevant clinical questions are introduced to illustrate how machine learning might help solve them—perhaps bringing anesthesiology into an era of machine-assisted discovery.",1
"Adaptation and innovation are crucial to the manufacturing industry. This advancement is expected to result in the implementation of environmentally-friendly production methods through the utilization of innovative technologies. In order to advance sustainability, the implementation of smart industrial technologies necessitates a worldwide outlook. Thanks to extensive research in the field of artificial intelligence (AI), several AI-based approaches, including machine learning, have been successfully used in the industry to promote sustainable production. The objective of this research was to thoroughly assess the scientific literature on the use of artificial intelligence and machine learning (ML) in the industry. Indeed, the advent of Industry 4.0 has positioned artificial intelligence and machine learning as the primary catalysts behind the transformative smart factory revolution. The objective of this review was to categorize the literature based on many factors such as publication year, authors, scientific sector, nation, institution, and keywords. The analysis was conducted utilizing the Web of Science and SCOPUS database. In addition, the researchers utilized UCINET and NVivo 12 software to carry out the tasks. A systematic analysis of empirical studies on machine learning (ML) and artificial intelligence (AI) published in the past century was conducted to examine the progression of the subject before and after the advent of Industry 4.0, spanning from 1999 to the present. A total of eighty-two papers were examined and categorized. One notable finding is the higher quantity of publications produced by the United States, which has seen a surge in interest following the emergence of Industry 4.0.","Adaptation and innovation are extremely important to the manufacturing industry. This development should lead to sustainable manufacturing using new technologies. To promote sustainability, smart production requires global perspectives of smart production application technology. In this regard, thanks to intensive research efforts in the field of artificial intelligence (AI), a number of AI-based techniques, such as machine learning, have already been established in the industry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze, systematically, the scientific literature relating to the application of artificial intelligence and machine learning (ML) in industry. In fact, with the introduction of the Industry 4.0, artificial intelligence and machine learning are considered the driving force of smart factory revolution. The purpose of this review was to classify the literature, including publication year, authors, scientific sector, country, institution, and keywords. The analysis was done using the Web of Science and SCOPUS database. Furthermore, UCINET and NVivo 12 software were used to complete them. A literature review on ML and AI empirical studies published in the last century was carried out to highlight the evolution of the topic before and after Industry 4.0 introduction, from 1999 to now. Eighty-two articles were reviewed and classified. A first interesting result is the greater number of works published by the USA and the increasing interest after the birth of Industry 4.0.",1
"Autoimmune illnesses are long-lasting, complex ailments that include multiple factors. Machine learning (ML), a subset of artificial intelligence, enables the identification of patterns in patient data. These patterns can be utilized to forecast patient outcomes, leading to enhanced clinical care. In this study, we examined the application of machine learning techniques to tackle clinical issues related to autoimmune diseases. A systematic review was performed utilizing the MEDLINE, Embase, and Computers and Applied Sciences Complete databases. The publications considered relevant were those that contained the terms ""machine learning"" or ""artificial intelligence"" along with the search term(s) related to autoimmune illnesses in their title, abstract, or key phrases. Exclusion criteria: studies written in languages other than English, studies lacking real human patient data, studies published before 2001, studies that were not subjected to peer review, studies focusing on comorbidity research and review papers unrelated to autoimmune diseases. A total of 169 out of 702 studies satisfied the criteria for inclusion. Support vector machines and random forests were the predominant machine learning techniques employed. The most prevalent ML models utilized data pertaining to multiple sclerosis, rheumatoid arthritis, and inflammatory bowel disease. Only a tiny fraction of research (7.7% or 13 out of 169) incorporated multiple data types during the modeling procedure. 8.3% of the studies (14 out of 169) used cross-validation and a separate testing set to evaluate their models, which helps ensure more reliable results. It would be advantageous for the field to implement a standard procedure of validating, cross-validating, and independently testing machine learning models. Several models demonstrated excellent prediction performance in straightforward circumstances, such as classifying cases and controls. Future advancements may allow for the development of more sophisticated predictive models by integrating numerous forms of data.","Autoimmune diseases are chronic, multifactorial conditions. Through machine learning (ML), a branch of the wider field of artificial intelligence, it is possible to extract patterns within patient data, and exploit these patterns to predict patient outcomes for improved clinical management. Here, we surveyed the use of ML methods to address clinical problems in autoimmune disease. A systematic review was conducted using MEDLINE, embase and computers and applied sciences complete databases. Relevant papers included “machine learning” or “artificial intelligence” and the autoimmune diseases search term(s) in their title, abstract or key words. Exclusion criteria: studies not written in English, no real human patient data included, publication prior to 2001, studies that were not peer reviewed, non-autoimmune disease comorbidity research and review papers. 169 (of 702) studies met the criteria for inclusion. Support vector machines and random forests were the most popular ML methods used. ML models using data on multiple sclerosis, rheumatoid arthritis and inflammatory bowel disease were most common. A small proportion of studies (7.7% or 13/169) combined different data types in the modelling process. Cross-validation, combined with a separate testing set for more robust model evaluation occurred in 8.3% of papers (14/169). The field may benefit from adopting a best practice of validation, cross-validation and independent testing of ML models. Many models achieved good predictive results in simple scenarios (e.g. classification of cases and controls). Progression to more complex predictive models may be achievable in future through integration of multiple data types.",1
"Drug design and development is a crucial field of study for pharmaceutical businesses and chemical researchers. Nevertheless, the obstacles of low effectiveness, inaccurate distribution, lengthy process, and exorbitant expenses provide significant problems that affect the development and exploration of new drugs. In addition, the drug discovery pipeline is hindered by the inclusion of intricate and extensive data from genomes, proteomics, microarray data, and clinical trials. Artificial intelligence and machine learning are essential in the process of drug discovery and development. Artificial neural networks and deep learning algorithms have revolutionized the field. Machine learning and deep learning algorithms have been utilized in various drug discovery procedures, including peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. The historical evidence bolsters the integration of artificial intelligence and deep learning in this domain. In addition, advanced data mining, curation, and management strategies have played a crucial role in supporting the development of new modeling algorithms. To summarize, the progress made in artificial intelligence and deep learning presents a promising chance to enhance the rational medication design and discovery process, ultimately benefiting humanity.","Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind.",1
"Artificial intelligence (AI) has gained significant attention due to groundbreaking technological advancements and remarkable experimental outcomes, particularly in the domain of picture analysis and processing. Within the field of medicine, several specializations such as radiology, pathology, and oncology have recognized the significance of utilizing images. As a result, substantial research and development efforts have been dedicated to harnessing the capabilities of artificial intelligence (AI) for therapeutic purposes. As AI becomes increasingly common in medical imaging analytic activities like diagnosis, segmentation, and classification, the safe and efficient use of clinical AI applications depends, in part, on well-informed practitioners. The objective of this review is to provide an overview of the fundamental technological foundations of artificial intelligence (AI), together with the most advanced machine learning techniques and their utilization in the field of medical imaging. Furthermore, we delve into the emerging patterns and prospective avenues for future investigation. This text aims to elucidate the increasing prevalence of AI approaches in medical image analysis workflows and their potential to facilitate the adoption of AI-based solutions in clinical settings.","Artificial intelligence (AI) has recently become a very popular buzzword, as a consequence of disruptive technical advances and impressive experimental results, notably in the field of image analysis and processing. In medicine, specialties where images are central, like radiology, pathology or oncology, have seized the opportunity and considerable efforts in research and development have been deployed to transfer the potential of AI to clinical applications. With AI becoming a more mainstream tool for typical medical imaging analysis tasks, such as diagnosis, segmentation, or classification, the key for a safe and efficient use of clinical AI applications relies, in part, on informed practitioners. The aim of this review is to present the basic technological pillars of AI, together with the state-of-the-art machine learning methods and their application to medical imaging. In addition, we discuss the new trends and future research directions. This will help the reader to understand how AI methods are now becoming an ubiquitous tool in any medical image analysis workflow and pave the way for the clinical implementation of AI-based solutions.",1
"However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research.","This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research.",2
"Artificial intelligence (AI) is developing and its application is spreading at an alarming rate, and AI has become part of our daily lives. A review of available and relevant literature was done using the systematic review method to identify the current research focus and provide an in-depth understanding of AI technology in education for educators and future research directions. As a matter of fact, AI has changed the way people learn. The purpose of this study is to analyze the opportunities, benefits, and challenges of AI in education. However, its adoption in the educational sector has been saddled with challenges and ethical issues. Findings showed that AI's adoption in education has advanced in the developed countries and most research became popular within the Industry 4.0 era. Other challenges, as well as recommendations, are discussed in the study.","Artificial intelligence (AI) is developing and its application is spreading at an alarming rate, and AI has become part of our daily lives. As a matter of fact, AI has changed the way people learn. However, its adoption in the educational sector has been saddled with challenges and ethical issues. The purpose of this study is to analyze the opportunities, benefits, and challenges of AI in education. A review of available and relevant literature was done using the systematic review method to identify the current research focus and provide an in-depth understanding of AI technology in education for educators and future research directions. Findings showed that AI's adoption in education has advanced in the developed countries and most research became popular within the Industry 4.0 era. Other challenges, as well as recommendations, are discussed in the study.",2
"Finally, the article offers recommendations for AIED scholars on strategies for engagement with the policymaking process, and for performing ethics and policy-oriented AIED research to that end, in order to shape policy deliberations on behalf of the public good. These documents articulate plans and expectations regarding how AI will impact policy sectors, including education, and typically discuss the social and ethical implications of AI. This article engages in thematic analysis of 24 such national AI policy strategies, reviewing the role of education in global AI policy discourse. In light of these findings, the article applies a framework of five AI ethics principles to consider ways in which policymakers can better incorporate AIED’s implications. Further, the ethical implications of AIED receive scant attention despite the prominence of AI ethics discussion generally in these documents. This suggests that AIED and its broader policy and ethical implications—good or bad—have failed to reach mainstream awareness and the agendas of key decision-makers, a concern given that effective policy and careful consideration of ethics are inextricably linked, as this article argues. It finds that the use of AI in education (AIED) is largely absent from policy conversations, while the instrumental value of education in supporting an AI-ready workforce and training more AI experts is overwhelmingly prioritized. As of 2021, more than 30 countries have released national artificial intelligence (AI) policy strategies.","As of 2021, more than 30 countries have released national artificial intelligence (AI) policy strategies. These documents articulate plans and expectations regarding how AI will impact policy sectors, including education, and typically discuss the social and ethical implications of AI. This article engages in thematic analysis of 24 such national AI policy strategies, reviewing the role of education in global AI policy discourse. It finds that the use of AI in education (AIED) is largely absent from policy conversations, while the instrumental value of education in supporting an AI-ready workforce and training more AI experts is overwhelmingly prioritized. Further, the ethical implications of AIED receive scant attention despite the prominence of AI ethics discussion generally in these documents. This suggests that AIED and its broader policy and ethical implications—good or bad—have failed to reach mainstream awareness and the agendas of key decision-makers, a concern given that effective policy and careful consideration of ethics are inextricably linked, as this article argues. In light of these findings, the article applies a framework of five AI ethics principles to consider ways in which policymakers can better incorporate AIED’s implications. Finally, the article offers recommendations for AIED scholars on strategies for engagement with the policymaking process, and for performing ethics and policy-oriented AIED research to that end, in order to shape policy deliberations on behalf of the public good.",2
"Method: A narrative synthesis and a systematic literature review were conducted in this review article. The literature and information were obtained from various books and research articles on EBSCO, Google Scholar, Scopus, Web of Science, and ScienceDirect. The inclusion criteria were studies that clearly defined artificial intelligence in the education sector, were published and written in English and were peer-reviewed. As a result, artificial intelligence technologies positively and negatively affect the education sector. Result: Artificial intelligence has already entered the education sector. Implementing artificial intelligence is a strategic and critical factor in educational development. Furthermore, artificial intelligence is increasingly being used as a digital assistant. Five independent reviewers assessed search results, extracted data, and set the studies’ quality to summarise and report the findings. However, some risks are associated with artificial intelligence advancements, such as safety, security, and privacy concerns. They assist teachers and students in various ways, including giving students access to a wide range of learning materials based on their specific learning needs and subjects. Conclusion: Artificial intelligence technologies have positive and negative effects on education. Thus, it is critical to prioritise artificial intelligence in education and implement appropriate strategies to meet teachers' and students' needs and expectations through AI technologies. As a result, academic performance will be excellent. Recommendation & Implication: Qualitative research, such as interviews, or quantitative analysis, such as online questionnaires, may be developed in the future to provide more explanations and explicit findings. The implications could be applied to school administrators, teachers, and students to understand better and implement appropriate strategies to improve educational performance through AI.","Method: A narrative synthesis and a systematic literature review were conducted in this review article. The literature and information were obtained from various books and research articles on EBSCO, Google Scholar, Scopus, Web of Science, and ScienceDirect. The inclusion criteria were studies that clearly defined artificial intelligence in the education sector, were published and written in English and were peer-reviewed. Five independent reviewers assessed search results, extracted data, and set the studies’ quality to summarise and report the findings.

Result: Artificial intelligence has already entered the education sector. Implementing artificial intelligence is a strategic and critical factor in educational development. Furthermore, artificial intelligence is increasingly being used as a digital assistant. They assist teachers and students in various ways, including giving students access to a wide range of learning materials based on their specific learning needs and subjects. However, some risks are associated with artificial intelligence advancements, such as safety, security, and privacy concerns. As a result, artificial intelligence technologies positively and negatively affect the education sector.

Conclusion: Artificial intelligence technologies have positive and negative effects on education. Thus, it is critical to prioritise artificial intelligence in education and implement appropriate strategies to meet teachers' and students' needs and expectations through AI technologies. As a result, academic performance will be excellent.

Recommendation & Implication: Qualitative research, such as interviews, or quantitative analysis, such as online questionnaires, may be developed in the future to provide more explanations and explicit findings. The implications could be applied to school administrators, teachers, and students to understand better and implement appropriate strategies to improve educational performance through AI.",2
"Artificial Intelligence (AI) is reshaping the world in profound ways; some of its impacts are certainly beneficial but widespread and lasting harms can result from the technology as well. The integration of AI into various aspects of human life is underway, and the complex ethical concerns emerging from the design, deployment, and use of the technology serves as a reminder that it is time to revisit what future developers and designers, along with professionals, are learning when it comes to AI. It is of paramount importance to train future members of the AI community, and other stakeholders as well, to reflect on the ways in which AI might impact people’s lives and to embrace their responsibilities to enhance its benefits while mitigating its potential harms. In this paper, we briefly describe different approaches to AI ethics and offer a set of recommendations related to AI ethics pedagogy. This could occur in part through the fuller and more systematic inclusion of AI ethics into the curriculum.","Artificial Intelligence (AI) is reshaping the world in profound ways; some of its impacts are certainly beneficial but widespread and lasting harms can result from the technology as well. The integration of AI into various aspects of human life is underway, and the complex ethical concerns emerging from the design, deployment, and use of the technology serves as a reminder that it is time to revisit what future developers and designers, along with professionals, are learning when it comes to AI. It is of paramount importance to train future members of the AI community, and other stakeholders as well, to reflect on the ways in which AI might impact people’s lives and to embrace their responsibilities to enhance its benefits while mitigating its potential harms. This could occur in part through the fuller and more systematic inclusion of AI ethics into the curriculum. In this paper, we briefly describe different approaches to AI ethics and offer a set of recommendations related to AI ethics pedagogy.",2
"The goal of precision education is to identify at-risk
students as early as possible and provide timely intervention on the basis of teaching and learning experiences
(Lu et al., 2018). As addressed by Stephen Yang in his ICCE 2019 keynote speech (Yang, 2019), precision
education is a new challenge when applying artificial intelligence (AI), machine learning, and learning analytics
to improve teaching quality and learning performance. For this special issue, thirteen research papers that specialize in precision education, AI, machine
learning, and learning analytics to engage in an in-depth research experiences concerning various applications,
methods, pedagogical models, and environments were exchanged to achieve better understanding of the
application of AI in education Drawing from this main theme of precision education, this special issue advocates an in-depth
dialogue between cold technology and warm humanity, in turn offering greater understanding of precision
education.","As addressed by Stephen Yang in his ICCE 2019 keynote speech (Yang, 2019), precision
education is a new challenge when applying artificial intelligence (AI), machine learning, and learning analytics
to improve teaching quality and learning performance. The goal of precision education is to identify at-risk
students as early as possible and provide timely intervention on the basis of teaching and learning experiences
(Lu et al., 2018). Drawing from this main theme of precision education, this special issue advocates an in-depth
dialogue between cold technology and warm humanity, in turn offering greater understanding of precision
education. For this special issue, thirteen research papers that specialize in precision education, AI, machine
learning, and learning analytics to engage in an in-depth research experiences concerning various applications,
methods, pedagogical models, and environments were exchanged to achieve better understanding of the
application of AI in education",2
"Based on 4,519 publications from 2000 to 2019, we attempt to fill this gap and identify trends and topics related to AI applications in education (AIEd) using topicbased bibliometrics. However, no large-scale reviews have been conducted to comprehensively investigate the various aspects of this field. With the increasing use of Artificial Intelligence (AI) technologies in education, the number of published studies in the field has increased. Results of the review reveal an increasing interest in using AI for educational purposes from the academic community. The main research topics include intelligent tutoring systems for special education; natural language processing for language education; educational robots for AI education; educational data mining for performance prediction; discourse analysis in computer-supported collaborative learning; neural networks for teaching evaluation; affective computing for learner emotion detection; and recommender systems for personalized learning. We also discuss the challenges and future directions of AIEd.","With the increasing use of Artificial Intelligence (AI) technologies in education, the number of published studies in the field has increased. However, no large-scale reviews have been conducted to comprehensively investigate the various aspects of this field. Based on 4,519 publications from 2000 to 2019, we attempt to fill this gap and identify trends and topics related to AI applications in education (AIEd) using topicbased bibliometrics. Results of the review reveal an increasing interest in using AI for educational purposes from the academic community. The main research topics include intelligent tutoring systems for special education; natural language processing for language education; educational robots for AI education; educational data mining for performance prediction; discourse analysis in computer-supported collaborative learning; neural networks for teaching evaluation; affective computing for learner emotion detection; and recommender systems for personalized learning. We also discuss the challenges and future directions of AIEd.",2
"In light of fast-growing popular, political and professional discourses around AI in education, this article outlines five broad areas of contention that merit closer attention in future discussion and decision-making. These include: (1) taking care to focus on issues relating to 'actually existing' AI rather than the overselling of speculative AI technologies; (2) clearly foregrounding the limitations of AI in terms of modelling social contexts, and simulating human intelligence, reckoning, autonomy and emotions; (3) foregrounding the social harms associated with AI use; (4) acknowledging the value-driven nature of claims around AI; and (5) paying closer attention to the environmental and ecological sustainability of continued AI development and implementation. Thus, in contrast to popular notions of AI as a neutral tool, the argument is made for engaging with the ongoing use of AI in education as a political action that has varying impacts on different groups of people in various educational contexts.","In light of fast-growing popular, political and professional discourses around AI in education, this article outlines five broad areas of contention that merit closer attention in future discussion and decision-making. These include: (1) taking care to focus on issues relating to 'actually existing' AI rather than the overselling of speculative AI technologies; (2) clearly foregrounding the limitations of AI in terms of modelling social contexts, and simulating human intelligence, reckoning, autonomy and emotions; (3) foregrounding the social harms associated with AI use; (4) acknowledging the value-driven nature of claims around AI; and (5) paying closer attention to the environmental and ecological sustainability of continued AI development and implementation. Thus, in contrast to popular notions of AI as a neutral tool, the argument is made for engaging with the ongoing use of AI in education as a political action that has varying impacts on different groups of people in various educational contexts.",2
"One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. However, it is important to also consider the limitations of this technology. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.","Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.",2
"Artificial intelligence (AI) is rapidly transforming various industries, including education. However, AI also poses several challenges, such as
ethical concerns, potential biases, and the need for re-skilling the workforce. The research work employs a systematic review
methodology, examining the literature on AI in educational management. This research work aims to explore the
application of AI in educational management, including its benefits and challenges. The research concludes that AI has an enormous capacity
to improve educational management, but it must be deployed with care and caution. AI is being used in educational management
to enhance the learning process, improve student outcomes, and streamline administrative tasks. The study finds that AI has several advantages, including
improving student engagement, personalization of learning, and cost-effectiveness.","Artificial intelligence (AI) is rapidly transforming various industries, including education. AI is being used in educational management
to enhance the learning process, improve student outcomes, and streamline administrative tasks. This research work aims to explore the
application of AI in educational management, including its benefits and challenges. The research work employs a systematic review
methodology, examining the literature on AI in educational management. The study finds that AI has several advantages, including
improving student engagement, personalization of learning, and cost-effectiveness. However, AI also poses several challenges, such as
ethical concerns, potential biases, and the need for re-skilling the workforce. The research concludes that AI has an enormous capacity
to improve educational management, but it must be deployed with care and caution.",2
"These advanced algorithms are designed for rapid and precise diagnosis, enabling swift interventions to prevent visual impairment by identifying intricate patterns that are invisible to the human eye. The primary aim of this initiative is to address all forms of diabetic retinopathy using cutting-edge AI techniques, including deep neural networks and machine learning. The smart vision initiative sets the stage for a future where diabetic retinopathy no longer leads to blindness, offering a brighter, clearer, and safer optical future for those affected by the condition. Through the identification of complex patterns that are invisible to the human eye, these algorithms guarantee quick and accurate diagnosis. This early detection is crucial as it allows for immediate care, significantly reducing the risk of irreversible vision loss. Using artificial intelligence (AI) to its transformative advantage, the smart vision initiative represents a paradigm shift in the diagnostics and treatment of diabetic retinopathy.","Using artificial intelligence (AI) to its transformative advantage, the smart vision initiative represents a paradigm shift in the diagnostics and treatment of diabetic retinopathy. The primary aim of this initiative is to address all forms of diabetic retinopathy using cutting-edge AI techniques, including deep neural networks and machine learning. These advanced algorithms are designed for rapid and precise diagnosis, enabling swift interventions to prevent visual impairment by identifying intricate patterns that are invisible to the human eye. Through the identification of complex patterns that are invisible to the human eye, these algorithms guarantee quick and accurate diagnosis. This early detection is crucial as it allows for immediate care, significantly reducing the risk of irreversible vision loss. The smart vision initiative sets the stage for a future where diabetic retinopathy no longer leads to blindness, offering a brighter, clearer, and safer optical future for those affected by the condition.",2
"The way healthcare is provided could be completely changed by the application of artificial intelligence (AI) and computer vision (CV). The difficulties of employing computer vision in healthcare are also covered in the chapter, including data privacy concerns, bias, legal concerns, a lack of accessibility, and the complexity of biological systems. Improved diagnosis, lower costs, personalized treatment, better patient outcomes, and quicker drug discovery are all advantages of employing AI-assisted computer vision in healthcare. AI-enhanced computer vision can be applied to medical picture analysis, disease detection, patient health monitoring, surgical assistance, drug discovery acceleration, and the creation of individualized treatment programs. The sorts of computer vision utilized in healthcare systems are discussed in this chapter, including medical image analysis, disease diagnosis, movement and gait analysis, surgical support, behavioral analysis, and medication discovery. Overall, AI-assisted computer vision holds immense promise for revolutionizing healthcare systems by enabling quicker and more accurate diagnosis, enhancing patient outcomes, and cutting costs. However, the application of these technologies also presents difficulties in terms of data privacy, bias, and legal matters. To make sure that these technologies are used in an ethical and responsible manner, it is crucial to address the issues related to them.","The way healthcare is provided could be completely changed by the application of artificial intelligence (AI) and computer vision (CV). AI-enhanced computer vision can be applied to medical picture analysis, disease detection, patient health monitoring, surgical assistance, drug discovery acceleration, and the creation of individualized treatment programs. Improved diagnosis, lower costs, personalized treatment, better patient outcomes, and quicker drug discovery are all advantages of employing AI-assisted computer vision in healthcare. However, the application of these technologies also presents difficulties in terms of data privacy, bias, and legal matters. The sorts of computer vision utilized in healthcare systems are discussed in this chapter, including medical image analysis, disease diagnosis, movement and gait analysis, surgical support, behavioral analysis, and medication discovery. The difficulties of employing computer vision in healthcare are also covered in the chapter, including data privacy concerns, bias, legal concerns, a lack of accessibility, and the complexity of biological systems. Overall, AI-assisted computer vision holds immense promise for revolutionizing healthcare systems by enabling quicker and more accurate diagnosis, enhancing patient outcomes, and cutting costs. To make sure that these technologies are used in an ethical and responsible manner, it is crucial to address the issues related to them.",2
"Agriculture is the ultimate imperative and primary source of origin to furnish domestic income for multifarious countries. The plant disease syndrome is noticeable in distinct parts of plants. Computer vision, deep learning, few-shot learning, and soft computing techniques are utilized by various investigators to automatically identify the disease in plants via leaf images. Thus, recognition of plant disease is essential. Hence, this review helps the investigator to automatically detect disease in plants using machine learning, deep learning and few shot learning and provide certain diagnosis techniques to prevent disease. Nonetheless, commonly the infection is detected in distinct leaves of plants. The security of crops concerning quality and quantity is crucial to monitor disease in plants. Moreover, some of the future works in the classification of disease are also discussed. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. Also, certain molecular techniques have been established to prevent and mitigate the pathogenic threat. The disease caused in plants due to various pathogens like viruses, fungi, and bacteria is liable for considerable monetary losses in the agriculture corporation across the world. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops.","Agriculture is the ultimate imperative and primary source of origin to furnish domestic income for multifarious countries. The disease caused in plants due to various pathogens like viruses, fungi, and bacteria is liable for considerable monetary losses in the agriculture corporation across the world. The security of crops concerning quality and quantity is crucial to monitor disease in plants. Thus, recognition of plant disease is essential. The plant disease syndrome is noticeable in distinct parts of plants. Nonetheless, commonly the infection is detected in distinct leaves of plants. Computer vision, deep learning, few-shot learning, and soft computing techniques are utilized by various investigators to automatically identify the disease in plants via leaf images. These techniques also benefit farmers in achieving expeditious and appropriate actions to avoid a reduction in the quality and quantity of crops. The application of these techniques in the recognition of disease can avert the disadvantage of origin by a factious selection of disease features, extraction of features, and boost the speed of technology and efficiency of research. Also, certain molecular techniques have been established to prevent and mitigate the pathogenic threat. Hence, this review helps the investigator to automatically detect disease in plants using machine learning, deep learning and few shot learning and provide certain diagnosis techniques to prevent disease. Moreover, some of the future works in the classification of disease are also discussed.",2
"The sphere of artificial intelligence (AI) technology is quite wide. There are many individual and collaborative AI-based technologies available. One of them is computer vision technology. Computer vision is also related to other technologies: Machine learning (ML), deep learning (DL), artificial neural networks, etc. One of the areas where it has been widely applied in recent times is healthcare. Computer vision is applied in many different areas. Also, the example of tumor detection by computer vision in a MATLAB environment is considered. In this chapter, the concept of computer vision, its fields of application, and its application in healthcare are reviewed. In healthcare, various algorithms in the aforementioned technologies are used to obtain meaningful information from medical images.","The sphere of artificial intelligence (AI) technology is quite wide. There are many individual and collaborative AI-based technologies available. One of them is computer vision technology. Computer vision is also related to other technologies: Machine learning (ML), deep learning (DL), artificial neural networks, etc. Computer vision is applied in many different areas. One of the areas where it has been widely applied in recent times is healthcare. In healthcare, various algorithms in the aforementioned technologies are used to obtain meaningful information from medical images. In this chapter, the concept of computer vision, its fields of application, and its application in healthcare are reviewed. Also, the example of tumor detection by computer vision in a MATLAB environment is considered.",2
"Inverse gas chromatography (IGC) has emerged as a highly sensitive, adaptable, and effective technology for material analysis. These insights contribute to a deeper understanding of material behavior and aid in the design and optimization of advanced materials. In this comprehensive review, we delve into the historical background, instrumentation, and diverse applications of IGC. Researchers and practitioners will find valuable information on the selection and description of numerous models used in IGC experiments. The applications of IGC span various domains, including polymers, medicines, minerals, surfactants, and nanomaterials. Furthermore, IGC facilitates the measurement of important parameters such as sorption enthalpy and entropy, surface energy components (dispersive and specific), co/adhesion work, glass transition temperature, surface heterogeneity, miscibility, solubility parameters, and specific surface area. Through employing thermochemical approaches, IGC provides crucial insight into physicochemical information of materials such as dispersive surface free energy, Gibbs surface energy components and Guttamann Lewis acid-base parameters. Moreover, the integration of computer vision and image processing techniques with IGC has enhanced our understanding of materials intricate surface texture, roughness, and related properties. This convergence of IGC with computer vision and artificial intelligence (AI) presents exciting opportunities for future exploration of chemical materials, opening new avenues for research and discovery. This paper not only provides a comprehensive overview of IGC, its techniques, and applications but also highlights the synergistic potential of combining IGC with AI and computer vision. The informative content and insights presented here will benefit researchers, scientists, and professionals in the field of advanced materials, enabling them to leverage IGC and AI for innovative materials discovery and development.","Inverse gas chromatography (IGC) has emerged as a highly sensitive, adaptable, and effective technology for material analysis. Through employing thermochemical approaches, IGC provides crucial insight into physicochemical information of materials such as dispersive surface free energy, Gibbs surface energy components and Guttamann Lewis acid-base parameters. In this comprehensive review, we delve into the historical background, instrumentation, and diverse applications of IGC. Researchers and practitioners will find valuable information on the selection and description of numerous models used in IGC experiments. The applications of IGC span various domains, including polymers, medicines, minerals, surfactants, and nanomaterials. Furthermore, IGC facilitates the measurement of important parameters such as sorption enthalpy and entropy, surface energy components (dispersive and specific), co/adhesion work, glass transition temperature, surface heterogeneity, miscibility, solubility parameters, and specific surface area. These insights contribute to a deeper understanding of material behavior and aid in the design and optimization of advanced materials. Moreover, the integration of computer vision and image processing techniques with IGC has enhanced our understanding of materials intricate surface texture, roughness, and related properties. This convergence of IGC with computer vision and artificial intelligence (AI) presents exciting opportunities for future exploration of chemical materials, opening new avenues for research and discovery. This paper not only provides a comprehensive overview of IGC, its techniques, and applications but also highlights the synergistic potential of combining IGC with AI and computer vision. The informative content and insights presented here will benefit researchers, scientists, and professionals in the field of advanced materials, enabling them to leverage IGC and AI for innovative materials discovery and development.",2
"At present, the application of Artificial Intelligence (AI) in industrial control, smart home and other fields has received good response. At present, the visual platform of embedded system has achieved remarkable results in practical applications, but its development has been seriously hampered by problems such as low overall development efficiency and unstable system performance. It showed the positive relationship between AI technology and EP VS. This paper designed an EP Vision System (VS) based on AI technology. The proportion of positive evaluation of System X was much higher than that of System Y, which indicated that System X can meet the actual application requirements and improve the system recognition efficiency to a certain extent. The test results showed that when other conditions were the same, students and experts had 83.5% and 90% positive evaluations of System X, and 16.5% and 10% negative evaluations respectively. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. The platform combined the embedded hardware design with the Support Vector Machine (SVM) algorithm to realize the intelligent robot interaction and target detection functions. However, AI technology has certain requirements for computer performance, and also faces problems in network security, data analysis, human-computer interaction, etc.","At present, the application of Artificial Intelligence (AI) in industrial control, smart home and other fields has received good response. However, AI technology has certain requirements for computer performance, and also faces problems in network security, data analysis, human-computer interaction, etc. At present, the visual platform of embedded system has achieved remarkable results in practical applications, but its development has been seriously hampered by problems such as low overall development efficiency and unstable system performance. This paper designed an EP Vision System (VS) based on AI technology. The platform combined the embedded hardware design with the Support Vector Machine (SVM) algorithm to realize the intelligent robot interaction and target detection functions. The test results showed that when other conditions were the same, students and experts had 83.5% and 90% positive evaluations of System X, and 16.5% and 10% negative evaluations respectively. However, their positive evaluation of System Y only accounted for 19% and 4%, while the negative evaluation accounted for 81% and 96%. The proportion of positive evaluation of System X was much higher than that of System Y, which indicated that System X can meet the actual application requirements and improve the system recognition efficiency to a certain extent. It showed the positive relationship between AI technology and EP VS.",2
"Many Artificial Intelligence based foundation models have been proposed for smart sensing to recognize the known object classes in the new but similar scenarios. Several representative case studies are discussed to show the potential usages of Sora-based Parallel Vision, followed by its future research direction. However, it is still challenging for the foundation models of smart sensing to detect all the object classes in both seen and unseen scenarios. This letter aims at pushing the boundary of smart sensing research for intelligent vehicles. We first summarize the current widely-used foundation models and the foundation intelligence needed for smart sensing of intelligent vehicles. We then explain Sora-based Parallel Vision to boost the foundation models of smart sensing from basic intelligence (1.0) to enhanced intelligence (2.0) and final generalized intelligence (3.0). installed on the modern intelligent vehicles.","installed on the modern intelligent vehicles. Many Artificial Intelligence based foundation models have been proposed for smart sensing to recognize the known object classes in the new but similar scenarios. However, it is still challenging for the foundation models of smart sensing to detect all the object classes in both seen and unseen scenarios. This letter aims at pushing the boundary of smart sensing research for intelligent vehicles. We first summarize the current widely-used foundation models and the foundation intelligence needed for smart sensing of intelligent vehicles. We then explain Sora-based Parallel Vision to boost the foundation models of smart sensing from basic intelligence (1.0) to enhanced intelligence (2.0) and final generalized intelligence (3.0). Several representative case studies are discussed to show the potential usages of Sora-based Parallel Vision, followed by its future research direction.",2
"The application of AI and machine learning, particularly the vision transformer method, in bacterial detection presents a promising solution to overcome limitations of traditional methods, offering faster and more accurate detection of disease-causing bacteria like E. coli and salmonella in water, crucial for human survival, with ongoing research to further assess its effectiveness in microbiology. This research introduces a revolutionary positional self-attention transformer model for the classification of bacterial colonies. Leveraging the proven success of transformer architectures in various domains, we enhanced the model's performance by integrating a positional self-attention mechanism. The model's adaptability to diverse colony shapes and arrangements marks a significant advancement, promising to redefine the landscape of bacterial colony classification through the lens of state-of-the-art deep learning techniques. We trained the model on a substantial dataset of bacterial images, which ensures its robustness and generalization to diverse colony types. This allows the model to effectively capture spatial relationships and patterns within bacterial colonies, contributing to highly accurate classification results. The proposed model adeptly captured the spatial relationships and sequential patterns inherent in bacterial colony images, allowing for more accurate and robust classification. The proposed model demonstrated remarkable performance, achieving an accuracy of 98.50% in the classification of bacterial colonies. This novel approach surpasses traditional methods by effectively capturing intricate spatial relationships within microbial structures, offering unprecedented accuracy in discerning subtle morphological variations. We presented a novel approach for bacterial colony classification utilizing a positional self-attention transformer model. The high classification accuracy attained by the model, suggests its potential for practical applications in the early diagnosis of infectious diseases and the development of targeted treatments. The findings of this study underscore the effectiveness of incorporating positional self-attention in transformer models for image-based classification tasks, particularly in the domain of bacterial colony analysis.","The application of AI and machine learning, particularly the vision transformer method, in bacterial detection presents a promising solution to overcome limitations of traditional methods, offering faster and more accurate detection of disease-causing bacteria like E. coli and salmonella in water, crucial for human survival, with ongoing research to further assess its effectiveness in microbiology. This research introduces a revolutionary positional self-attention transformer model for the classification of bacterial colonies. Leveraging the proven success of transformer architectures in various domains, we enhanced the model's performance by integrating a positional self-attention mechanism. We presented a novel approach for bacterial colony classification utilizing a positional self-attention transformer model. This allows the model to effectively capture spatial relationships and patterns within bacterial colonies, contributing to highly accurate classification results. We trained the model on a substantial dataset of bacterial images, which ensures its robustness and generalization to diverse colony types. The proposed model adeptly captured the spatial relationships and sequential patterns inherent in bacterial colony images, allowing for more accurate and robust classification. The proposed model demonstrated remarkable performance, achieving an accuracy of 98.50% in the classification of bacterial colonies. This novel approach surpasses traditional methods by effectively capturing intricate spatial relationships within microbial structures, offering unprecedented accuracy in discerning subtle morphological variations. The model's adaptability to diverse colony shapes and arrangements marks a significant advancement, promising to redefine the landscape of bacterial colony classification through the lens of state-of-the-art deep learning techniques. The high classification accuracy attained by the model, suggests its potential for practical applications in the early diagnosis of infectious diseases and the development of targeted treatments. The findings of this study underscore the effectiveness of incorporating positional self-attention in transformer models for image-based classification tasks, particularly in the domain of bacterial colony analysis.",2
"The research on lane keeping and recognition, obstacle detection and avoidance, traffic signal and sign recognition is of great practical significance. In these technologies, computer vision, as a direct entry point to data processing, is an integral part of autonomous driving. Secondly, it brings revolutionary changes to the future transportation system. The application of image processing and computer vision in autonomous driving plays a key role in enabling vehicles to perceive and understand the surrounding environment and achieve intelligent decision-making and control. Therefore, in combination with the application of computer vision and artificial intelligence in automatic driving, this paper expounds the image processing technology in automatic driving, including camera and sensor technology, image acquisition and preprocessing, feature extraction and object detection, so as to discuss the application of computer vision algorithm in automatic driving. Autonomous vehicle is a typical high-tech comprehensive application, including scene perception, optimization calculation, multi-level assisted driving and other functions, using computer vision, sensors, information fusion, information communication, high-performance computing, artificial intelligence and automatic control and other technologies.","Autonomous vehicle is a typical high-tech comprehensive application, including scene perception, optimization calculation, multi-level assisted driving and other functions, using computer vision, sensors, information fusion, information communication, high-performance computing, artificial intelligence and automatic control and other technologies. In these technologies, computer vision, as a direct entry point to data processing, is an integral part of autonomous driving. Secondly, it brings revolutionary changes to the future transportation system. The application of image processing and computer vision in autonomous driving plays a key role in enabling vehicles to perceive and understand the surrounding environment and achieve intelligent decision-making and control. Therefore, in combination with the application of computer vision and artificial intelligence in automatic driving, this paper expounds the image processing technology in automatic driving, including camera and sensor technology, image acquisition and preprocessing, feature extraction and object detection, so as to discuss the application of computer vision algorithm in automatic driving. The research on lane keeping and recognition, obstacle detection and avoidance, traffic signal and sign recognition is of great practical significance.",2
"Medical image segmentation is a crucial task in computer vision, playing a pivotal role in applications such as diagnostics, treatment planning, and medical research. The present study explores a wide range of methodologies employed in the field of medical research to achieve image segmentation. These techniques range from traditional approaches based on thresholding, edge detection, region-based and clustering, to modern artificial intelligence methods, particularly deep learning techniques. The strengths and limitations of each method are thoroughly examined. It aims to delve deeply into the different segmentation methods, offering a comparative perspective on their effectiveness. Through an exhaustive compilation and detailed critique of the results obtained by employing a range of segmentation strategies, the study presents the outcomes of multiple approaches, accompanied by an in-depth analysis of the strengths and weaknesses inherent to the various techniques applied to medical image segmentation. Furthermore, This document delves into the most recent technological progress in segmentation, emphasizing major breakthroughs capable of transforming the precision and productivity of analyzing medical images. This paper focuses on analyzing various architectures used for medical image segmentation, specifically evaluating their performance. This research enhances the comprehension of how these methods can be applied within the medical sector, especially in the area of computer vision.","Medical image segmentation is a crucial task in computer vision, playing a pivotal role in applications such as diagnostics, treatment planning, and medical research. The present study explores a wide range of methodologies employed in the field of medical research to achieve image segmentation. These techniques range from traditional approaches based on thresholding, edge detection, region-based and clustering, to modern artificial intelligence methods, particularly deep learning techniques. The strengths and limitations of each method are thoroughly examined. This paper focuses on analyzing various architectures used for medical image segmentation, specifically evaluating their performance. It aims to delve deeply into the different segmentation methods, offering a comparative perspective on their effectiveness. Furthermore, This document delves into the most recent technological progress in segmentation, emphasizing major breakthroughs capable of transforming the precision and productivity of analyzing medical images. Through an exhaustive compilation and detailed critique of the results obtained by employing a range of segmentation strategies, the study presents the outcomes of multiple approaches, accompanied by an in-depth analysis of the strengths and weaknesses inherent to the various techniques applied to medical image segmentation. This research enhances the comprehension of how these methods can be applied within the medical sector, especially in the area of computer vision.",2
"This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The discussion and conclusions emphasize the potential of A.I. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology.","This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. The discussion and conclusions emphasize the potential of A.I. and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy.",2
"The face is the most essential part of the human body, and because of its distinctive traits, it is crucial for recognizing people. Facial recognition technology (FRT) is one of the most successful and fascinating technologies of the modern times. Businesses are replacing conventional fingerprint scanners with artificial intelligence—based FRT, opening up enormous commercial prospects. Security and surveillance, authentication/access control systems, digital healthcare, photo retrieval, etc., are some sectors where its use has become essential. Due to its contactless biometric characteristics, FRT is becoming quite popular worldwide. The world is moving towards contactless FRT after the COVID-19 pandemic. In the present communication, we presented the global adoption of FRT, its rising trend in the market, utilization of the technology in various sectors, its challenges and rising concerns with special reference to India and worldwide.","The face is the most essential part of the human body, and because of its distinctive traits, it is crucial for recognizing people. Facial recognition technology (FRT) is one of the most successful and fascinating technologies of the modern times. The world is moving towards contactless FRT after the COVID-19 pandemic. Due to its contactless biometric characteristics, FRT is becoming quite popular worldwide. Businesses are replacing conventional fingerprint scanners with artificial intelligence—based FRT, opening up enormous commercial prospects. Security and surveillance, authentication/access control systems, digital healthcare, photo retrieval, etc., are some sectors where its use has become essential. In the present communication, we presented the global adoption of FRT, its rising trend in the market, utilization of the technology in various sectors, its challenges and rising concerns with special reference to India and worldwide.",2
"Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. This timeline illustrates the progression and development of the techniques and data resources used in FER. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) to the deep learning era. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.","Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of the techniques and data resources used in FER. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) to the deep learning era. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.",2
"Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. This timeline illustrates the progression and development of the techniques and data resources used in FER. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. to the deep learning era. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.","Recent technological developments have enabled computers to identify and categorize facial expressions to determine a person’s emotional state in an image or a video. This process, called “Facial Expression Recognition (FER)”, has become one of the most popular research areas in computer vision. In recent times, deep FER systems have primarily concentrated on addressing two significant challenges: the problem of overfitting due to limited training data availability, and the presence of expression-unrelated variations, including illumination, head pose, image resolution, and identity bias. In this paper, a comprehensive survey is provided on deep FER, encompassing algorithms and datasets that offer insights into these intrinsic problems. Initially, this paper presents a detailed timeline showcasing the evolution of methods and datasets in deep facial expression recognition (FER). This timeline illustrates the progression and development of the techniques and data resources used in FER. Then, a comprehensive review of FER methods is introduced, including the basic principles of FER (components such as preprocessing, feature extraction and classification, and methods, etc.) from the pro-deep learning era (traditional methods using handcrafted features, i.e., SVM and HOG, etc.) to the deep learning era. Moreover, a brief introduction is provided related to the benchmark datasets (there are two categories: controlled environments (lab) and uncontrolled environments (in the wild)) used to evaluate different FER methods and a comparison of different FER models. Existing deep neural networks and related training strategies designed for FER, based on static images and dynamic image sequences, are discussed. The remaining challenges and corresponding opportunities in FER and the future directions for designing robust deep FER systems are also pinpointed.",2
"Facial recognition is a well-established and popular field in Computer Vision, especially with advancements in deep learning and data sets. Deep facial recognition has made significant progress and is widely applied in real-world scenarios. Current algorithms achieve only 40.8 MAPS on modern objects, so careful dataset selection is crucial for optimal results. A complete facial recognition system involves three main components: facial recognition, orientation, and representation. While image classification accuracy is nearing 2.25%, surpassing human performance, object detection algorithms are still in the early stages. Object detection in machine vision is a challenging area that requires significant improvements. This article provides a detailed overview of the latest advancements in these areas, showing how deep learning has greatly enhanced their abilities. This system detects faces, aligns them to a standard view, and extracts features for recognition using deep convolutional neural networks.","Facial recognition is a well-established and popular field in Computer Vision, especially with advancements in deep learning and data sets. Deep facial recognition has made significant progress and is widely applied in real-world scenarios. A complete facial recognition system involves three main components: facial recognition, orientation, and representation. This system detects faces, aligns them to a standard view, and extracts features for recognition using deep convolutional neural networks. This article provides a detailed overview of the latest advancements in these areas, showing how deep learning has greatly enhanced their abilities. Object detection in machine vision is a challenging area that requires significant improvements. While image classification accuracy is nearing 2.25%, surpassing human performance, object detection algorithms are still in the early stages. Current algorithms achieve only 40.8 MAPS on modern objects, so careful dataset selection is crucial for optimal results.",2
"Despite being widely deployed in countries such as Russia and China, for pandemic purposes and beyond, western jurisdictions are much more reluctant to adopt it. Nonetheless, FRT presents some ethical and legal challenges, such as its use without ensuring consent from the individuals under surveillance, the protection of biometric data collected through surveillance, and the risk of using this information for other purposes besides public health. When properly used, FRT can support governments’ strategies to implement public health surveillance, which is defined in the literature as ‘the systematic collection, storage, usage, and dissemination of personal information to identify an outbreak and mitigate the spread of disease’. As planning for future pandemics is currently underway, this technology is envisioned as an efficient tool to track infected individuals and collect real-time surveillance data. Facial recognition technology (FRT) is one of several artificial intelligence (AI)-based technologies used during the COVID-19 pandemic to control the spread of the virus.","Facial recognition technology (FRT) is one of several artificial intelligence (AI)-based technologies used during the COVID-19 pandemic to control the spread of the virus. As planning for future pandemics is currently underway, this technology is envisioned as an efficient tool to track infected individuals and collect real-time surveillance data. When properly used, FRT can support governments’ strategies to implement public health surveillance, which is defined in the literature as ‘the systematic collection, storage, usage, and dissemination of personal information to identify an outbreak and mitigate the spread of disease’.
Nonetheless, FRT presents some ethical and legal challenges, such as its use without ensuring consent from the individuals under surveillance, the protection of biometric data collected through surveillance, and the risk of using this information for other purposes besides public health. Despite being widely deployed in countries such as Russia and China, for pandemic purposes and beyond, western jurisdictions are much more reluctant to adopt it.",2
"Harbouring the power of deep learning and artificial intelligence, one of the most important applications of computer vision is Patient Identification. In public health emergencies, such as pandemics, natural disasters, or other calamities, hospitals, and medical centres experience a sudden influx of patients, and hospital management faces difficulties in keeping track of patients, especially when they need to be moved between facilities or when new temporary healthcare facilities are set up. As a consequence of these challenges, there can be an increase in missing person cases. Patients may be inadvertently separated from their families. In this study, we have proposed a state-of-the-art patient face detection model using a twofold model that uses MTCNN short for “multi-task cascaded convolution neural network” for face detection and alignment purposes with a FaceNet Convolutional Neural Network (CNN) a renowned face embedding algorithm finally with KNN algorithm as a classifier to get an accuracy of 97.1%. Also, to ensure public safety during the pandemic we have constituted a Resnet34 model for mask detection trained on the Face Mask Detection dataset with an accuracy of 97%. The human face is a unique biometric system that can determine the age, gender, mood, of an individual, and even identity for verification purposes. During the COVID-19 pandemic, Delhi, India, faced a pressing issue where approximately 1,500 COVID-19-positive patients went missing. This study not only addresses the immediate challenges of patient identification and safety during crises but also carries implications for broader healthcare applications. The proposed models offer promising avenues for enhancing patient care and security.","During the COVID-19 pandemic, Delhi, India, faced a pressing issue where approximately 1,500 COVID-19-positive patients went missing. In public health emergencies, such as pandemics, natural disasters, or other calamities, hospitals, and medical centres experience a sudden influx of patients, and hospital management faces difficulties in keeping track of patients, especially when they need to be moved between facilities or when new temporary healthcare facilities are set up. As a consequence of these challenges, there can be an increase in missing person cases. Patients may be inadvertently separated from their families. The human face is a unique biometric system that can determine the age, gender, mood, of an individual, and even identity for verification purposes. Harbouring the power of deep learning and artificial intelligence, one of the most important applications of computer vision is Patient Identification. In this study, we have proposed a state-of-the-art patient face detection model using a twofold model that uses MTCNN short for “multi-task cascaded convolution neural network” for face detection and alignment purposes with a FaceNet Convolutional Neural Network (CNN) a renowned face embedding algorithm finally with KNN algorithm as a classifier to get an accuracy of 97.1%. Also, to ensure public safety during the pandemic we have constituted a Resnet34 model for mask detection trained on the Face Mask Detection dataset with an accuracy of 97%. This study not only addresses the immediate challenges of patient identification and safety during crises but also carries implications for broader healthcare applications. The proposed models offer promising avenues for enhancing patient care and security.",2
"Each pillar of the PERMA model is evaluated as a regression or classification problem using machine learning algorithms. Understanding and promoting individual well-being is essential for staff health and long-term success, but current tools for assessing subjective well-being rely on time-consuming surveys and questionnaires, which limit the possibility of providing the real-time feedback needed to raise awareness and change individual behavior. This paper proposes a framework for understanding the process of non-verbal communication in teamwork, using video data to identify significant predictors of individual well-being in teamwork. These promising results point to interesting avenues for research, for instance fusing different media for the analysis of individual well-being in teamwork. Statistical analysis is applied to each time series, leading to the generation of a dataset of 125 features, which are then linked to PERMA (Positive Emotion, Engagement, Relationships, Meaning, and Accomplishments) surveys developed in the context of positive psychology. Our approach was applied to a case study, where 80 students collaborated in 20 teams for a week on a team task in a face-to-face setting. 
Well-being is one of the pillars of positive psychology, which is known to have positive effects not only on the personal and professional lives of individuals but also on teams and organizations. This enabled us to formulate several hypotheses identifying factors influencing individual well-being in teamwork. It relies on video acquisition technologies and state-of-the-art artificial intelligence tools to extract individual, relative, and environmental characteristics from panoramic video.","Well-being is one of the pillars of positive psychology, which is known to have positive effects not only on the personal and professional lives of individuals but also on teams and organizations. Understanding and promoting individual well-being is essential for staff health and long-term success, but current tools for assessing subjective well-being rely on time-consuming surveys and questionnaires, which limit the possibility of providing the real-time feedback needed to raise awareness and change individual behavior. This paper proposes a framework for understanding the process of non-verbal communication in teamwork, using video data to identify significant predictors of individual well-being in teamwork. It relies on video acquisition technologies and state-of-the-art artificial intelligence tools to extract individual, relative, and environmental characteristics from panoramic video. Statistical analysis is applied to each time series, leading to the generation of a dataset of 125 features, which are then linked to PERMA (Positive Emotion, Engagement, Relationships, Meaning, and Accomplishments) surveys developed in the context of positive psychology. Each pillar of the PERMA model is evaluated as a regression or classification problem using machine learning algorithms. Our approach was applied to a case study, where 80 students collaborated in 20 teams for a week on a team task in a face-to-face setting. This enabled us to formulate several hypotheses identifying factors influencing individual well-being in teamwork. These promising results point to interesting avenues for research, for instance fusing different media for the analysis of individual well-being in teamwork.",2
"Thereby, this paper deals with a system which could recognize the face of the intruder through surveillance camera using ML and AI based algorithms. For safety most of the household is having CC cameras such that they could recognize the persons from it. Face recognition has a very important role in various applications, from security, surveillance to authentication. In few highly secured places where allowance to any unknown intruder is strictly prohibited. These CCTV are allocated for having safety and to know who visited their houses. The design specified is successfully implemented using HOG feature extraction and SVM classification algorithms and it classifies the faces for a video stream given as input. The major objective entitled to this paper is to recognize the faces of people from the video by HOG feature extractor and classify them using SVM and train the machine to tell who is the person working for the organization and who are the intruder.","Face recognition has a very important role in various applications, from security, surveillance to authentication. For safety most of the household is having CC cameras such that they could recognize the persons from it. These CCTV are allocated for having safety and to know who visited their houses. In few highly secured places where allowance to any unknown intruder is strictly prohibited. Thereby, this paper deals with a system which could recognize the face of the intruder through surveillance camera using ML and AI based algorithms. The design specified is successfully implemented using HOG feature extraction and SVM classification algorithms and it classifies the faces for a video stream given as input. The major objective entitled to this paper is to recognize the faces of people from the video by HOG feature extractor and classify them using SVM and train the machine to tell who is the person working for the organization and who are the intruder.",2
"The products are placed on shelves which have pressure sensors to detect if any product is picked up. These shelves are closed and they only open with your shopping cards. The idea is to make a more convenient and advanced super market experience, where there are no cashiers or lines so that we can shop hassle free. Just as technology is being used to solve all the problems so why not this one. A person just needs to walk in after scanning their QR code through the app with their unique ID on it. We look forward to provide this technology to various super market chains in the country and abroad and help them implement it with a nominal one time investment. The shopping carts and baskets have sensors on them, which can detect the product entering or being taken out. The growing population also leads to a growing consumer base which increases the load and resources to cater the needs of the day-by-day increasing consumers. When you reach the counter, you only have swipe your card again and money will be deducted from your account according to your purchase and a receipt will be given. This project implements Artificial Intelligence and Internet of Things to automate a supermarket for better efficiency. It will record the customer's presence in the shop.","The growing population also leads to a growing consumer base which increases the load and resources to cater the needs of the day-by-day increasing consumers. Just as technology is being used to solve all the problems so why not this one. The idea is to make a more convenient and advanced super market experience, where there are no cashiers or lines so that we can shop hassle free. This project implements Artificial Intelligence and Internet of Things to automate a supermarket for better efficiency. A person just needs to walk in after scanning their QR code through the app with their unique ID on it. It will record the customer's presence in the shop. The shopping carts and baskets have sensors on them, which can detect the product entering or being taken out. The products are placed on shelves which have pressure sensors to detect if any product is picked up. These shelves are closed and they only open with your shopping cards. When you reach the counter, you only have swipe your card again and money will be deducted from your account according to your purchase and a receipt will be given. We look forward to provide this technology to various super market chains in the country and abroad and help them implement it with a nominal one time investment.",2
"Autonomous vehicles (AVs) are expected to reshape future transportation systems, and decision making is one of the critical modules toward high-level automated driving. The datasets to be used in developing data-driven methods dramatically influence the performance of decision making; hence, it is necessary to have a comprehensive insight into the existing datasets. To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more focus. From the aspects of collection sources, driving data can be divided into vehicle-, environment-, and driver-related data. The future trends of AV dataset development are summarized. This study compares the state-of-the-art datasets of these three categories and summarizes their features, including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also discusses potential applications of datasets on various aspects of AV decision making, assisting researchers in finding appropriate ones to support their own research.","Autonomous vehicles (AVs) are expected to reshape future transportation systems, and decision making is one of the critical modules toward high-level automated driving. To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more focus. The datasets to be used in developing data-driven methods dramatically influence the performance of decision making; hence, it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle-, environment-, and driver-related data. This study compares the state-of-the-art datasets of these three categories and summarizes their features, including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also discusses potential applications of datasets on various aspects of AV decision making, assisting researchers in finding appropriate ones to support their own research. The future trends of AV dataset development are summarized.",2
"The planned trajectory is fitted by an optimization-based approach which minimizes the acceleration of the reference trajectory. In this paper, a safe and reliable motion planning and control framework is proposed to handle the tracking errors caused by inaccurate tracking by coordinating the motion planning layer and controller. The collision-free waypoint set can then be obtained by combining global search and the proposed waypoint set filtering method. The advantages and effectiveness of the proposed motion planning and control method are verified by simulation and experimental results. Accurate trajectory tracking is unrealistic in real-world scenarios, however, which is commonly assumed to facilitate motion planning algorithm design. Then, the planned trajectory is checked and modified by the designed anti-collision modification to ensure safety. Using invertible transformation and adaptive compensation allows the transient trajectory tracking errors to be limited within the designed region even with actuator faults. Because tracking error is considered and margined at the planning level, safety and reliability can be guaranteed by the coordination between the planning and control levels under inaccurate tracking and actuator faults. Specifically, motion space is divided into safe regions and risky regions by designing the movement restraint size dependent on tracking error to construct the repulsive potential field.","Accurate trajectory tracking is unrealistic in real-world scenarios, however, which is commonly assumed to facilitate motion planning algorithm design. In this paper, a safe and reliable motion planning and control framework is proposed to handle the tracking errors caused by inaccurate tracking by coordinating the motion planning layer and controller. Specifically, motion space is divided into safe regions and risky regions by designing the movement restraint size dependent on tracking error to construct the repulsive potential field. The collision-free waypoint set can then be obtained by combining global search and the proposed waypoint set filtering method. The planned trajectory is fitted by an optimization-based approach which minimizes the acceleration of the reference trajectory. Then, the planned trajectory is checked and modified by the designed anti-collision modification to ensure safety. Using invertible transformation and adaptive compensation allows the transient trajectory tracking errors to be limited within the designed region even with actuator faults. Because tracking error is considered and margined at the planning level, safety and reliability can be guaranteed by the coordination between the planning and control levels under inaccurate tracking and actuator faults. The advantages and effectiveness of the proposed motion planning and control method are verified by simulation and experimental results.",2
"This distribution of risks raises ethically relevant questions that cannot be evaded by simple heuristics such as “hitting the brakes.” Using an interactive, graphical representation of different traffic situations, we measured participants’ preferences on driving maneuvers of AVs in a representative survey in Germany. The rich literature on the ethics of autonomous vehicles (AVs) revolves around moral judgments in unavoidable collision scenarios. We argue for extending the debate to driving behaviors in everyday road traffic where ubiquitous ethical questions arise due to the permanent redistribution of risk among road users. Our research might build a bridge between engineers and philosophers to discuss the ethics of AVs more constructively. Our participants’ preferences deviated significantly from mere collision avoidance. Interestingly, our participants were willing to take risks themselves for the benefit of other road users, suggesting that the social dilemma of AVs may be mitigated in risky environments. How would people distribute risks of autonomous vehicles (AVs) in everyday road traffic?","How would people distribute risks of autonomous vehicles (AVs) in everyday road traffic? The rich literature on the ethics of autonomous vehicles (AVs) revolves around moral judgments in unavoidable collision scenarios. We argue for extending the debate to driving behaviors in everyday road traffic where ubiquitous ethical questions arise due to the permanent redistribution of risk among road users. This distribution of risks raises ethically relevant questions that cannot be evaded by simple heuristics such as “hitting the brakes.” Using an interactive, graphical representation of different traffic situations, we measured participants’ preferences on driving maneuvers of AVs in a representative survey in Germany. Our participants’ preferences deviated significantly from mere collision avoidance. Interestingly, our participants were willing to take risks themselves for the benefit of other road users, suggesting that the social dilemma of AVs may be mitigated in risky environments. Our research might build a bridge between engineers and philosophers to discuss the ethics of AVs more constructively.",2
"Artificial intelligence is one of the emerging technologies that simulate human intelligence in machines by programming it to think like human beings and mimic their actions. An autonomous vehicle can function itself and carry out necessary functions without any human involvement. Artificial intelligence is the collection of data, path planning, and execution in autonomous vehicles that require some machine learning techniques that are a part of artificial intelligence. But this comes with some privacy issues and security concerns. The autonomous vehicle's activities are supported by sensor data and a few artificial intelligence systems. This innovative technology may provide increased passenger safety, less congested roads, congestion reduction, optimum traffic, lower fuel consumption, less pollution, and better travel experiences. Autonomous vehicles play a vital role in industry, agriculture, transportation, and military applications. Security is an important concern for autonomous vehicles. The issues of cybersecurity while incorporating artificial intelligence in autonomous vehicles will be covered in this article, along with the growing technology of self-driving automobiles.","Artificial intelligence is one of the emerging technologies that simulate human intelligence in machines by programming it to think like human beings and mimic their actions. An autonomous vehicle can function itself and carry out necessary functions without any human involvement. This innovative technology may provide increased passenger safety, less congested roads, congestion reduction, optimum traffic, lower fuel consumption, less pollution, and better travel experiences. Autonomous vehicles play a vital role in industry, agriculture, transportation, and military applications. The autonomous vehicle's activities are supported by sensor data and a few artificial intelligence systems. Artificial intelligence is the collection of data, path planning, and execution in autonomous vehicles that require some machine learning techniques that are a part of artificial intelligence. But this comes with some privacy issues and security concerns. Security is an important concern for autonomous vehicles. The issues of cybersecurity while incorporating artificial intelligence in autonomous vehicles will be covered in this article, along with the growing technology of self-driving automobiles.",2
"Throughout the last decades, the number of vehicles on the road has steadily increased due to the rising demand for urban mobility and contemporary logistics. We must first examine AI's development and history in order to comprehend its functions in AV systems. The issues mentioned above can be significantly resolved by making vehicles smarter by reducing their reliance on humans. Over the past century, various nations have conducted extensive research that has fueled the automation of road vehicles. The development of autonomous vehicle (AV) technologies is currently being pursued by all significant motor manufacturers worldwide. Undoubtedly, the widespread use of autonomous cars is more imminent than we realize given the development of artificial intelligence (AI). In order for AVs to perceive their surroundings and make the right decisions in real time, AI has emerged as a crucial component. This development of AI is being driven by the growth of big data from numerous sensing devices and cutting-edge computing resources. Two of the many detrimental effects of more vehicles on the road, which also impede economic development, are increased traffic congestion and traffic accidents.","Throughout the last decades, the number of vehicles on the road has steadily increased due to the rising demand for urban mobility and contemporary logistics. Two of the many detrimental effects of more vehicles on the road, which also impede economic development, are increased traffic congestion and traffic accidents. The issues mentioned above can be significantly resolved by making vehicles smarter by reducing their reliance on humans. Over the past century, various nations have conducted extensive research that has fueled the automation of road vehicles. The development of autonomous vehicle (AV) technologies is currently being pursued by all significant motor manufacturers worldwide. Undoubtedly, the widespread use of autonomous cars is more imminent than we realize given the development of artificial intelligence (AI). In order for AVs to perceive their surroundings and make the right decisions in real time, AI has emerged as a crucial component. This development of AI is being driven by the growth of big data from numerous sensing devices and cutting-edge computing resources. We must first examine AI's development and history in order to comprehend its functions in AV systems.",2
"The future sustainability of the global automotive industry will be greatly affected by the fourth industrial revolution and the evolution of artificial intelligence (AI). The future trajectory of the AV industry is expected to be an interplay between commercial, social, risk, infrastructure, and regulatory mechanisms with various impacts on the industry’s stakeholders. In this chapter, the key factors of the autonomous vehicles (AVs) are analyzed using AI developments in radar and laser technology, commercial risk factors, self-driving consumer behavior, city infrastructure constraints, and social adaptations to new technology. The “new normal” is projected to be driven by new industry standards including an increasingly autonomous self-driving technology, amended safety standards, more complex insurance regulations, adaptive social resistance to technological change, city infrastructure requirements with a digital divide, and disruptive business innovation based on strategic input supply partnerships with open-source AI. This study predicts that the most likely sustainable scenario for the AV industry is that it will be driven by: (1) AI’s pulsed laser LiDAR (Light Detection and Ranging) with a sufficient loop frequency and GPS bi-directional cloud technology requirement, (2) pooled insurance in contrast to individual liability, (3) smart city infrastructure with expected sharp digital divide across transport regions leading to more regional inequality, and (4) customers who strongly prefer a human controlled semi-autonomous vehicle rather than complete machine autonomy.","The future sustainability of the global automotive industry will be greatly affected by the fourth industrial revolution and the evolution of artificial intelligence (AI). The “new normal” is projected to be driven by new industry standards including an increasingly autonomous self-driving technology, amended safety standards, more complex insurance regulations, adaptive social resistance to technological change, city infrastructure requirements with a digital divide, and disruptive business innovation based on strategic input supply partnerships with open-source AI. In this chapter, the key factors of the autonomous vehicles (AVs) are analyzed using AI developments in radar and laser technology, commercial risk factors, self-driving consumer behavior, city infrastructure constraints, and social adaptations to new technology. The future trajectory of the AV industry is expected to be an interplay between commercial, social, risk, infrastructure, and regulatory mechanisms with various impacts on the industry’s stakeholders. This study predicts that the most likely sustainable scenario for the AV industry is that it will be driven by: (1) AI’s pulsed laser LiDAR (Light Detection and Ranging) with a sufficient loop frequency and GPS bi-directional cloud technology requirement, (2) pooled insurance in contrast to individual liability, (3) smart city infrastructure with expected sharp digital divide across transport regions leading to more regional inequality, and (4) customers who strongly prefer a human controlled semi-autonomous vehicle rather than complete machine autonomy.",2
"In this paper, we present a novel framework that leverages Large Language Models (LLMs) to enhance autonomous vehicles' decision-making processes. Autonomous vehicles of the future will not only transport passengers but also interact and adapt to their desires, making the journey comfortable, efficient, and pleasant. By integrating LLMs' natural language capabilities and contextual understanding, specialized tools usage, synergizing reasoning, and acting with various modules on autonomous vehicles, this framework aims to seamlessly integrate the advanced language and reasoning capabilities of LLMs into autonomous vehicles. The future of autonomous vehicles lies in the convergence of human-centric design and advanced AI capabilities. The proposed framework holds the potential to revolutionize the way autonomous vehicles operate, offering personalized assistance, continuous learning, and transparent decision-making, ultimately contributing to safer and more efficient autonomous driving technologies.","The future of autonomous vehicles lies in the convergence of human-centric design and advanced AI capabilities. Autonomous vehicles of the future will not only transport passengers but also interact and adapt to their desires, making the journey comfortable, efficient, and pleasant. In this paper, we present a novel framework that leverages Large Language Models (LLMs) to enhance autonomous vehicles' decision-making processes. By integrating LLMs' natural language capabilities and contextual understanding, specialized tools usage, synergizing reasoning, and acting with various modules on autonomous vehicles, this framework aims to seamlessly integrate the advanced language and reasoning capabilities of LLMs into autonomous vehicles. The proposed framework holds the potential to revolutionize the way autonomous vehicles operate, offering personalized assistance, continuous learning, and transparent decision-making, ultimately contributing to safer and more efficient autonomous driving technologies.",2
"The potential for connected automated vehicles is multifaceted, and automated advancement deals with more of Internet of Things (IoTs) development enabling artificial intelligence (AI). Early advancements in engineering, electronics, and many other fields have inspired AI. This chapter discusses the history of autonomous vehicles (AV), trending research areas of artificial intelligence technology in AV, state-of-the-art datasets used for AV research, and several Machine Learning (ML)/Deep Learning (DL) algorithms constituting the functioning of AV as a system, concluding with the challenges and opportunities of AI in AV. In studying vehicle autonomy, there are two categories of development available: high-level system integrations like new-energy vehicles and intelligent transportation systems and the other involves backward subsystem advancement like sensor and information processing systems. Automated vehicles contribute greatly toward traffic optimization and casualty reduction. The Advanced Driver Assistance System shows results that meet the expectations of real-world problems in vehicle autonomy. Situational intelligence that collects enormous amounts of data is considered for high-definition creation of city maps, land surveying, and quality checking of roads as well. The infotainment system of the transport covers the driver's gesture recognition, language transaction, and perception of the surroundings with the assistance of a camera, Light Detection and Ranging (LiDAR), and Radio Detection And Ranging (RADAR) along with localization of the objects in the scene. There are several proposals of technologies used in automated vehicles.","The potential for connected automated vehicles is multifaceted, and automated advancement deals with more of Internet of Things (IoTs) development enabling artificial intelligence (AI). Early advancements in engineering, electronics, and many other fields have inspired AI. There are several proposals of technologies used in automated vehicles. Automated vehicles contribute greatly toward traffic optimization and casualty reduction. In studying vehicle autonomy, there are two categories of development available: high-level system integrations like new-energy vehicles and intelligent transportation systems and the other involves backward subsystem advancement like sensor and information processing systems. The Advanced Driver Assistance System shows results that meet the expectations of real-world problems in vehicle autonomy. Situational intelligence that collects enormous amounts of data is considered for high-definition creation of city maps, land surveying, and quality checking of roads as well. The infotainment system of the transport covers the driver's gesture recognition, language transaction, and perception of the surroundings with the assistance of a camera, Light Detection and Ranging (LiDAR), and Radio Detection And Ranging (RADAR) along with localization of the objects in the scene. This chapter discusses the history of autonomous vehicles (AV), trending research areas of artificial intelligence technology in AV, state-of-the-art datasets used for AV research, and several Machine Learning (ML)/Deep Learning (DL) algorithms constituting the functioning of AV as a system, concluding with the challenges and opportunities of AI in AV.",2
"Artificial intelligence is now a necessary component for both production and service systems in recent years, as technology has become a vital aspect of daily life. Self-driving automobiles can address environmental issues as well as safety-related ones. Research on autonomous vehicles has substantially advanced in recent years. These individuals can travel considerably more safely and independently. Although some people might be apprehensive to give a computer control of their vehicle, automated driving technologies have the potential to make roads safer. Self-driving technology has many advantages, one of which will make more easily accessible means of transport to people who are unable to drive. Unlike humans, computers do not really have difficulty keeping attention when driving. Additionally, by responding appropriately, an automated car can prevent accidents to potentially dangerous events on the road. Automated driving vehicles operate autonomously, also known as driverless cars that can operate without a human driver. For a variety of reasons, such as inexperience, incapacity, or age, many people are unable to operate a vehicle. Artificially intelligent autonomous vehicles are the current need of the society. Therefore, we will explore the architectures of both software and hardware of autonomous cars in this chapter, as well as their parts, benefits, and future developments.","Artificial intelligence is now a necessary component for both production and service systems in recent years, as technology has become a vital aspect of daily life. Automated driving vehicles operate autonomously, also known as driverless cars that can operate without a human driver. Research on autonomous vehicles has substantially advanced in recent years. Artificially intelligent autonomous vehicles are the current need of the society. Although some people might be apprehensive to give a computer control of their vehicle, automated driving technologies have the potential to make roads safer. Self-driving automobiles can address environmental issues as well as safety-related ones. Unlike humans, computers do not really have difficulty keeping attention when driving. Additionally, by responding appropriately, an automated car can prevent accidents to potentially dangerous events on the road. Self-driving technology has many advantages, one of which will make more easily accessible means of transport to people who are unable to drive. For a variety of reasons, such as inexperience, incapacity, or age, many people are unable to operate a vehicle. These individuals can travel considerably more safely and independently. Therefore, we will explore the architectures of both software and hardware of autonomous cars in this chapter, as well as their parts, benefits, and future developments.",2
"Central to this evolution is the integration of Artificial Intelligence (AI) and learning algorithms, propelling vehicles into realms of unprecedented autonomy. The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. This paper provides a comprehensive exploration of the evolutionary trajectory of AI within autonomous vehicles, tracing the journey from foundational principles to the most recent advancements. Commencing with a current landscape overview, the paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI and learning algorithms, and automating key tasks at each level. The study presents statistical insights into the usage and types of AI/learning algorithms over the years, showcasing the evolving research landscape within the automotive industry. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. Additionally, the document discusses the variation in software package sizes across different autonomy levels","The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolution is the integration of Artificial Intelligence (AI) and learning algorithms, propelling vehicles into realms of unprecedented autonomy. This paper provides a comprehensive exploration of the evolutionary trajectory of AI within autonomous vehicles, tracing the journey from foundational principles to the most recent advancements. Commencing with a current landscape overview, the paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. The study presents statistical insights into the usage and types of AI/learning algorithms over the years, showcasing the evolving research landscape within the automotive industry. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI and learning algorithms, and automating key tasks at each level. Additionally, the document discusses the variation in software package sizes across different autonomy levels",2
"From the research results, it was found that the implementation of artificial empathy strategies in human-AI interactions has great potential to improve the quality of interactions and customer experiences. In this context, the use of artificial empathy strategies is of particular interest due to its potential in improving customer experiences affectively and socially. This research aims to explore the optimization of human-AI interactions through the application of artificial empathy strategies in improving affective and social customer experiences. The research approach used is qualitative by reviewing various studies and related literature. The data sources used are journals, articles and books that are relevant to the research topic. Human-AI interaction has become an important focus in the development of more responsive and humane technology. The use of technologies such as natural language processing, emotion recognition, and sentiment analysis can enable AI to respond more precisely and sensitively to user needs and emotions.","Human-AI interaction has become an important focus in the development of more responsive and humane technology. In this context, the use of artificial empathy strategies is of particular interest due to its potential in improving customer experiences affectively and socially. This research aims to explore the optimization of human-AI interactions through the application of artificial empathy strategies in improving affective and social customer experiences. The research approach used is qualitative by reviewing various studies and related literature. The data sources used are journals, articles and books that are relevant to the research topic. From the research results, it was found that the implementation of artificial empathy strategies in human-AI interactions has great potential to improve the quality of interactions and customer experiences. The use of technologies such as natural language processing, emotion recognition, and sentiment analysis can enable AI to respond more precisely and sensitively to user needs and emotions.",2
"Empathy computing is an emerging research field that integrates artificial intelligence (AI) and big data technology to predict, identify, simulate, and generate human empathy. This field builds upon psychological studies in terms of concepts, measurements, neural foundations, and applications of empathy, and employs innovative computing approaches for analyzing and simulating empathy. Within the business sector, it enables organizations to deliver tailored customer experiences, thereby enhancing satisfaction and fostering loyalty through the generation of empathic dialogues. The current research on empathy computing can be categorized into four themes based on different purposes and methods. As a result, they emerge as the key application scenarios for empathy computing. This endeavor can be further divided into two categories: (1) individual empathy assessment, which focuses on analyzing individual empathetic traits, and (2) empathetic content classification, which focuses on analyzing empathetic features in texts rather than individuals. On the other hand, research also focuses on simulating and expressing empathy through computing, which includes (3) the design of empathetic response systems and (4) the development of generative empathetic dialogue systems. The former provides users with a limited number of predefined rule-based responses and feedback to express empathy, while the latter utilizes AI to automatically generate a wide range of empathetic dialogues without relying on predefined rules. These four research streams are relatively independent yet complementary. Moreover, as research progresses, new directions will continue to emerge, such as improving the empathic capabilities of computers through brain-computer interface technology. Although research on empathy computing is still in its early stages, it has shown potential for innovative applications in scenarios such as mental health, education, business services, and public management. With the increasing prevalence of artificial intelligence, these fields, which involve substantial interpersonal interactions, are positioned to become the primary domains for human-computer interaction. On one hand, empathy computing primarily aims to analyze and comprehend empathy using computers. In the realm of mental health, empathy computing can assist in automatically evaluating and enhancing therapists' empathetic abilities. Additionally, it facilitates policymakers to respond empathetically to citizens' needs and inquiries, thereby fostering trust between the government and the public. In the field of education, empathy computing can facilitate the learning process by employing empathetic AI tutors. This article critically reviews current research on empathy computing and discusses its future directions from a psychological perspective, with the aim of facilitating foundational research and practical applications in this field. In public management, empathy computing can be used to generate empathetic discourse to counteract negative speech. Additionally, it can provide personalized empathetic support and guidance through AI-driven chatbots. These four scenarios illustrate the vast potential applications of empathy computing. However, due to concerns related to safety and ethics, complete reliance on computers to perform empathetic tasks is currently not feasible. Instead, a collaboration between humans and computers is necessary. Empathy computing represents a transformative frontier, not only providing methods to measure and analyze empathy automatically on a larger scale but also enriching the theoretical landscape of empathy research. Psychologists play indispensable roles in leading, evaluating, and optimizing research and practice in this field. This expansion raises novel questions about the universality of empathy and its potential evolution in human-computer interaction. Empathy computing holds the promise of serving as a cornerstone for a unified theory of empathy that encompasses diverse relationship dynamics, ranging from human-human to human-machine interactions and beyond. It is beneficial for comprehensively understanding empathy and effectively promoting it in the context of an intelligent society. Future research should focus on developing integrated theoretical models of empathy computing, establishing reliable psychological and behavioral datasets of empathy-related characteristics, and validating and refining empathy computing research through a human-centered approach. It extends traditional studies on empathy in interpersonal relationships to explore its emerging manifestations in human-AI relationships. The collaboration of scholars in psychology and computer science is imperative to ensure that AI learns empathy effectively and ethically, thereby fostering people’s wellbeing in the forthcoming intelligent society.","Empathy computing is an emerging research field that integrates artificial intelligence (AI) and big data technology to predict, identify, simulate, and generate human empathy. This field builds upon psychological studies in terms of concepts, measurements, neural foundations, and applications of empathy, and employs innovative computing approaches for analyzing and simulating empathy. This article critically reviews current research on empathy computing and discusses its future directions from a psychological perspective, with the aim of facilitating foundational research and practical applications in this field.
The current research on empathy computing can be categorized into four themes based on different purposes and methods. On one hand, empathy computing primarily aims to analyze and comprehend empathy using computers. This endeavor can be further divided into two categories: (1) individual empathy assessment, which focuses on analyzing individual empathetic traits, and (2) empathetic content classification, which focuses on analyzing empathetic features in texts rather than individuals. On the other hand, research also focuses on simulating and expressing empathy through computing, which includes (3) the design of empathetic response systems and (4) the development of generative empathetic dialogue systems. The former provides users with a limited number of predefined rule-based responses and feedback to express empathy, while the latter utilizes AI to automatically generate a wide range of empathetic dialogues without relying on predefined rules. These four research streams are relatively independent yet complementary. Moreover, as research progresses, new directions will continue to emerge, such as improving the empathic capabilities of computers through brain-computer interface technology.
Although research on empathy computing is still in its early stages, it has shown potential for innovative applications in scenarios such as mental health, education, business services, and public management. With the increasing prevalence of artificial intelligence, these fields, which involve substantial interpersonal interactions, are positioned to become the primary domains for human-computer interaction. As a result, they emerge as the key application scenarios for empathy computing. In the realm of mental health, empathy computing can assist in automatically evaluating and enhancing therapists' empathetic abilities. Additionally, it can provide personalized empathetic support and guidance through AI-driven chatbots. In the field of education, empathy computing can facilitate the learning process by employing empathetic AI tutors. Within the business sector, it enables organizations to deliver tailored customer experiences, thereby enhancing satisfaction and fostering loyalty through the generation of empathic dialogues. In public management, empathy computing can be used to generate empathetic discourse to counteract negative speech. Additionally, it facilitates policymakers to respond empathetically to citizens' needs and inquiries, thereby fostering trust between the government and the public. These four scenarios illustrate the vast potential applications of empathy computing. However, due to concerns related to safety and ethics, complete reliance on computers to perform empathetic tasks is currently not feasible. Instead, a collaboration between humans and computers is necessary.
Empathy computing represents a transformative frontier, not only providing methods to measure and analyze empathy automatically on a larger scale but also enriching the theoretical landscape of empathy research. It extends traditional studies on empathy in interpersonal relationships to explore its emerging manifestations in human-AI relationships. This expansion raises novel questions about the universality of empathy and its potential evolution in human-computer interaction. Empathy computing holds the promise of serving as a cornerstone for a unified theory of empathy that encompasses diverse relationship dynamics, ranging from human-human to human-machine interactions and beyond. It is beneficial for comprehensively understanding empathy and effectively promoting it in the context of an intelligent society.
Future research should focus on developing integrated theoretical models of empathy computing, establishing reliable psychological and behavioral datasets of empathy-related characteristics, and validating and refining empathy computing research through a human-centered approach. Psychologists play indispensable roles in leading, evaluating, and optimizing research and practice in this field. The collaboration of scholars in psychology and computer science is imperative to ensure that AI learns empathy effectively and ethically, thereby fostering people’s wellbeing in the forthcoming intelligent society.",2
"This was done by exploring how participants perceive anthropomorphic chatbots as machines or humans, the existence of verbal abuse during human chatbot interactions, and the expectation of chatbot helpfulness depending on gender dynamics. This study was conducted to investigate the empathy between human chatbot interactions among computer science students at Uppsala University, Sweden. A semi-structured interview methodology with five students was conducted for qualitative data collection. The collected data was manually analyzed using thematic analysis. The results of this study found that there is empathy in human chatbot interaction, regardless of whether participants perceive anthropomorphic chatbots as humans or machines. However, the level of empathy is generally low as participants frustrate when they are dissatisfied with the response of chatbots and exit the chatbots without expressing their frustration, and they usually forget their frustration and come again with other questions another time. The study also shows that participants might expect more help and politeness if chatbots are more likely to be female.","This study was conducted to investigate the empathy between human chatbot interactions among computer science students at Uppsala University, Sweden. This was done by exploring how participants perceive anthropomorphic chatbots as machines or humans, the existence of verbal abuse during human chatbot interactions, and the expectation of chatbot helpfulness depending on gender dynamics. A semi-structured interview methodology with five students was conducted for qualitative data collection. The collected data was manually analyzed using thematic analysis. The results of this study found that there is empathy in human chatbot interaction, regardless of whether participants perceive anthropomorphic chatbots as humans or machines. However, the level of empathy is generally low as participants frustrate when they are dissatisfied with the response of chatbots and exit the chatbots without expressing their frustration, and they usually forget their frustration and come again with other questions another time. The study also shows that participants might expect more help and politeness if chatbots are more likely to be female.",2
"From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.","From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.",2
"In the current state-of-the-art, there are no tools to do that. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors.","Interactive software agents, such as chatbots, are progressively being used in the area of health and well-being. In such applications, where agents engage with users in interpersonal conversations for, e.g., coaching, comfort or behavior-change interventions, there is an increased need for understanding agents’ empathic capabilities. In the current state-of-the-art, there are no tools to do that. In order to understand empathic capabilities in interactive software agents, we need a precise notion of empathy. The literature discusses a variety of definitions of empathy, but there is no consensus of a formal definition. Based on a systematic literature review and a qualitative analysis of recent approaches to empathy in interactive agents for health and well-being, a formal definition—an ontology—of empathy is developed. We present the potential of the formal definition in a controlled user-study by applying it as a tool for assessing empathy in two state-of-the-art health and well-being chatbots; Replika and Wysa. Our findings suggest that our definition captures necessary conditions for assessing empathy in interactive agents, and how it can uncover and explain trends in changing perceptions of empathy over time. The definition, implemented in Web Ontology Language (OWL), may serve as an automated tool, enabling systems to recognize empathy in interactions—be it an interactive agent evaluating its own empathic performance or an intelligent system assessing the empathic capability of its interlocutors.",2
"Advances in the performance of large language models (LLMs) have led some researchers to propose the emergence of theory of mind (ToM) in artificial intelligence (AI). We propose that the method of empathy has special significance for honoring the right to be an exception that is distinct from the value of predictive accuracy, at which LLMs excel. Can LLMs seriously consider an individual's claim that their case is different based on internal mental states like beliefs, desires, and intentions, or are they limited to judging that case based on its similarities to others? Rather than employing the characteristically human method of empathy, they learn to attribute mental states by recognizing linguistic patterns in a dataset that typically do not include that individual. We ask whether LLMs' inability to empathize precludes them from honoring an individual's right to be an exception, that is, from making assessments of character and predictions of behavior that reflect appropriate sensitivity to a person's individuality. LLMs can attribute beliefs, desires, intentions, and emotions, and they will improve in their accuracy. We conclude by considering whether using empathy to consider exceptional cases has intrinsic or merely practical value and we introduce conceptual and empirical avenues for advancing this investigation.","Advances in the performance of large language models (LLMs) have led some researchers to propose the emergence of theory of mind (ToM) in artificial intelligence (AI). LLMs can attribute beliefs, desires, intentions, and emotions, and they will improve in their accuracy. Rather than employing the characteristically human method of empathy, they learn to attribute mental states by recognizing linguistic patterns in a dataset that typically do not include that individual. We ask whether LLMs' inability to empathize precludes them from honoring an individual's right to be an exception, that is, from making assessments of character and predictions of behavior that reflect appropriate sensitivity to a person's individuality. Can LLMs seriously consider an individual's claim that their case is different based on internal mental states like beliefs, desires, and intentions, or are they limited to judging that case based on its similarities to others? We propose that the method of empathy has special significance for honoring the right to be an exception that is distinct from the value of predictive accuracy, at which LLMs excel. We conclude by considering whether using empathy to consider exceptional cases has intrinsic or merely practical value and we introduce conceptual and empirical avenues for advancing this investigation.",2
"We found that participants embodying personas in VR felt significantly more empathy toward the characters they embodied and rated the AI as significantly less fair compared to a baseline condition in which they imagined to be these characters. Furthermore, we investigate differences between embodied personas and discuss qualitative results to gain insight into the participant’s mental model creation. As Virtual Reality has previously been shown to increase empathy through immersive perspective-taking, we conducted a laboratory study in which participants were confronted with a biased Wizard of Oz AI while embodying personas that varied widely in their ability to achieve high financial credit scores due to their age and gender. In a world increasingly driven by AI systems, controversial use cases for AI that significantly affect people’s lives become more likely scenarios. Hence, increasing awareness of AI bias that might affect underprivileged groups becomes an increasing challenge.","In a world increasingly driven by AI systems, controversial use cases for AI that significantly affect people’s lives become more likely scenarios. Hence, increasing awareness of AI bias that might affect underprivileged groups becomes an increasing challenge. As Virtual Reality has previously been shown to increase empathy through immersive perspective-taking, we conducted a laboratory study in which participants were confronted with a biased Wizard of Oz AI while embodying personas that varied widely in their ability to achieve high financial credit scores due to their age and gender. We found that participants embodying personas in VR felt significantly more empathy toward the characters they embodied and rated the AI as significantly less fair compared to a baseline condition in which they imagined to be these characters. Furthermore, we investigate differences between embodied personas and discuss qualitative results to gain insight into the participant’s mental model creation.",2
"Furthermore, AI substantially impacts investors' decision-making process when it comes to investing; nevertheless, AI partially mediates the relationship between emotional intelligence and investment decisions. This nuanced understanding provides valuable insights for financial practitioners, policymakers, and researchers, emphasizing the need for holistic strategies that integrate emotional and technological dimensions in navigating the intricacies of modern investment landscapes. Through empirical analysis, we reveal that EI not only directly impacts ID but also exerts its influence indirectly through AI-mediated pathways. The findings underscore the pivotal role of emotional awareness in investor decision-making, augmented by the technological capabilities of AI. By scrutinizing the direct influence of human emotional intelligence on investment choices and elucidating the mediating role of AI in this process, our research seeks to unravel the complex interplay between minds and machines. In the evolving landscape of financial decision-making, this study delves into the intricate relationships among Emotional Intelligence (EI), Artificial Intelligence (AI), and Investment Decisions (ID). It suggests that most investors are influenced by the identified emotional intelligence when making investment decisions. As the synergy between human intuition and artificial intelligence becomes increasingly integral to financial decision-making, this study contributes to the ongoing discourse on the symbiotic relationship between minds and machines in investments","In the evolving landscape of financial decision-making, this study delves into the intricate relationships among Emotional Intelligence (EI), Artificial Intelligence (AI), and Investment Decisions (ID). By scrutinizing the direct influence of human emotional intelligence on investment choices and elucidating the mediating role of AI in this process, our research seeks to unravel the complex interplay between minds and machines. Through empirical analysis, we reveal that EI not only directly impacts ID but also exerts its influence indirectly through AI-mediated pathways. The findings underscore the pivotal role of emotional awareness in investor decision-making, augmented by the technological capabilities of AI. It suggests that most investors are influenced by the identified emotional intelligence when making investment decisions. Furthermore, AI substantially impacts investors' decision-making process when it comes to investing; nevertheless, AI partially mediates the relationship between emotional intelligence and investment decisions. This nuanced understanding provides valuable insights for financial practitioners, policymakers, and researchers, emphasizing the need for holistic strategies that integrate emotional and technological dimensions in navigating the intricacies of modern investment landscapes. As the synergy between human intuition and artificial intelligence becomes increasingly integral to financial decision-making, this study contributes to the ongoing discourse on the symbiotic relationship between minds and machines in investments",2
"Empathy is a specific moral aspect of human behavior. The global workplace, and thereby a consideration of employee stakeholders, includes unique behavioral and ethical considerations, including a consideration of human empathy. Further, the human aspects of workplaces are within the domain of human resources and managerial oversight in business organizations. As such, human emotions and interactions are complicated by daily work related expectations, employee/employer interactions and work practices, and the outcomes of employees’ work routines. Increasingly, the understanding of models of AI-reliant business practices underscores the need for the consideration of the ethical aspects of AI impacts on employees in the workplace. Business ethics, human resources, and risk management practices are endemic aspects within workplaces. As such, attributive ethical indications of the role of AI in the workplace and its impacts on employees is necessary. Empathy is concerned with human intentions. This paper explores a systematic ethical lens of the opportunities and the risks of AI ideation, development, and deployment in business-employee relations practices beyond a compliance mindset, and that introduces a further set of workplace considerations. Moreover, this paper uses a cognitive lens of empathy and focuses on artificial morality related to the ethical concerns, implications, and practices of AI development, deployment, and workplace practices that may impact employees in a variety of business aspects.","Empathy is a specific moral aspect of human behavior. The global workplace, and thereby a consideration of employee stakeholders, includes unique behavioral and ethical considerations, including a consideration of human empathy. Further, the human aspects of workplaces are within the domain of human resources and managerial oversight in business organizations. As such, human emotions and interactions are complicated by daily work related expectations, employee/employer interactions and work practices, and the outcomes of employees’ work routines. Business ethics, human resources, and risk management practices are endemic aspects within workplaces. Increasingly, the understanding of models of AI-reliant business practices underscores the need for the consideration of the ethical aspects of AI impacts on employees in the workplace. This paper explores a systematic ethical lens of the opportunities and the risks of AI ideation, development, and deployment in business-employee relations practices beyond a compliance mindset, and that introduces a further set of workplace considerations. Empathy is concerned with human intentions. As such, attributive ethical indications of the role of AI in the workplace and its impacts on employees is necessary. Moreover, this paper uses a cognitive lens of empathy and focuses on artificial morality related to the ethical concerns, implications, and practices of AI development, deployment, and workplace practices that may impact employees in a variety of business aspects.",2
"However, existing research frequently overlooks the multidimensionality of empathy, leading to an insufficient understanding if artificial empathy is perceived similarly to interpersonal empathy. This research thus highlights that empathy does not equally apply to human-bot interactions. This paper argues that implementing experiential expressions of empathy may have unintended negative consequences as they might feel inauthentic. Instead, providing instrumental support could be more suitable for modeling artificial empathy as it aligns better with computer-like schemas towards chatbots. Two experimental studies using healthcare chatbots examine the effect of empathetic (feeling with), sympathetic (feeling for), and behavioral-empathetic (empathetic helping) vs. non-empathetic responses on perceived warmth, perceived authenticity, and their consequences on trust and using intentions. A third study does not replicate this backfiring effect in human-human interactions. As hypothesized, empathetic, and sympathetic responses reduce the chatbot's perceived authenticity suppressing this positive effect in both studies. Results reveal that any kind of empathy (vs. no empathy) enhances perceived warmth resulting in higher trust and using intentions. It further introduces the concept of ‘perceived authenticity’ and demonstrates that distinctively human attributes might backfire by feeling inauthentic in interactions with chatbots. Implementing empathy to healthcare chatbots is considered promising to create a sense of human warmth.","Implementing empathy to healthcare chatbots is considered promising to create a sense of human warmth. However, existing research frequently overlooks the multidimensionality of empathy, leading to an insufficient understanding if artificial empathy is perceived similarly to interpersonal empathy. This paper argues that implementing experiential expressions of empathy may have unintended negative consequences as they might feel inauthentic. Instead, providing instrumental support could be more suitable for modeling artificial empathy as it aligns better with computer-like schemas towards chatbots. Two experimental studies using healthcare chatbots examine the effect of empathetic (feeling with), sympathetic (feeling for), and behavioral-empathetic (empathetic helping) vs. non-empathetic responses on perceived warmth, perceived authenticity, and their consequences on trust and using intentions. Results reveal that any kind of empathy (vs. no empathy) enhances perceived warmth resulting in higher trust and using intentions. As hypothesized, empathetic, and sympathetic responses reduce the chatbot's perceived authenticity suppressing this positive effect in both studies. A third study does not replicate this backfiring effect in human-human interactions. This research thus highlights that empathy does not equally apply to human-bot interactions. It further introduces the concept of ‘perceived authenticity’ and demonstrates that distinctively human attributes might backfire by feeling inauthentic in interactions with chatbots.",2
"With the rapid development of artificial intelligence, there is an increasing number of industries relying on the accuracy and efficiency of deep learning algorithms. This proposed framework emphasises considering the cause and trigger of emotions as the explanation for the deep learning-based emotion analysis, and it includes two main components: the extraction of the emotion cause and the visualisation of emotion-triggering words. Still, emotion should be different from other task categories because the generation of emotion involves human-specific factors and logic. There are mathematical-based explanation methods, and they often generalise emotion analysis as a classification task. In the context of emotion analysis used in business and public opinion monitoring, it is sometimes difficult for decision-makers to trust the outcome without explanation from the supposedly emotionless machines. This paper proposes an emotion analysis explanation framework that is grounded in psychological theories focusing on the stimulus from classic emotion theories. That engenders scepticism and resistance from some quarters of deep learning-based technologies. But due to the inexplicability and black box effect of deep neural networks, we can only obtain results without knowing the applied reasoning behind them.","With the rapid development of artificial intelligence, there is an increasing number of industries relying on the accuracy and efficiency of deep learning algorithms. But due to the inexplicability and black box effect of deep neural networks, we can only obtain results without knowing the applied reasoning behind them. That engenders scepticism and resistance from some quarters of deep learning-based technologies. In the context of emotion analysis used in business and public opinion monitoring, it is sometimes difficult for decision-makers to trust the outcome without explanation from the supposedly emotionless machines. There are mathematical-based explanation methods, and they often generalise emotion analysis as a classification task. Still, emotion should be different from other task categories because the generation of emotion involves human-specific factors and logic. This paper proposes an emotion analysis explanation framework that is grounded in psychological theories focusing on the stimulus from classic emotion theories. This proposed framework emphasises considering the cause and trigger of emotions as the explanation for the deep learning-based emotion analysis, and it includes two main components: the extraction of the emotion cause and the visualisation of emotion-triggering words.",2
"However, the influence of emotional expressions of chatbots on service outcomes has not received much attention from researchers. These findings advance research on the emotional expressions of chatbots and provide critical insights for deploying chatbots in customer service in the tourism industry. Chatbots' expressions of concern for customers can improve customer satisfaction by reducing expectancy violations. Drawing upon expectancy violations theory, we explored how emotional expressions of chatbots affect customer satisfaction using three experiments in the context of tourist attraction recommendations. In particular, customer's goal orientation, the human-likeness of chatbot's avatars, and the relationship type between customers and chatbots can moderate the negative relationship between emotional expression and expectancy violation. Artificial intelligence chatbots have invaded the tourism industry owing to their low cost and high efficiency.","Artificial intelligence chatbots have invaded the tourism industry owing to their low cost and high efficiency. However, the influence of emotional expressions of chatbots on service outcomes has not received much attention from researchers. Drawing upon expectancy violations theory, we explored how emotional expressions of chatbots affect customer satisfaction using three experiments in the context of tourist attraction recommendations. Chatbots' expressions of concern for customers can improve customer satisfaction by reducing expectancy violations. In particular, customer's goal orientation, the human-likeness of chatbot's avatars, and the relationship type between customers and chatbots can moderate the negative relationship between emotional expression and expectancy violation. These findings advance research on the emotional expressions of chatbots and provide critical insights for deploying chatbots in customer service in the tourism industry.",2
"The PRISMA systematic review methodology was used to describe the state of the situation of research on this topic, taking into account theories, methodologies, countries, and educational levels. This chapter presents a systematic review on the relationship between artificial intelligence and emotions in education in Latin America and the Caribbean. Fifteen published articles were finally selected, focusing on Brazil and Colombia, university level, students as unit of analysis, methodologies based on facial recognition, psychology and software combined. It is hoped to deepen the research in other disciplines, with other theories and methodologies.","This chapter presents a systematic review on the relationship between artificial intelligence and emotions in education in Latin America and the Caribbean. The PRISMA systematic review methodology was used to describe the state of the situation of research on this topic, taking into account theories, methodologies, countries, and educational levels. Fifteen published articles were finally selected, focusing on Brazil and Colombia, university level, students as unit of analysis, methodologies based on facial recognition, psychology and software combined. It is hoped to deepen the research in other disciplines, with other theories and methodologies.",2
"and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy. The discussion and conclusions emphasize the potential of A.I. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli.","This paper introduces a study employing artificial intelligence (AI) to utilize computer vision algorithms for detecting human emotions in video content during user interactions with diverse visual stimuli. The research aims to unveil the creation of software capable of emotion detection by leveraging AI algorithms and image processing pipelines to identify users' facial expressions. The process involves assessing users through images and facilitating the implementation of computer vision algorithms aligned with psychological theories defining emotions and their recognizable features. The study demonstrates the feasibility of emotion recognition through convolutional neural networks (CNN) and software development and training based on facial expressions. The results highlight successful emotion identification; however, precision improvement necessitates further training for contexts with more diverse images and additional algorithms to distinguish closely related emotional patterns. The discussion and conclusions emphasize the potential of A.I. and computer vision algorithms in emotion detection, providing insights into software development, ongoing training, and the evolving landscape of emotion recognition technology. Further training is necessary for contexts with more diverse images, alongside additional algorithms that can effectively distinguish between facial expressions depicting closely related emotional patterns, enhancing certainty and accuracy.",2
"Since the 1950s, a significant number of clinical cases have confirmed the effectiveness of art in rehabilitation therapy and psychological interventions. With the advancement of artificial intelligence technology, AI painting software based on the Stable Diffusion algorithm model enables image creation through prompts and feedback. This study tracks and measures the emotional changes in patients before and after using the AI painting software Stable Diffusion WebUI using emotional vocabulary measurement methods. Therefore, whether AI painting software can positively impact human emotions becomes a critical factor for its application in art therapy. On one hand, it allows for the in-depth development of guided artificial intelligence painting software specifically designed as a dedicated tool for art therapy a form of AI software for artistic healing. This result opens a new window for the integration of artificial intelligence with art therapy research. According to the experimental data of this project, artificial intelligence painting can leave a positive impression on human emotions. On the other hand, it encourages further research into the effectiveness of traditional painting versus AI-assisted painting in art therapy, aiming to explore the underlying principles and mechanisms of art therapy.","Since the 1950s, a significant number of clinical cases have confirmed the effectiveness of art in rehabilitation therapy and psychological interventions. With the advancement of artificial intelligence technology, AI painting software based on the Stable Diffusion algorithm model enables image creation through prompts and feedback. Therefore, whether AI painting software can positively impact human emotions becomes a critical factor for its application in art therapy. This study tracks and measures the emotional changes in patients before and after using the AI painting software Stable Diffusion WebUI using emotional vocabulary measurement methods. According to the experimental data of this project, artificial intelligence painting can leave a positive impression on human emotions. This result opens a new window for the integration of artificial intelligence with art therapy research. On one hand, it allows for the in-depth development of guided artificial intelligence painting software specifically designed as a dedicated tool for art therapy a form of AI software for artistic healing. On the other hand, it encourages further research into the effectiveness of traditional painting versus AI-assisted painting in art therapy, aiming to explore the underlying principles and mechanisms of art therapy.",2
"INTRODUCTION: In recent years, there has been a convergence between Artificial Intelligence and neuroscience, particularly in studying the brain and developing treatments for neurological disorders. Artificial neural networks and deep learning provide valuable insights into neural processing and brain functioning. Neuroscience has encountered happiness and is opening up to an approach that seeks evidence to understand people's well-being supported by Artificial Intelligence. RESULTS A total of 603 articles were obtained, and it is evident that the most significant scientific production is centered in the United States (184), United Kingdom (74), and China (73). METHODS: A bibliometric analysis was performed with articles from the Scopus database in 2013-2023; likewise, the VOSviewer was used for information processing. Three clusters are generated from the Co-occurrence - Author Keywords analysis. The first cluster, red, is related to Artificial Intelligence applications for predicting happiness; the second cluster, green, is associated with Artificial Intelligence tools in neuroscience; and the third cluster, blue, is related to neuroscience in psychology. OBJECTIVES: To evaluate the interaction between neuroscience and happiness based on the advances in Artificial Intelligence. CONCLUSION: Neuroscience research has made significant leaps in understanding mental processes such as emotions and consciousness. Recent research tries to explain how neural processes influence an individual's happiness.","INTRODUCTION: In recent years, there has been a convergence between Artificial Intelligence and neuroscience, particularly in studying the brain and developing treatments for neurological disorders. Artificial neural networks and deep learning provide valuable insights into neural processing and brain functioning. Recent research tries to explain how neural processes influence an individual's happiness. OBJECTIVES: To evaluate the interaction between neuroscience and happiness based on the advances in Artificial Intelligence. METHODS: A bibliometric analysis was performed with articles from the Scopus database in 2013-2023; likewise, the VOSviewer was used for information processing. RESULTS A total of 603 articles were obtained, and it is evident that the most significant scientific production is centered in the United States (184), United Kingdom (74), and China (73). Three clusters are generated from the Co-occurrence - Author Keywords analysis. The first cluster, red, is related to Artificial Intelligence applications for predicting happiness; the second cluster, green, is associated with Artificial Intelligence tools in neuroscience; and the third cluster, blue, is related to neuroscience in psychology. CONCLUSION: Neuroscience research has made significant leaps in understanding mental processes such as emotions and consciousness. Neuroscience has encountered happiness and is opening up to an approach that seeks evidence to understand people's well-being supported by Artificial Intelligence.",2
"The pursuit of biologically inspired cognitive architectures (BICA) has driven significant advancements in artificial intelligence (AI) and artificial general intelligence (AGI). However, most existing BICA models lack a critical aspect of human intelligence: emotions and feelings. This research explores the development and implementation of an emotion-integrated cognitive architecture that mimics human emotional processing within a computational framework. EICA aims to integrate emotional processing into the core of the AI system, enabling robust, flexible, and adaptable AI agents that can respond to complex and dynamic environments with human-like emotional intelligence. Our proposed architecture, Emotion-Integrated Cognitive Architecture (EICA), is inspired by the latest findings in cognitive psychology, neurobiology, neuroscience and affective computing. The architecture incorporates emotion-generating, recognition, and regulation mechanisms, allowing AI agents to perceive, interpret, and respond to emotions in themselves and others. The EICA model leverages advances in brain imaging and recording techniques to draw insights from the neural basis of emotions in humans. We present the concept of EICA, including its modular structure and interaction with other cognitive components. We also provide case studies showcasing EICA's successful implementation in various AI applications, such as virtual assistants and adaptive robotics. This research represents a significant step towards achieving the BICA Challenge by advancing the computational replication of human emotional intelligence. By integrating emotions and feelings into AI systems, we move closer to realizing the full potential of bi-directional understanding between artificial and biological intelligences.","The pursuit of biologically inspired cognitive architectures (BICA) has driven significant advancements in artificial intelligence (AI) and artificial general intelligence (AGI). However, most existing BICA models lack a critical aspect of human intelligence: emotions and feelings. This research explores the development and implementation of an emotion-integrated cognitive architecture that mimics human emotional processing within a computational framework. Our proposed architecture, Emotion-Integrated Cognitive Architecture (EICA), is inspired by the latest findings in cognitive psychology, neurobiology, neuroscience and affective computing. EICA aims to integrate emotional processing into the core of the AI system, enabling robust, flexible, and adaptable AI agents that can respond to complex and dynamic environments with human-like emotional intelligence. The EICA model leverages advances in brain imaging and recording techniques to draw insights from the neural basis of emotions in humans. The architecture incorporates emotion-generating, recognition, and regulation mechanisms, allowing AI agents to perceive, interpret, and respond to emotions in themselves and others. We present the concept of EICA, including its modular structure and interaction with other cognitive components. We also provide case studies showcasing EICA's successful implementation in various AI applications, such as virtual assistants and adaptive robotics. This research represents a significant step towards achieving the BICA Challenge by advancing the computational replication of human emotional intelligence. By integrating emotions and feelings into AI systems, we move closer to realizing the full potential of bi-directional understanding between artificial and biological intelligences.",2
"Network news is an important way for netizens to get social information. Experimental results demonstrate that the proposed model outperforms the traditional BiLSTM-CRF model, achieving superior performance with only a 20% proportional training data set compared to the 40% proportional training data set required by the conventional model. The method jointly trains sentence and trigger vectors through a trigger-matching network, utilizing the trigger vectors as attention queries for subsequent sequence annotation models. Furthermore, the proposed method employs entity labels to effectively recognize neologisms in web news, enabling the customization of the set of sensitive words and the number of words within the set to be detected, as well as extending the web news word sentiment lexicon for sentiment observation. Specifically, the proposed method introduces an automatic annotation approach for Chinese entity triggers and a Named Entity Recognition (NER) model that can achieve high accuracy with a small number of training data sets. Named entity recognition technology under artificial background can realize the classification of place, date and other information in text information. This article combines named entity recognition and deep learning technology. Massive news information hinders netizens to get key information. Moreover, the loss function curve shows that my model exhibits better accuracy and faster convergence speed than the compared model. Finally, my model achieves an average accuracy rate of 97.88% in sentiment viewpoint detection.","Network news is an important way for netizens to get social information. Massive news information hinders netizens to get key information. Named entity recognition technology under artificial background can realize the classification of place, date and other information in text information. This article combines named entity recognition and deep learning technology. Specifically, the proposed method introduces an automatic annotation approach for Chinese entity triggers and a Named Entity Recognition (NER) model that can achieve high accuracy with a small number of training data sets. The method jointly trains sentence and trigger vectors through a trigger-matching network, utilizing the trigger vectors as attention queries for subsequent sequence annotation models. Furthermore, the proposed method employs entity labels to effectively recognize neologisms in web news, enabling the customization of the set of sensitive words and the number of words within the set to be detected, as well as extending the web news word sentiment lexicon for sentiment observation. Experimental results demonstrate that the proposed model outperforms the traditional BiLSTM-CRF model, achieving superior performance with only a 20% proportional training data set compared to the 40% proportional training data set required by the conventional model. Moreover, the loss function curve shows that my model exhibits better accuracy and faster convergence speed than the compared model. Finally, my model achieves an average accuracy rate of 97.88% in sentiment viewpoint detection.",2
"The results show that compared with the original CNN, LSTM, and T-LSTM, the BiLSTM-based neural network performs better in the task of text emotion expression and information conveyance, with the accuracy rate staying above 0.925, and the effect on the English dataset is a bit better than that on the Chinese dataset. Then, the crawler tool is used to obtain the dataset from the Chinese English module under the MOOC of Chinese universities, and the evaluation indexes are set according to the model’s performance, followed by the experimental analysis of the English text emotion expression and information conveyance. This study aims to enhance English teaching and communication between Chinese and foreign cultures. Secondly, using artificial intelligence technology, it is proposed to construct an analysis model for English text emotion and information communication using the BiLSTM neural network. This paper firstly researches English text emotion expression and information communication, classifies English text emotion expression and information communication according to the human emotion-value relationship, and summarizes the characteristics of English emotion expression and information communication. To deal with the characteristics of English text quickly and efficiently, it is necessary to encode the emotional information of English text, and based on encoding, the BiLSTM neural network is applied to extract the emotional features of English text and solve the problem of the loss of emotional features through the loss function.","This paper firstly researches English text emotion expression and information communication, classifies English text emotion expression and information communication according to the human emotion-value relationship, and summarizes the characteristics of English emotion expression and information communication. Secondly, using artificial intelligence technology, it is proposed to construct an analysis model for English text emotion and information communication using the BiLSTM neural network. To deal with the characteristics of English text quickly and efficiently, it is necessary to encode the emotional information of English text, and based on encoding, the BiLSTM neural network is applied to extract the emotional features of English text and solve the problem of the loss of emotional features through the loss function. Then, the crawler tool is used to obtain the dataset from the Chinese English module under the MOOC of Chinese universities, and the evaluation indexes are set according to the model’s performance, followed by the experimental analysis of the English text emotion expression and information conveyance. The results show that compared with the original CNN, LSTM, and T-LSTM, the BiLSTM-based neural network performs better in the task of text emotion expression and information conveyance, with the accuracy rate staying above 0.925, and the effect on the English dataset is a bit better than that on the Chinese dataset. This study aims to enhance English teaching and communication between Chinese and foreign cultures.",2
"Current efforts encounter challenges in balancing intra- and inter-speaker context dependencies when tackling intra-modal interactions. Multimodal Emotion Recognition in Conversations (ERC) aims to identify the emotions conveyed by each utterance in a conversational video. This balance is vital as it encompasses modeling self-dependency (emotional inertia) where speakers' own emotions affect them and modeling interpersonal dependencies (empathy) where counterparts' emotions influence a speaker. Furthermore, challenges arise in addressing cross-modal interactions that involve content with conflicting emotions across different modalities. To address this issue, we introduce an adaptive interactive graph network (IGN) called AdaIGN that employs the Gumbel Softmax trick to adaptively select nodes and edges, enhancing intra- and cross-modal interactions. Next, we propose Node- and Edge-level Selection Policies (NESP) to guide node and edge selection, along with a Graph-Level Selection Policy (GSP) to integrate the utterance representation from original IGN and NESP-enhanced IGN. Unlike undirected graphs, we use a directed IGN to prevent future utterances from impacting the current one. Moreover, we design a task-specific loss function that prioritizes text modality and intra-speaker context selection. To reduce computational complexity, we use pre-defined pseudo labels through self-supervised methods to mask unnecessary utterance nodes for selection. Experimental results show that AdaIGN outperforms state-of-the-art methods on two popular datasets. Our code will be available at https://github.com/TuGengs/AdaIGN.","Multimodal Emotion Recognition in Conversations (ERC) aims to identify the emotions conveyed by each utterance in a conversational video. Current efforts encounter challenges in balancing intra- and inter-speaker context dependencies when tackling intra-modal interactions. This balance is vital as it encompasses modeling self-dependency (emotional inertia) where speakers' own emotions affect them and modeling interpersonal dependencies (empathy) where counterparts' emotions influence a speaker. Furthermore, challenges arise in addressing cross-modal interactions that involve content with conflicting emotions across different modalities. To address this issue, we introduce an adaptive interactive graph network (IGN) called AdaIGN that employs the Gumbel Softmax trick to adaptively select nodes and edges, enhancing intra- and cross-modal interactions. Unlike undirected graphs, we use a directed IGN to prevent future utterances from impacting the current one. Next, we propose Node- and Edge-level Selection Policies (NESP) to guide node and edge selection, along with a Graph-Level Selection Policy (GSP) to integrate the utterance representation from original IGN and NESP-enhanced IGN. Moreover, we design a task-specific loss function that prioritizes text modality and intra-speaker context selection. To reduce computational complexity, we use pre-defined pseudo labels through self-supervised methods to mask unnecessary utterance nodes for selection. Experimental results show that AdaIGN outperforms state-of-the-art methods on two popular datasets. Our code will be available at https://github.com/TuGengs/AdaIGN.",2
"Segmentation of tumors in ultrasound (US) images of the breast is a critical issue in medical imaging. The model was trained on low complexity images and applied to the entire set of images. The paper aims to introduce a novel AI-based hybrid model for US segmentation that offers high accuracy, requires relatively smaller datasets, and is capable of handling previously unseen data. The software can be used for diagnostics and the US-guided biopsies. The age of the patients ranges from 22 to 73 years. The model has been trained and verified on 1264 ultrasound images. The method outperforms 14 selected state-of-the-art algorithms applied to US images characterized by complex geometry and high level of noise. The proposed method (DL-AL) produces excellent results in terms of the dice coefficient (region) and the relative Hausdorff distance H3 (contour-based) as follows: the easiest image complexity level, Dice = 0.96 and H3 = 0.26; the medium complexity level, Dice = 0.91 and H3 = 0.82; and the hardest complexity level, Dice = 0.90 and H3 = 0.84. The algorithms are verified on three US datasets. The images are in the JPEG and PNG formats. A unique and robust hybrid approach that combines deep learning (DL) and multi-agent artificial life (AL) has been introduced. The DL-AL outperforms the second best (Unet-based) method by 10–20%. These tests show a significant advantage of DL-AL over 30% The paper offers an original classification of the images and tests to analyze the limits of the DL. All other metrics follow the same pattern. The 14 benchmark algorithms include deformable shapes, edge linking, superpixels, machine learning, and DL methods. The method has been also tested by a series of unconventional tests. (1) Only the low complexity images have been used for training (68% unknown images): Dice = 0.80 and H3 = 2.01. These results are summarized below. Due to the poor quality of US images and the varying specifications of US machines, segmentation and classification of abnormalities present difficulties even for trained radiologists. (2) The low and the medium complexity images have been used for training (51% unknown images): Dice = 0.86 and H3 = 1.32. (3) The low, medium, and hard complexity images have been used for training (35% unknown images): Dice = 0.92 and H3 = 0.76. The tests use eight-region shape- and contour-based evaluation metrics.","Segmentation of tumors in ultrasound (US) images of the breast is a critical issue in medical imaging. Due to the poor quality of US images and the varying specifications of US machines, segmentation and classification of abnormalities present difficulties even for trained radiologists. The paper aims to introduce a novel AI-based hybrid model for US segmentation that offers high accuracy, requires relatively smaller datasets, and is capable of handling previously unseen data. The software can be used for diagnostics and the US-guided biopsies. A unique and robust hybrid approach that combines deep learning (DL) and multi-agent artificial life (AL) has been introduced. The algorithms are verified on three US datasets. The method outperforms 14 selected state-of-the-art algorithms applied to US images characterized by complex geometry and high level of noise. The paper offers an original classification of the images and tests to analyze the limits of the DL. The model has been trained and verified on 1264 ultrasound images. The images are in the JPEG and PNG formats. The age of the patients ranges from 22 to 73 years. The 14 benchmark algorithms include deformable shapes, edge linking, superpixels, machine learning, and DL methods. The tests use eight-region shape- and contour-based evaluation metrics. The proposed method (DL-AL) produces excellent results in terms of the dice coefficient (region) and the relative Hausdorff distance H3 (contour-based) as follows: the easiest image complexity level, Dice = 0.96 and H3 = 0.26; the medium complexity level, Dice = 0.91 and H3 = 0.82; and the hardest complexity level, Dice = 0.90 and H3 = 0.84. All other metrics follow the same pattern. The DL-AL outperforms the second best (Unet-based) method by 10–20%. The method has been also tested by a series of unconventional tests. The model was trained on low complexity images and applied to the entire set of images. These results are summarized below. (1) Only the low complexity images have been used for training (68% unknown images): Dice = 0.80 and H3 = 2.01. (2) The low and the medium complexity images have been used for training (51% unknown images): Dice = 0.86 and H3 = 1.32. (3) The low, medium, and hard complexity images have been used for training (35% unknown images): Dice = 0.92 and H3 = 0.76. These tests show a significant advantage of DL-AL over 30%",2
"A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI’s role with human judgment remains a challenge. Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare.","Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI’s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.",2
"Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing fMRI responses to sentences. Further, (ii) lower perplexity—a measure of next-word prediction performance—is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. Here, we use two complementary approaches to ask how the models’ ability to capture human fMRI responses to sentences is affected by the amount of training data. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally plausible in terms of the amount of training data given that this amount is similar to what children are estimated to be exposed to during the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to reach state-of-the-art next-word prediction performance on the human benchmark at different stages during training. Artificial neural networks have emerged as computationally plausible models of human language processing. A major criticism of these models is that the amount of training data they receive far exceeds that of humans during language learning. In tandem, these findings establish that although some training is necessary for the models’ predictive ability, a developmentally realistic amount of training (~100 million words) may suffice.","Artificial neural networks have emerged as computationally plausible models of human language processing. A major criticism of these models is that the amount of training data they receive far exceeds that of humans during language learning. Here, we use two complementary approaches to ask how the models’ ability to capture human fMRI responses to sentences is affected by the amount of training data. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally plausible in terms of the amount of training data given that this amount is similar to what children are estimated to be exposed to during the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to reach state-of-the-art next-word prediction performance on the human benchmark at different stages during training. Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing fMRI responses to sentences. Further, (ii) lower perplexity—a measure of next-word prediction performance—is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. In tandem, these findings establish that although some training is necessary for the models’ predictive ability, a developmentally realistic amount of training (~100 million words) may suffice.",2
"Moreover, a significant relationship was observed between professional training in AI and its positive impact on social dynamics. Future research directions include exploring AI ethics and regulation in diverse cultural contexts and the impact of emerging technologies like quantum computing on AI ethics. The study investigated the correlations between regulatory compliance, ethical awareness, professional training, and experience in AI practice with the effectiveness of AI implementation and data integrity. The findings revealed a strong positive correlation between higher levels of regulatory compliance and perceived effectiveness in AI implementation, as well as between AI ethics awareness and data integrity assurance. The need for dynamic, adaptable, and inclusive regulatory frameworks that can align AI practices with societal values and ethical norms is emphasized. However, experience in the AI field, while positively correlated, showed a weaker link to data integrity, indicating that experience alone is insufficient for ensuring effective AI practices. The study highlights the importance of ethical considerations, regulatory frameworks, and professional training in shaping AI development and its societal implications. This study examines the ethical challenges and regulatory dynamics of Artificial Intelligence (AI) in relation to data integrity and its influence on social dynamics. Employing a cross-sectional survey approach, primary data was collected from 650 AI practitioners across various sectors, encompassing developers, data scientists, ethicists, and policymakers.","This study examines the ethical challenges and regulatory dynamics of Artificial Intelligence (AI) in relation to data integrity and its influence on social dynamics. Employing a cross-sectional survey approach, primary data was collected from 650 AI practitioners across various sectors, encompassing developers, data scientists, ethicists, and policymakers. The study investigated the correlations between regulatory compliance, ethical awareness, professional training, and experience in AI practice with the effectiveness of AI implementation and data integrity. The findings revealed a strong positive correlation between higher levels of regulatory compliance and perceived effectiveness in AI implementation, as well as between AI ethics awareness and data integrity assurance. Moreover, a significant relationship was observed between professional training in AI and its positive impact on social dynamics. However, experience in the AI field, while positively correlated, showed a weaker link to data integrity, indicating that experience alone is insufficient for ensuring effective AI practices. The study highlights the importance of ethical considerations, regulatory frameworks, and professional training in shaping AI development and its societal implications. The need for dynamic, adaptable, and inclusive regulatory frameworks that can align AI practices with societal values and ethical norms is emphasized. Future research directions include exploring AI ethics and regulation in diverse cultural contexts and the impact of emerging technologies like quantum computing on AI ethics.",2
"Advances in artificial intelligence (AI) create an increasing similarity between the performance of AI systems or AI-based robots and human communication. They raise the questions:
1. whether it is possible to communicate with, understand, and even empathically perceive artificial agents;
2. whether we should ascribe actual subjectivity and thus quasi-personal status to them beyond a certain level of simulation;
3. what will be the impact of an increasing dissolution of the distinction between simulated and real encounters. This assumption is ultimately based on the presupposition of a shared form of life, conceived here as �conviviality.�
(2) The possibility that future artificial agents could meet these preconditions is refuted on the basis of embodied and enactive cognition, which links subjectivity and consciousness to the aliveness of an organism. (3) Even if subjectivity is in principle impossible for artificial agents, the distinction between simulated and real subjectivity might nevertheless become increasingly blurred. (1) To answer these questions, the paper argues that the precondition for actually understanding others consists in the implicit assumption of the subjectivity of our counterpart, which makes shared feelings and a we-intentionality possible. Here, possible consequences are discussed, especially using the example of virtual psychotherapy. Finally, the paper makes case for a mindful appproach to the language we use to talk about artificial systems and pleads for preventing a systematic pretense of subjectivity.","Advances in artificial intelligence (AI) create an increasing similarity between the performance of AI systems or AI-based robots and human communication. They raise the questions:
1. whether it is possible to communicate with, understand, and even empathically perceive artificial agents;
2. whether we should ascribe actual subjectivity and thus quasi-personal status to them beyond a certain level of simulation;
3. what will be the impact of an increasing dissolution of the distinction between simulated and real encounters.
(1) To answer these questions, the paper argues that the precondition for actually understanding others consists in the implicit assumption of the subjectivity of our counterpart, which makes shared feelings and a we-intentionality possible. This assumption is ultimately based on the presupposition of a shared form of life, conceived here as �conviviality.�
(2) The possibility that future artificial agents could meet these preconditions is refuted on the basis of embodied and enactive cognition, which links subjectivity and consciousness to the aliveness of an organism.
(3) Even if subjectivity is in principle impossible for artificial agents, the distinction between simulated and real subjectivity might nevertheless become increasingly blurred. Here, possible consequences are discussed, especially using the example of virtual psychotherapy. Finally, the paper makes case for a mindful appproach to the language we use to talk about artificial systems and pleads for preventing a systematic pretense of subjectivity.",2
"This focus analyzes his predicted course of action for artificial intelligence outlined within his unpublished paper AGI Ruin: A List of Lethalities. However, it argues that both weak and strong artificial intelligence systems, devoid of human-defined goals, would not inherently pose existential threats to humanity, challenging the notions of artificial intelligence alignment, bringing into question the validity of Nick Bostroms Orthogonality Thesis. This paper navigates artificial intelligences recent advancements and increasing media attention. A notable focus is placed on Eliezer Yudkowsky, a leading figure within the domain of artificial intelligence alignment, who aims to bridge the understanding gap between public perceptions and rationalist viewpoints on artificial intelligence technology. The concept of intelligence is then applied to contemporary artificial intelligence capabilities and developments to understand its applicability to the technologies. This paper finds contemporary artificial intelligence systems are, to some extent, intelligent. Furthermore, the possibility of artificial life created through the method of assembling various modules each emulating a separate mind function is discussed. This is achieved by attempting to understand the concept of intelligence itself and identifying a reasonable working definition of that concept.","This paper navigates artificial intelligences recent advancements and increasing media attention. A notable focus is placed on Eliezer Yudkowsky, a leading figure within the domain of artificial intelligence alignment, who aims to bridge the understanding gap between public perceptions and rationalist viewpoints on artificial intelligence technology. This focus analyzes his predicted course of action for artificial intelligence outlined within his unpublished paper AGI Ruin: A List of Lethalities. This is achieved by attempting to understand the concept of intelligence itself and identifying a reasonable working definition of that concept. The concept of intelligence is then applied to contemporary artificial intelligence capabilities and developments to understand its applicability to the technologies. This paper finds contemporary artificial intelligence systems are, to some extent, intelligent. However, it argues that both weak and strong artificial intelligence systems, devoid of human-defined goals, would not inherently pose existential threats to humanity, challenging the notions of artificial intelligence alignment, bringing into question the validity of Nick Bostroms Orthogonality Thesis. Furthermore, the possibility of artificial life created through the method of assembling various modules each emulating a separate mind function is discussed.",2
"Consequently, perception and control limitations have constrained how soft robots are built today. Progress toward untethered autonomy will require deliberate convergence in how the field codevelops new materials, fabrication methods, and control strategies for soft robots. While soft robotics has advanced the design and fabrication of physically intelligent bodies, the integration of information-processing capabilities for computational intelligence remains a challenge. Particular attention is paid to the scale dependence of solutions. Across scales, living beings couple computational or cognitive intelligence with physical intelligence through body morphology, material multifunctionality, and mechanical compliance. This framework allows emergent synergies between material and information processing properties of soft matter to be readily exploited for task-capable agents. A conceptual framework is proposed for a task-first design paradigm that sidesteps limitations imposed by control strategies. Here, a new perspective is put forward: that researchers should use tasks alone to impose material and information constraints on soft robot design. The impressive capabilities of living organisms arise from the way autonomy is materialized by their bodies. Finally, an outlook is presented on emerging research opportunities for achieving autonomy in future soft robots as large as elephant trunks and as small as paramecia.","The impressive capabilities of living organisms arise from the way autonomy is materialized by their bodies. Across scales, living beings couple computational or cognitive intelligence with physical intelligence through body morphology, material multifunctionality, and mechanical compliance. While soft robotics has advanced the design and fabrication of physically intelligent bodies, the integration of information-processing capabilities for computational intelligence remains a challenge. Consequently, perception and control limitations have constrained how soft robots are built today. Progress toward untethered autonomy will require deliberate convergence in how the field codevelops new materials, fabrication methods, and control strategies for soft robots. Here, a new perspective is put forward: that researchers should use tasks alone to impose material and information constraints on soft robot design. A conceptual framework is proposed for a task-first design paradigm that sidesteps limitations imposed by control strategies. This framework allows emergent synergies between material and information processing properties of soft matter to be readily exploited for task-capable agents. Particular attention is paid to the scale dependence of solutions. Finally, an outlook is presented on emerging research opportunities for achieving autonomy in future soft robots as large as elephant trunks and as small as paramecia.",2
"These made groundwork to improve the efficiency and automatic level of artificial fish animation. A Self-Reproduction model of Artificial Fish based on gene control is put forward and built. Based on Artificial Fish's phenotype, the contents of its chromosome are given. Based on this model, heredity rules are given. Simulation program is designed and developed based on all these models built above. In this paper, Self-Reproduction characteristic of Artificial Life is introduced to computer animation. Artificial Fish could reproduce and grow in the virtual marine environment freely controlled by the gene model and rules. Cognitive models based on Artificial Intelligence is put forward and built to control behaviors of artificial fish in high level. Artificial behaviors include predefined behaviors and nondeterminate behaviors.","In this paper, Self-Reproduction characteristic of Artificial Life is introduced to computer animation. A Self-Reproduction model of Artificial Fish based on gene control is put forward and built. Based on Artificial Fish's phenotype, the contents of its chromosome are given. Based on this model, heredity rules are given. Artificial Fish could reproduce and grow in the virtual marine environment freely controlled by the gene model and rules. Artificial behaviors include predefined behaviors and nondeterminate behaviors. Cognitive models based on Artificial Intelligence is put forward and built to control behaviors of artificial fish in high level. Simulation program is designed and developed based on all these models built above. These made groundwork to improve the efficiency and automatic level of artificial fish animation.",2
"In this paper, the concepts of ""Life"", ""Artificial Life"" and ""Generalized Artificial Life"" and the problem ""Is Artificial Life true Life?"" are discussed.","In this paper, the concepts of ""Life"", ""Artificial Life"" and ""Generalized Artificial Life"" and the problem ""Is Artificial Life true Life?"" are discussed.",2
"The technical bases of the contest as well as a description of the artificial life model are explained in detail. The game consists of a simulated Petri dish where two colonies of microorganisms-software agents-must struggle to survive. The pedagogical experience acquired in the contest development is discussed, as well as the resulting learning experience, which generated students enthusiasm and has helped them to develop mental models of possible AI algorithms. This work reports an experience in using an Artificial Life competitive game that simulates an artificial life environment for unstructured and informal Artificial Intelligence (AI) teaching to students from computer science engineering careers. To achieve this goal, the participants must implement surviving strategies for their agents, which include fighting strategies and basic reproduction rules to prevail over all the artificial environment.","This work reports an experience in using an Artificial Life competitive game that simulates an artificial life environment for unstructured and informal Artificial Intelligence (AI) teaching to students from computer science engineering careers. The game consists of a simulated Petri dish where two colonies of microorganisms-software agents-must struggle to survive. To achieve this goal, the participants must implement surviving strategies for their agents, which include fighting strategies and basic reproduction rules to prevail over all the artificial environment. The technical bases of the contest as well as a description of the artificial life model are explained in detail. The pedagogical experience acquired in the contest development is discussed, as well as the resulting learning experience, which generated students enthusiasm and has helped them to develop mental models of possible AI algorithms.",2
"Both transmission and distribution networks should be appropriately adjusted to alleviate congestion within the respective companies. Fuzzy logic emerges as a powerful tool for optimizing power flow solutions, particularly in the context of deregulated power systems. In a deregulated power system, strategic placement of distribution generator units plays a crucial role in minimizing power loss and enhancing overall system performance by mitigating fluctuations. To identify areas of weakness, especially within transmission companies, accessing optimal power flow algorithms becomes essential in a deregulated power system. By employing fuzzy logic controls, the ideal placement of distribution generators (DGs) can be determined, ensuring the reliability indices are identified through optimal power flow solutions and fuzzy logic controllers to maintain system feasibility. The aggregator must assess system performance, utilizing data obtained from distribution and transmission companies within the deregulated power system.","﻿Fuzzy logic emerges as a powerful tool for optimizing power flow solutions, particularly in the context of deregulated power systems. By employing fuzzy logic controls, the ideal placement of distribution generators (DGs) can be determined, ensuring the reliability indices are identified through optimal power flow solutions and fuzzy logic controllers to maintain system feasibility. In a deregulated power system, strategic placement of distribution generator units plays a crucial role in minimizing power loss and enhancing overall system performance by mitigating fluctuations. To identify areas of weakness, especially within transmission companies, accessing optimal power flow algorithms becomes essential in a deregulated power system. Both transmission and distribution networks should be appropriately adjusted to alleviate congestion within the respective companies. The aggregator must assess system performance, utilizing data obtained from distribution and transmission companies within the deregulated power system.",2
"In this article, the causes of technological disturbances in electrical systems are considered, and several characteristic disadvantages of the protection and automation of elements of electrical systems are highlighted. The tendency to decrease the reliability of relay protection associated with the transition from analog to digital types of protection is substantiated. An algorithm of protection and automation operation using fuzzy logic elements has been developed. This article analyzes the most common damages and presents the results of modeling an electrical system with transformer coupling, where all types of asymmetric short circuits were initiated. The dynamics of changes in the symmetrical components of short-circuit currents of the forward, reverse, and zero sequences are determined. Rules have been created for the identification of asymmetric types of short circuits. Based on the studied examples, the use of fuzzy logic in protections, the expediency of using fuzzy logic elements in protection devices, and the automation of electrical systems to identify types of short circuits are justified. The proposed algorithm of protection and automation will reduce the time to determine the type of damage and trigger protections.","﻿In this article, the causes of technological disturbances in electrical systems are considered, and several characteristic disadvantages of the protection and automation of elements of electrical systems are highlighted. The tendency to decrease the reliability of relay protection associated with the transition from analog to digital types of protection is substantiated. Based on the studied examples, the use of fuzzy logic in protections, the expediency of using fuzzy logic elements in protection devices, and the automation of electrical systems to identify types of short circuits are justified. This article analyzes the most common damages and presents the results of modeling an electrical system with transformer coupling, where all types of asymmetric short circuits were initiated. The dynamics of changes in the symmetrical components of short-circuit currents of the forward, reverse, and zero sequences are determined. Rules have been created for the identification of asymmetric types of short circuits. An algorithm of protection and automation operation using fuzzy logic elements has been developed. The proposed algorithm of protection and automation will reduce the time to determine the type of damage and trigger protections.",2
"This study presents to design of a usability metric framework and then quantifies the overall usability quality of an m-commerce mobile application with the help of fuzzy logic. The usability of any mobile application is used to find out the user experience of the mobile application by analyzing the user's expectations and preferences. Fuzzy logic always be the optimal choice for quantification. Fuzzy logic-based quantification of usability expectation assesses the user experience of an m-commerce mobile application by taking into account the user's needs, preferences, and expectations. This process helps to identify areas of improvement, enabling the developers to make necessary changes for a better user experience. Usability expectation also takes into account the ability of the user to understand and interact with the application, the degree to which the application meets the user's expectations, and the overall satisfaction with the application. Fuzzy logic-based quantification of usability expectation for an m-commerce mobile application is a process of measuring the usability of a mobile application by using fuzzy logic principles. The proposed usability metric framework is based on the Goal-Question-Metric (GQM) approach and is intended to provide a comprehensive and systematic approach to design metrics to assess the qualitative aspect of mobile phone applications. The framework has been developed and tested in an m-commerce context and provides a set of measurable criteria to quantify m-commerce mobile applications as per standard. The results of the evaluation can then be used to improve m-commerce mobile applications and to ensure that the user experience is optimized","﻿Fuzzy logic-based quantification of usability expectation for an m-commerce mobile application is a process of measuring the usability of a mobile application by using fuzzy logic principles. The usability of any mobile application is used to find out the user experience of the mobile application by analyzing the user's expectations and preferences. Fuzzy logic always be the optimal choice for quantification. Fuzzy logic-based quantification of usability expectation assesses the user experience of an m-commerce mobile application by taking into account the user's needs, preferences, and expectations. Usability expectation also takes into account the ability of the user to understand and interact with the application, the degree to which the application meets the user's expectations, and the overall satisfaction with the application. This process helps to identify areas of improvement, enabling the developers to make necessary changes for a better user experience. This study presents to design of a usability metric framework and then quantifies the overall usability quality of an m-commerce mobile application with the help of fuzzy logic. The proposed usability metric framework is based on the Goal-Question-Metric (GQM) approach and is intended to provide a comprehensive and systematic approach to design metrics to assess the qualitative aspect of mobile phone applications. The framework has been developed and tested in an m-commerce context and provides a set of measurable criteria to quantify m-commerce mobile applications as per standard. The results of the evaluation can then be used to improve m-commerce mobile applications and to ensure that the user experience is optimized",2
"The performance of photovoltaic (PV) affected directly by climatic changes, The controller maintain maximum potential energy conversation to operate the pimping system at nominal conditions, fuzzy logic intelligent controllers are successfully suitable and applicable in engineering and applied science. The aim of this paper is present an experimental approach in Implementation of fuzzy logic maximum power point tracking (MPPT) with boost converter based on Arduino Mega micro-controller to maximize energy production in different weather condition applied to small scale pumping system for water and chemical fluid analyses in isolated area. The system is supplied by 20 (W) solar photovoltaic (PV) panel. This paper present a real-time MATLAB/Simulink fuzzy logic method controlling and monitoring MPPT application using an low cost Arduino Mega micro-controller combined with (LV25, LP55) sensors controlling boost converter interconnected with solar panel and plastic pump.","﻿The performance of photovoltaic (PV) affected directly by climatic changes, The controller maintain maximum potential energy conversation to operate the pimping system at nominal conditions, fuzzy logic intelligent controllers are successfully suitable and applicable in engineering and applied science. The aim of this paper is present an experimental approach in Implementation of fuzzy logic maximum power point tracking (MPPT) with boost converter based on Arduino Mega micro-controller to maximize energy production in different weather condition applied to small scale pumping system for water and chemical fluid analyses in isolated area. The system is supplied by 20 (W) solar photovoltaic (PV) panel. This paper present a real-time MATLAB/Simulink fuzzy logic method controlling and monitoring MPPT application using an low cost Arduino Mega micro-controller combined with (LV25, LP55) sensors controlling boost converter interconnected with solar panel and plastic pump.",2
"The FLC's performance is assessed by simulation, and it is meant to be resilient to parameter fluctuations and uncertainties. Several photovoltaic (PV) modules, a DC-DC converter, and loads make up the microgrid. This study proposes an FLC-based voltage control technique that leverages input factors including PV output power, DC-DC converter duty cycle, and load current to identify the best course of action for preserving the system's voltage stability. Due to the widespread use of intermittent PV power, voltage stability is a crucial problem for DC microgrids and is difficult to accomplish. This article employs a fuzzy logic controller (FLC) to investigate voltage stability in a PV-based DC microgrid. The simulation results demonstrate that the suggested FLC-based control strategy successfully maintains the microgrid's voltage stability under a variety of operational circumstances, including changing solar irradiance and load variations. Moreover, the FLC performs better than other control methods.","﻿This article employs a fuzzy logic controller (FLC) to investigate voltage stability in a PV-based DC microgrid. Several photovoltaic (PV) modules, a DC-DC converter, and loads make up the microgrid. Due to the widespread use of intermittent PV power, voltage stability is a crucial problem for DC microgrids and is difficult to accomplish. This study proposes an FLC-based voltage control technique that leverages input factors including PV output power, DC-DC converter duty cycle, and load current to identify the best course of action for preserving the system's voltage stability. The FLC's performance is assessed by simulation, and it is meant to be resilient to parameter fluctuations and uncertainties. The simulation results demonstrate that the suggested FLC-based control strategy successfully maintains the microgrid's voltage stability under a variety of operational circumstances, including changing solar irradiance and load variations. Moreover, the FLC performs better than other control methods.",2
"Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. In this regard, we introduce a general barrier function and prescribed performance methodology to tackle constrained range impediments effectively. This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). With the aid of the dynamic surface technology, we propose a decentralized adaptive event-triggering fault-tolerant (ETFT) formation control strategy.","﻿This article delves into the intricacies of adaptive fuzzy event-triggered formation tracking control for nonholonomic multirobot systems characterized by infinite actuator faults and range constraints. To address these issues, we leverage the power of fuzzy logic systems (FLSs) and employ adaptive methods to approximate unknown nonlinear functions and uncertain parameters present in robotic dynamics. In the course of information exploration, the problems of collision avoidance and connectivity maintenance are ever present due to limitations of distance and visual fields. In this regard, we introduce a general barrier function and prescribed performance methodology to tackle constrained range impediments effectively. Furthermore, to reduce the number of controller executions and compensate for any effect arising from infinite actuator failures, robots engage with their leader at the moment of actuator faults using fewer network communication resources yet maintain uninterrupted tracking of the desired trajectory generated by the leader. With the aid of the dynamic surface technology, we propose a decentralized adaptive event-triggering fault-tolerant (ETFT) formation control strategy. We guarantee that all signals are semi-global uniformly ultimately bounded (SGUUB). Ultimately, we demonstrate the practical feasibility of the ETFT control strategy for nonholonomic multirobot systems.",2
"For the product T-norm, we construct an HDFIS named HDFIS-prod, which easily escapes from the numeric underflow problem. The most frequently used T-norms for computing the firing strengths are product and minimum operators of which the former is often preferred because of its differentiability. However, for high-dimensional problems, the product T-norm suffers from the numeric underflow problem. For the minimum T-norm, an empirical observation led us to develop a mechanism that has the natural ability to deal with super high-dimensional problems, which results in another HDFIS named HDFIS-min. Fuzzy inference systems (FISs) have been developed for many years but the use of FISs for high-dimensional problems is still a challenging task. Both HDFIS-prod and HDFIS-min are tested on 18 datasets with feature dimensions varying from 1024 to 120450. Here, we primarily focus on addressing the problem that is associated with the use of the T-norms for designing high-dimensional FISs (HDFISs). The main novelty is that we propose an adaptive dimension-dependent membership function (DMF). The simulation results demonstrate that both of them have competitive performance on handling high-dimensional datasets.","﻿Fuzzy inference systems (FISs) have been developed for many years but the use of FISs for high-dimensional problems is still a challenging task. The most frequently used T-norms for computing the firing strengths are product and minimum operators of which the former is often preferred because of its differentiability. However, for high-dimensional problems, the product T-norm suffers from the numeric underflow problem. Here, we primarily focus on addressing the problem that is associated with the use of the T-norms for designing high-dimensional FISs (HDFISs). For the product T-norm, we construct an HDFIS named HDFIS-prod, which easily escapes from the numeric underflow problem. The main novelty is that we propose an adaptive dimension-dependent membership function (DMF). For the minimum T-norm, an empirical observation led us to develop a mechanism that has the natural ability to deal with super high-dimensional problems, which results in another HDFIS named HDFIS-min. Both HDFIS-prod and HDFIS-min are tested on 18 datasets with feature dimensions varying from 1024 to 120450. The simulation results demonstrate that both of them have competitive performance on handling high-dimensional datasets.",2
"Conventional direct torque control and indirect control with flux orientation have some drawbacks, such as current harmonics, torque ripples, flux ripples, and rise time. This article examines a solution to the major problems of induction machine control in order to achieve superior dynamic performance. In this article, we propose a comparative analysis between previous approaches and the one using fuzzy logic. Results from the simulation show that the direct torque control method using fuzzy logic is more effective in providing a precise and fast response without overshooting, and it eliminates torque and flux fluctuations at low switching frequencies. The demonstrated improvements in dynamic performance contribute to increased operational efficiency and reliability in industrial applications.","﻿This article examines a solution to the major problems of induction machine control in order to achieve superior dynamic performance. Conventional direct torque control and indirect control with flux orientation have some drawbacks, such as current harmonics, torque ripples, flux ripples, and rise time. In this article, we propose a comparative analysis between previous approaches and the one using fuzzy logic. Results from the simulation show that the direct torque control method using fuzzy logic is more effective in providing a precise and fast response without overshooting, and it eliminates torque and flux fluctuations at low switching frequencies. The demonstrated improvements in dynamic performance contribute to increased operational efficiency and reliability in industrial applications.",2
"The main idea of this paper is the substantiation of the methodological approach to the assessment of personnel risks of enterprises based on the application of the fuzzy logic apparatus in order to identify the problems of personnel risk management and provide appropriate recommendations for their solution. Here, the functions r, g, h, q, f are unknown functions of the given variables. The methods of fuzzy set theory, comparative analysis, scientific abstraction, generalization of scientific experience of modern theoretical research, systemcomplex approach were used. The study proposed a methodological approach to assessing the level of personnel risks of an enterprise; numerical experiments were conducted on the basis of a group of construction equipment manufacturers. Analysis of the results of assessing the level of personnel risks of enterprises made it possible to identify the problems of managing personnel risks at enterprises Statement of a mathematical problem: the work considers hierarchical fuzzy data, namely: four groups of indicators for assessing the level of personnel risks (quantitative composition – F1, state of qualifications and intellectual potential – F2, staff turnover – F3, motivational system – F4), each of the indicators has a different number of fuzzy coefficients (there are twelve of them in the current work – vi , i=1÷12). The proposed methodological approach to assessing the level of personnel risks of enterprises based on the apparatus of fuzzy logic allows, in contrast to existing ones, to integrate the consideration of both qualitative and quantitative indicators when assessing the level of personnel risks and personnel movement indicators and to significantly increase the efficiency of decision-making under conditions of uncertainty and reduce costs in the event of adverse situations. As an output variable, there is a functional – an integrated indicator Int = f(F1, F2, F3, F4) of the personnel risk level, which, in turn, is also a fuzzy value. The methodological basis of the study is the classic provisions and fundamental works of foreign and domestic scientists, statistical data, the results of our research into the problems of assessing personnel risks of enterprises. We have expert evaluations of the change in all input data; as a rule, they vary within three terms: Low (I), Medium (G), High (E). Formalized information on each variable can be written as , then for a group of indicators we have: . Using a fuzzy system and performing calculations with its help requires the system to have the following structural elements: membership functions of input and output variables, a rule base, and an output mechanism. These structural elements are the components that will be built when designing a fuzzy system. The built mathematical model and the method of its formalization on the basis of FST make it possible to estimate the level of personnel risk at the enterprise, which enables further substantiation of a set of measures to increase the efficiency of its use. The constructed system of fuzzy logical inference can be considered intelligent as it uses elements of computational intelligence, in particular, the theory of fuzzy sets. Indicators are functions of fuzzy coefficients: F1 = r(v1, v2, v3); F2 = g(v4,v5, v6, v7); F3 = h(v8, v9, v10,); F4=q(v11, v12).","﻿The main idea of this paper is the substantiation of the methodological approach to the assessment of personnel risks of enterprises based on the application of the fuzzy logic apparatus in order to identify the problems of personnel risk management and provide appropriate recommendations for their solution. The methodological basis of the study is the classic provisions and fundamental works of foreign and domestic scientists, statistical data, the results of our research into the problems of assessing personnel risks of enterprises. The methods of fuzzy set theory, comparative analysis, scientific abstraction, generalization of scientific experience of modern theoretical research, systemcomplex approach were used. The study proposed a methodological approach to assessing the level of personnel risks of an enterprise; numerical experiments were conducted on the basis of a group of construction equipment manufacturers. Analysis of the results of assessing the level of personnel risks of enterprises made it possible to identify the problems of managing personnel risks at enterprises Statement of a mathematical problem: the work considers hierarchical fuzzy data, namely: four groups of indicators for assessing the level of personnel risks (quantitative composition – F1, state of qualifications and intellectual potential – F2, staff turnover – F3, motivational system – F4), each of the indicators has a different number of fuzzy coefficients (there are twelve of them in the current work – vi , i=1÷12). Indicators are functions of fuzzy coefficients: F1 = r(v1, v2, v3); F2 = g(v4,v5, v6, v7); F3 = h(v8, v9, v10,); F4=q(v11, v12). As an output variable, there is a functional – an integrated indicator Int = f(F1, F2, F3, F4) of the personnel risk level, which, in turn, is also a fuzzy value. Here, the functions r, g, h, q, f are unknown functions of the given variables. We have expert evaluations of the change in all input data; as a rule, they vary within three terms: Low (I), Medium (G), High (E). Formalized information on each variable can be written as , then for a group of indicators we have: . Using a fuzzy system and performing calculations with its help requires the system to have the following structural elements: membership functions of input and output variables, a rule base, and an output mechanism. These structural elements are the components that will be built when designing a fuzzy system. The built mathematical model and the method of its formalization on the basis of FST make it possible to estimate the level of personnel risk at the enterprise, which enables further substantiation of a set of measures to increase the efficiency of its use. The constructed system of fuzzy logical inference can be considered intelligent as it uses elements of computational intelligence, in particular, the theory of fuzzy sets. The proposed methodological approach to assessing the level of personnel risks of enterprises based on the apparatus of fuzzy logic allows, in contrast to existing ones, to integrate the consideration of both qualitative and quantitative indicators when assessing the level of personnel risks and personnel movement indicators and to significantly increase the efficiency of decision-making under conditions of uncertainty and reduce costs in the event of adverse situations.",2
"Real-acting objects are characterized by the presence of various types of random perturbations, which significantly reduce the quality of the control process, which determines the use of modern methods of intellectual technology to solve the problem of synthesis of control systems of structurally complex dynamic objects, allowing to compensate the influence of external factors with the properties of randomness and partial uncertainty. The article considers issues of synthesis of the automatic control system of dynamic objects by applying the theory of intelligent control. The effectiveness of the neuro-fuzzy regulator is explained by the possibility of providing quality control of the dynamic object under random perturbations and uncertainty of input data. The radial basis function is designed to approximate functions defined in the implicit form of pattern sets. The neuro-fuzzy regulator's parameter configuration is accomplished using a genetic algorithm, enabling more efficient computation to determine the regulator's set parameters. In this case, a neural network based on radial-basis functions is used at each discrete interval for neuro-fuzzy approximation of the control system, allowing real-time adjustment of the regulator parameters. To determine the optimal tuning parameters of the neuro-fuzzy regulator, characterized by high convergence and the possibility of determining global extrema, a genetic algorithm was used. The regulator's parameters are represented as a vector, facilitating their application to multidimensional objects.","﻿Real-acting objects are characterized by the presence of various types of random perturbations, which significantly reduce the quality of the control process, which determines the use of modern methods of intellectual technology to solve the problem of synthesis of control systems of structurally complex dynamic objects, allowing to compensate the influence of external factors with the properties of randomness and partial uncertainty. The article considers issues of synthesis of the automatic control system of dynamic objects by applying the theory of intelligent control. In this case, a neural network based on radial-basis functions is used at each discrete interval for neuro-fuzzy approximation of the control system, allowing real-time adjustment of the regulator parameters. The radial basis function is designed to approximate functions defined in the implicit form of pattern sets. The neuro-fuzzy regulator's parameter configuration is accomplished using a genetic algorithm, enabling more efficient computation to determine the regulator's set parameters. The regulator's parameters are represented as a vector, facilitating their application to multidimensional objects. To determine the optimal tuning parameters of the neuro-fuzzy regulator, characterized by high convergence and the possibility of determining global extrema, a genetic algorithm was used. The effectiveness of the neuro-fuzzy regulator is explained by the possibility of providing quality control of the dynamic object under random perturbations and uncertainty of input data.",2
"Easy internet access and technological advancements have resulted in information overload and a plethora of options, making decision-making extremely difficult. In addition to comparing CNN-based RSs on common grounds, this article provides a full examination of CNN-based RSs and how they might use various types of auxiliary information. Three fundamental forms of RS that use implicit or explicit feedback for recommendation are collaborative, content-based, and hybrid filtering. Ratings are the most common form of feedback, but product descriptions, reviews, images, audios, and videos are also important and can help improve the performance of the traditional RS. These additional variables can have a significant impact on RS’s performance. The study also discusses data characteristics, data statistics, and auxiliary information in a variety of publicly available datasets. Recommender System (RS) is a potential solution for assisting users in making decisions by recommending or predicting product ratings. Traditional RSs used approaches based on the nearest neighbor or other machine learning models, but thanks to recent advances in artificial intelligence and deep learning, RSs are now being developed using Convolutional Neural Networks (CNN), which can efficiently exploit auxiliary information. Different evaluation measures for RSs are also discussed, and readers are provided with interesting challenges and open research issues.","Easy internet access and technological advancements have resulted in information overload and a plethora of options, making decision-making extremely difficult. Recommender System (RS) is a potential solution for assisting users in making decisions by recommending or predicting product ratings. Three fundamental forms of RS that use implicit or explicit feedback for recommendation are collaborative, content-based, and hybrid filtering. Ratings are the most common form of feedback, but product descriptions, reviews, images, audios, and videos are also important and can help improve the performance of the traditional RS. These additional variables can have a significant impact on RS’s performance. Traditional RSs used approaches based on the nearest neighbor or other machine learning models, but thanks to recent advances in artificial intelligence and deep learning, RSs are now being developed using Convolutional Neural Networks (CNN), which can efficiently exploit auxiliary information. In addition to comparing CNN-based RSs on common grounds, this article provides a full examination of CNN-based RSs and how they might use various types of auxiliary information. The study also discusses data characteristics, data statistics, and auxiliary information in a variety of publicly available datasets. Different evaluation measures for RSs are also discussed, and readers are provided with interesting challenges and open research issues.",2
"It can therefore be applied to all types of education, including language learning, mathematics, science, etc. An education system personalized and optimized by machine learning algorithms can provide customized learning materials and recommendations based on each student's learning history, interests and abilities to improve learning outcomes, and machine learning algorithms can provide real-time feedback on student performance and adjust learning plans based on feedback. Traditional education systems often adopt a one-size-fits-all approach to teaching that does not take into account the unique needs and learning styles of each student. This makes the learning process more dynamic and personalized. In recent years, with the continuous progress and development of science and technology, especially the continuous development of artificial intelligence, machine algorithm and other technologies, the education system has also begun to carry out more personalized content from traditional functions. However, improving the efficiency of machine learning algorithms depends more on the improvement of numerical optimization algorithms, so it is necessary to summarize the optimization algorithms in large-scale machine learning. This paper tries to make a detailed overview of the existing machine learning algorithms in optimizing personalized education recommendation system, and introduces the algorithm optimization process.","In recent years, with the continuous progress and development of science and technology, especially the continuous development of artificial intelligence, machine algorithm and other technologies, the education system has also begun to carry out more personalized content from traditional functions. Traditional education systems often adopt a one-size-fits-all approach to teaching that does not take into account the unique needs and learning styles of each student. An education system personalized and optimized by machine learning algorithms can provide customized learning materials and recommendations based on each student's learning history, interests and abilities to improve learning outcomes, and machine learning algorithms can provide real-time feedback on student performance and adjust learning plans based on feedback. This makes the learning process more dynamic and personalized. It can therefore be applied to all types of education, including language learning, mathematics, science, etc. However, improving the efficiency of machine learning algorithms depends more on the improvement of numerical optimization algorithms, so it is necessary to summarize the optimization algorithms in large-scale machine learning. This paper tries to make a detailed overview of the existing machine learning algorithms in optimizing personalized education recommendation system, and introduces the algorithm optimization process.",2
"This paper presents a comprehensive literature review of the research and application of machine learning (ML) algorithms in recommender systems (RS). The study aims to identify recent trends, explore real-life applications, and guide researchers in positioning their research activities in this domain published in 2023 (Jan-June). The findings are categorized into different domains including education, healthcare, ML algorithms (auto-encoders and reinforcement learning), e-commerce, and digital journalism. The review highlights the enhanced recommendation accuracy, increased scalability, personalization and context awareness, diverse ML techniques, and strategies for handling cold start and data sparsity, and the foundation for future advancements in ML algorithms for RSs considering the application in manufacturing enterprises.","This paper presents a comprehensive literature review of the research and application of machine learning (ML) algorithms in recommender systems (RS). The study aims to identify recent trends, explore real-life applications, and guide researchers in positioning their research activities in this domain published in 2023 (Jan-June). The findings are categorized into different domains including education, healthcare, ML algorithms (auto-encoders and reinforcement learning), e-commerce, and digital journalism. The review highlights the enhanced recommendation accuracy, increased scalability, personalization and context awareness, diverse ML techniques, and strategies for handling cold start and data sparsity, and the foundation for future advancements in ML algorithms for RSs considering the application in manufacturing enterprises.",2
"Smart cities represent the convergence of information and communication technologies (ICT) with urban management to improve the quality of life of city dwellers. This research is seen as a significant breakthrough that can drive the evolution and efficiency of smart cities, establishing a solid framework for future research in this dynamic field. In this context, recommender systems, tools that offer personalised suggestions to city dwellers, have emerged as key contributors to this convergence. Our methodology included reviewing the Web of Science database, resulting in 130 articles that, filtered for relevancy, were reduced to 86. The first stage consisted of carrying out a bibliometric analysis with the objective of analysing structural aspects with the SciMAT tool. Secondly, a systematic literature review was undertaken using the PRISMA 2020 statement. The results illustrated the different processes by which recommendations are filtered in areas such as tourism, health, mobility, and transport. Their successful application in various areas of city life and their ability to process massive amounts of data generated in urban environments has expedited their status as a crucial technology in the evolution of city planning.","Smart cities represent the convergence of information and communication technologies (ICT) with urban management to improve the quality of life of city dwellers. In this context, recommender systems, tools that offer personalised suggestions to city dwellers, have emerged as key contributors to this convergence. Their successful application in various areas of city life and their ability to process massive amounts of data generated in urban environments has expedited their status as a crucial technology in the evolution of city planning. Our methodology included reviewing the Web of Science database, resulting in 130 articles that, filtered for relevancy, were reduced to 86. The first stage consisted of carrying out a bibliometric analysis with the objective of analysing structural aspects with the SciMAT tool. Secondly, a systematic literature review was undertaken using the PRISMA 2020 statement. The results illustrated the different processes by which recommendations are filtered in areas such as tourism, health, mobility, and transport. This research is seen as a significant breakthrough that can drive the evolution and efficiency of smart cities, establishing a solid framework for future research in this dynamic field.",2
"Internet of Things (IoT) based remote healthcare applications provide fast and preventative medical services to the patients at risk. However, predicting heart disease is a complex task and diagnosis results are rarely accurate. A cardiovascular disease prediction model is implemented by using BiGRU (Bidirectional-Gated Recurrent Unit) attention model which diagnose the cardiovascular disease and classify into five available cardiovascular classes. The performance of the DEEP-CARDIO is validated by Cloud Simulator (CloudSim) using the real-time Framingham’s and Statlog heart disease dataset. An Arduino controller receives the collected data from the IoT sensors to predict and diagnose the disease. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed for providing prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, the physiological data are collected from the patient’s remotely by using the four bio sensors such as ECG sensor, Pressure sensor, Pulse sensor and Glucose sensor. The recommendation system provides physical and dietary recommendations to cardiac patients based on the classified data, via user mobile application. The proposed DEEP CARDIO method achieves an overall accuracy of 99.90% whereas, the MABC-SVM, HCBDA and MLbPM method achieves 86.91%, 88.65% and 93.63% respectively.","Internet of Things (IoT) based remote healthcare applications provide fast and preventative medical services to the patients at risk. However, predicting heart disease is a complex task and diagnosis results are rarely accurate. To address this issue, a novel Recommendation System for Cardiovascular Disease Prediction Using IoT Network (DEEP-CARDIO) has been proposed for providing prior diagnosis, treatment, and dietary recommendations for cardiac diseases. Initially, the physiological data are collected from the patient’s remotely by using the four bio sensors such as ECG sensor, Pressure sensor, Pulse sensor and Glucose sensor. An Arduino controller receives the collected data from the IoT sensors to predict and diagnose the disease. A cardiovascular disease prediction model is implemented by using BiGRU (Bidirectional-Gated Recurrent Unit) attention model which diagnose the cardiovascular disease and classify into five available cardiovascular classes. The recommendation system provides physical and dietary recommendations to cardiac patients based on the classified data, via user mobile application. The performance of the DEEP-CARDIO is validated by Cloud Simulator (CloudSim) using the real-time Framingham’s and Statlog heart disease dataset. The proposed DEEP CARDIO method achieves an overall accuracy of 99.90% whereas, the MABC-SVM, HCBDA and MLbPM method achieves 86.91%, 88.65% and 93.63% respectively.",2
"The latest effort in delivering computing resources as a service to managers and consumers represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to users over the internet from large-scale data centers. However, with the advent of the cloud-based IoT and artificial intelligence (AI), which are advancing customer experience automations in many application areas, such as recommender systems (RS), a need has arisen for various modifications to support the IoT devices that are at the center of the automation world, including recent language models like ChatGPT and Bard and technologies like nanotechnology. Indeed, our conceptualization of the “fog-based recommender systems” opens many novel and challenging avenues for academic research, some of which are highlighted in the later part of this paper. Although numerous research studies have been published on FC “smart” applications, none hitherto have been conducted on fog-based smart marketing domains such as recommender systems. FC is considered a novel computational system, which can mitigate latency and improve bandwidth utilization for autonomous consumer behavior applications requiring real-time data-driven decision making. This paper provides a conceptual framework for studying the effects of fog computing on consumer behavior, with the goal of stimulating future research by using, as an example, the intersection of FC and RS. This paper introduces the marketing community to a recent computing development: IoT-driven fog computing (FC). Keywords: fog computing; recommender system; internet of things (IoT); edge computing; artificial intelligence (AI); software defined networks (SDNs)
ormation as well as personal and situational data [66].","The latest effort in delivering computing resources as a service to managers and consumers represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to users over the internet from large-scale data centers. However, with the advent of the cloud-based IoT and artificial intelligence (AI), which are advancing customer experience automations in many application areas, such as recommender systems (RS), a need has arisen for various modifications to support the IoT devices that are at the center of the automation world, including recent language models like ChatGPT and Bard and technologies like nanotechnology. This paper introduces the marketing community to a recent computing development: IoT-driven fog computing (FC). Although numerous research studies have been published on FC “smart” applications, none hitherto have been conducted on fog-based smart marketing domains such as recommender systems. FC is considered a novel computational system, which can mitigate latency and improve bandwidth utilization for autonomous consumer behavior applications requiring real-time data-driven decision making. This paper provides a conceptual framework for studying the effects of fog computing on consumer behavior, with the goal of stimulating future research by using, as an example, the intersection of FC and RS. Indeed, our conceptualization of the “fog-based recommender systems” opens many novel and challenging avenues for academic research, some of which are highlighted in the later part of this paper.
Keywords: fog computing; recommender system; internet of things (IoT); edge computing; artificial intelligence (AI); software defined networks (SDNs)
ormation as well as personal and situational data [66].",2
"Purpose: The general purpose of the study was to investigate the effectiveness of recommender systems in knowledge discovery. Methodology: The study adopted a desktop research methodology. Desk research is basically involved in collecting data from existing resources hence it is often considered a low cost technique as compared to field research, as the main cost is involved in executive’s time, telephone charges and directories. Desk research refers to secondary data or that which can be collected without fieldwork. Thus, the study relied on already published studies, reports and statistics. This secondary data was easily accessed through the online journals and library. Furthermore, it recommended the use of explainable AI techniques to improve transparency and user understanding of recommendation processes. The study on the effectiveness of recommender systems in knowledge discovery found that such systems played a pivotal role in facilitating users' exploration of vast information repositories, enabling them to uncover relevant resources and expand their knowledge. It found that recommender systems employing advanced algorithms and personalized techniques demonstrated higher effectiveness in generating relevant recommendations tailored to users' preferences and needs. Additionally, the study highlighted the positive correlation between user engagement metrics and knowledge discovery outcomes, emphasizing the importance of fostering active user participation in the recommendation process. Contextual information was also identified as a crucial factor influencing recommendation effectiveness. Overall, the study underscored the significance of continuous refinement and optimization of recommender system algorithms to enhance knowledge discovery outcomes for users. Unique Contribution to Theory, Practice and Policy: The Social Learning theory, Information Foraging theory and Cognitive Load theory may be used to anchor future studies on recommender systems in knowledge discovery. The study provided recommendations to enhance the efficacy of such systems. It suggested adopting hybrid recommender systems that combine collaborative and content-based filtering techniques to offer more accurate and diverse recommendations. Additionally, the study emphasized the importance of integrating contextual information into recommendation algorithms to dynamically adjust recommendations based on situational context. Findings: The findings reveal that there exists a contextual and methodological gap relating to recommender systems in knowledge discovery. Maximizing user engagement through active participation and feedback was also highlighted as crucial, along with prioritizing recommendation diversity to foster exploration and serendipitous discovery of new knowledge resources.","Purpose: The general purpose of the study was to investigate the effectiveness of recommender systems in knowledge discovery. Methodology: The study adopted a desktop research methodology. Desk research refers to secondary data or that which can be collected without fieldwork. Desk research is basically involved in collecting data from existing resources hence it is often considered a low cost technique as compared to field research, as the main cost is involved in executive’s time, telephone charges and directories. Thus, the study relied on already published studies, reports and statistics. This secondary data was easily accessed through the online journals and library. Findings: The findings reveal that there exists a contextual and methodological gap relating to recommender systems in knowledge discovery. The study on the effectiveness of recommender systems in knowledge discovery found that such systems played a pivotal role in facilitating users' exploration of vast information repositories, enabling them to uncover relevant resources and expand their knowledge. It found that recommender systems employing advanced algorithms and personalized techniques demonstrated higher effectiveness in generating relevant recommendations tailored to users' preferences and needs. Additionally, the study highlighted the positive correlation between user engagement metrics and knowledge discovery outcomes, emphasizing the importance of fostering active user participation in the recommendation process. Contextual information was also identified as a crucial factor influencing recommendation effectiveness. Overall, the study underscored the significance of continuous refinement and optimization of recommender system algorithms to enhance knowledge discovery outcomes for users. Unique Contribution to Theory, Practice and Policy: The Social Learning theory, Information Foraging theory and Cognitive Load theory may be used to anchor future studies on recommender systems in knowledge discovery. The study provided recommendations to enhance the efficacy of such systems. It suggested adopting hybrid recommender systems that combine collaborative and content-based filtering techniques to offer more accurate and diverse recommendations. Additionally, the study emphasized the importance of integrating contextual information into recommendation algorithms to dynamically adjust recommendations based on situational context. Furthermore, it recommended the use of explainable AI techniques to improve transparency and user understanding of recommendation processes. Maximizing user engagement through active participation and feedback was also highlighted as crucial, along with prioritizing recommendation diversity to foster exploration and serendipitous discovery of new knowledge resources.",2
"The application of Artificial Intelligence (AI) is significantly increasing in many Human Resources (HR) functions. In this study, we have delved into the various challenges of matching employee profiles to job profiles and the current problems faced by executives, human resource personnel or supervisors such as project managers in an organisation. This study employs a Delphi study-based methodology specifically, organising an expert panel that provides their opinions through their ratings and comments of a set of propositions. Based on the online Delphi study results and participant opinions, this research aims to identify the challenges related to employee-job profile matching through artificial intelligence and machine learning tools in the form of recommender systems. This research aims to understand how diverse experts from distinct organisations, such as Project Managers, Managers, Supervisors and Human Resource Managers, perceive the potential of artificial intelligence-based recommender systems to match job profiles with employee profiles. The study also sheds light on the potential or feasibility solutions of artificial intelligence in the form of recommender systems where we also test a couple of propositions that focus on potential solutions and various challenges for matching employee profiles to job profiles in an organisation.","The application of Artificial Intelligence (AI) is significantly increasing in many Human Resources (HR) functions. This research aims to understand how diverse experts from distinct organisations, such as Project Managers, Managers, Supervisors and Human Resource Managers, perceive the potential of artificial intelligence-based recommender systems to match job profiles with employee profiles. This study employs a Delphi study-based methodology specifically, organising an expert panel that provides their opinions through their ratings and comments of a set of propositions. Based on the online Delphi study results and participant opinions, this research aims to identify the challenges related to employee-job profile matching through artificial intelligence and machine learning tools in the form of recommender systems. In this study, we have delved into the various challenges of matching employee profiles to job profiles and the current problems faced by executives, human resource personnel or supervisors such as project managers in an organisation. The study also sheds light on the potential or feasibility solutions of artificial intelligence in the form of recommender systems where we also test a couple of propositions that focus on potential solutions and various challenges for matching employee profiles to job profiles in an organisation.",2
"To do this, we can analyze the user’s facial expression to deduce their feelings. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. The proposed system can be utilized in different places where real-time facial recognition plays an important role. The OAHEGA and FER-2013 datasets were utilized for experimental study. One use case for face emotion detection is playing music based on the user’s mood. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach.","Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.",2
"It compares these algorithms with the non-fused approach. The study begins by collecting Douban movie rating data and social network information. To ensure data integrity, Levenshtein distance detection is employed to remove duplicate scores, while natural language processing technology is utilized to extract keywords and topic information from social texts. Additionally, graph convolutional networks are utilized to convert user relationships into feature vectors, and a unique thermal coding method is used to convert discrete user and movie information into binary matrices. To prevent overfitting, the Ridge regularization method is introduced to gradually optimize potential feature vectors. Weighted average and feature connection techniques are then applied to integrate features from different fields. In the experimental stage, the paper conducts cross-domain information fusion optimization on four mainstream mathematical matrix decomposition algorithms: alternating least squares method, non-negative matrix decomposition, singular value decomposition, and latent factor model (LFM). Moreover, the paper combines the item-based collaborative filtering algorithm with merged user characteristics to generate personalized recommendation lists. The results indicate a significant improvement in score accuracy, with mean absolute error and root mean squared error reduced by 12.8% and 13.2% respectively across the four algorithms. Overall, the mathematical matrix decomposition algorithm combined with cross-domain information fusion demonstrates clear advantages in accuracy, prediction performance, recommendation diversity, and ranking quality, and improves the accuracy and diversity of the recommendation system. Additionally, when k = 10, the average F1 score reaches 0.97, and the ranking accuracy coverage of the LFM algorithm increases by 54.2%. Given the challenges of inter-domain information fusion and data sparsity in collaborative filtering algorithms, this paper proposes a cross-domain information fusion matrix decomposition algorithm to enhance the accuracy of personalized recommendations in artificial intelligence recommendation systems. By effectively addressing collaborative filtering challenges through the integration of diverse techniques, it significantly surpasses traditional models in recommendation accuracy and variety.","Given the challenges of inter-domain information fusion and data sparsity in collaborative filtering algorithms, this paper proposes a cross-domain information fusion matrix decomposition algorithm to enhance the accuracy of personalized recommendations in artificial intelligence recommendation systems. The study begins by collecting Douban movie rating data and social network information. To ensure data integrity, Levenshtein distance detection is employed to remove duplicate scores, while natural language processing technology is utilized to extract keywords and topic information from social texts. Additionally, graph convolutional networks are utilized to convert user relationships into feature vectors, and a unique thermal coding method is used to convert discrete user and movie information into binary matrices. To prevent overfitting, the Ridge regularization method is introduced to gradually optimize potential feature vectors. Weighted average and feature connection techniques are then applied to integrate features from different fields. Moreover, the paper combines the item-based collaborative filtering algorithm with merged user characteristics to generate personalized recommendation lists. In the experimental stage, the paper conducts cross-domain information fusion optimization on four mainstream mathematical matrix decomposition algorithms: alternating least squares method, non-negative matrix decomposition, singular value decomposition, and latent factor model (LFM). It compares these algorithms with the non-fused approach. The results indicate a significant improvement in score accuracy, with mean absolute error and root mean squared error reduced by 12.8% and 13.2% respectively across the four algorithms. Additionally, when k = 10, the average F1 score reaches 0.97, and the ranking accuracy coverage of the LFM algorithm increases by 54.2%. Overall, the mathematical matrix decomposition algorithm combined with cross-domain information fusion demonstrates clear advantages in accuracy, prediction performance, recommendation diversity, and ranking quality, and improves the accuracy and diversity of the recommendation system. By effectively addressing collaborative filtering challenges through the integration of diverse techniques, it significantly surpasses traditional models in recommendation accuracy and variety.",2
"Video games have been in the focus of the research and academic community for the last few years, with the study and experimentation of Artificial General Intelligence (AGI) standing out. Moreover, GAGI provides the user with a unique environment for simulating and studying AI agents inside the created game. Users can deploy multiple AI agents while interacting with them in real time, improving the understanding of their interactions and behaviors. GAGI also offers the possibility to reproduce the experiments, opening up multiple possibilities for the research community. As a game engine, GAGI is able to design and create novel 2D and 3D video games using C++ programming language. In this work a novel game engine, called GAGI, capable of serving as an AGI experimentation platform is presented. The features of the proposed software is compared against others widely-used game engines in the video games industry as well as in the research community, highlighting the advantages in terms of design capability and AI support. AGI experimentation platforms allow to analyze and study, in a visual way, the behavior of different AI agents previously defined.","Video games have been in the focus of the research and academic community for the last few years, with the study and experimentation of Artificial General Intelligence (AGI) standing out. AGI experimentation platforms allow to analyze and study, in a visual way, the behavior of different AI agents previously defined. In this work a novel game engine, called GAGI, capable of serving as an AGI experimentation platform is presented. As a game engine, GAGI is able to design and create novel 2D and 3D video games using C++ programming language. Moreover, GAGI provides the user with a unique environment for simulating and studying AI agents inside the created game. Users can deploy multiple AI agents while interacting with them in real time, improving the understanding of their interactions and behaviors. The features of the proposed software is compared against others widely-used game engines in the video games industry as well as in the research community, highlighting the advantages in terms of design capability and AI support. GAGI also offers the possibility to reproduce the experiments, opening up multiple possibilities for the research community.",2
"Monte Carlo Tree Search (MCTS) is a pronounced empirical search algorithm for agent decision-making, especially when enhanced by Deep Learning (DL), in mastering board games that were once thought to be unconquerable. However, it does not appear to be as equally successful in the domain of real-time video games, where the simulation time limit for exploration is a crucial factor, since they are generally designed to be played by human users and hence require a significant amount of resources for simulation. We validated the performance of our method by conducting a comparative experiment with other algorithms, including the traditional MCTS, under the environment of a commercial real-time video game. We in this paper propose a surrogate-assisted MCTS approach, specifically targeting commercial real-time video games by approximating the result of gameplay with a deep-learning-based surrogate model. Since commercial video games include considerably more complex and dynamic gameplays to satisfy their market consumers, as opposed to their non-commercial analogs, our work can be regarded as having challenged the domain unattempted by precedent studies. The key contribution of our work is that we designed a modified MCTS for video games that are both commercial and processed in real-time.","Monte Carlo Tree Search (MCTS) is a pronounced empirical search algorithm for agent decision-making, especially when enhanced by Deep Learning (DL), in mastering board games that were once thought to be unconquerable. However, it does not appear to be as equally successful in the domain of real-time video games, where the simulation time limit for exploration is a crucial factor, since they are generally designed to be played by human users and hence require a significant amount of resources for simulation. We in this paper propose a surrogate-assisted MCTS approach, specifically targeting commercial real-time video games by approximating the result of gameplay with a deep-learning-based surrogate model. The key contribution of our work is that we designed a modified MCTS for video games that are both commercial and processed in real-time. Since commercial video games include considerably more complex and dynamic gameplays to satisfy their market consumers, as opposed to their non-commercial analogs, our work can be regarded as having challenged the domain unattempted by precedent studies. We validated the performance of our method by conducting a comparative experiment with other algorithms, including the traditional MCTS, under the environment of a commercial real-time video game.",2
"Whether the application of exergames in physical education (PE) courses can significantly improve student performance in PE learning is still controversial. This review explores the promoting effect of exergames on student PE learning and the conditions in which the effect of exergames can be maximized. The meta-analysis showed that exergames effectively improved student performance in PE learning (SMD = 0.45, 95% CI: 0.27–0.63, P < 0.00001). A total of 16 randomized controlled trials involving 2962 subjects were included in this study. Based on the PICOS method, two researchers independently searched the ProQuest database, EBSCO database, Web of Science (WoS) database, PubMed database, Chinese National Knowledge Infrastructure (CNKI) database, Wanfang database, and VIP database, evaluated the literature quality using the Cochrane system evaluation manual, and performed a meta-analysis of the included literature. Subgroup analysis indicated that better results could be achieved when exergames were introduced in small kindergarten classes and continued for 1–2 months.","﻿Whether the application of exergames in physical education (PE) courses can significantly improve student performance in PE learning is still controversial. This review explores the promoting effect of exergames on student PE learning and the conditions in which the effect of exergames can be maximized. Based on the PICOS method, two researchers independently searched the ProQuest database, EBSCO database, Web of Science (WoS) database, PubMed database, Chinese National Knowledge Infrastructure (CNKI) database, Wanfang database, and VIP database, evaluated the literature quality using the Cochrane system evaluation manual, and performed a meta-analysis of the included literature. A total of 16 randomized controlled trials involving 2962 subjects were included in this study. The meta-analysis showed that exergames effectively improved student performance in PE learning (SMD = 0.45, 95% CI: 0.27–0.63, P < 0.00001). Subgroup analysis indicated that better results could be achieved when exergames were introduced in small kindergarten classes and continued for 1–2 months.",2
"Artificial Intelligence (AI) stands as a pivotal innovation deeply ingrained in both our daily routines and industrial operations. AI constantly updates human experiences, shaping interactions and augmenting capabilities. For instance, contemporary educational institutions leverage AI algorithms for attendance tracking via facial recognition technology. Its rapid evolution promises transformative impacts across various sectors, from cutting-edge industries to the lives of ordinary individuals. Looking ahead, the advent of autonomous vehicles represents a pinnacle of AI application, where vehicles rely entirely on AI systems for navigation, detecting traffic signals, and navigating roads.","Artificial Intelligence (AI) stands as a pivotal innovation deeply ingrained in both our daily routines and industrial operations. Its rapid evolution promises transformative impacts across various sectors, from cutting-edge industries to the lives of ordinary individuals. AI constantly updates human experiences, shaping interactions and augmenting capabilities. For instance, contemporary educational institutions leverage AI algorithms for attendance tracking via facial recognition technology. Looking ahead, the advent of autonomous vehicles represents a pinnacle of AI application, where vehicles rely entirely on AI systems for navigation, detecting traffic signals, and navigating roads.",2
"Within paradoxical videogame representations of AI weapons both as insurmountable enemies that pose existential threats to humankind in narratives and as easy targets that human protagonists routinely overcome in gameplay, we identify distortions of human machine interaction that contradict real-world scenarios. In this article, we explore these potentials in the context of military-themed videogames and their portrayals of weaponized artificial intelligence (AI). In so doing, we echo game studies research that calls for greater attention to the commercial and ludic dimensions of videogames so that international relations scholarship can better account for pop cultures bounded abilities to impact public understandings and political realities. These distortions revolve around videogames affording players enhanced human agency to dominate AI weapons to offer enjoyable gameplay, contradicting the same weapons being intended to diminish human agency on real-world battlefields. By leveraging the Actor-Network Theory concept of translation, we explain how these distorted portrayals of AI weapons are produced by entanglements between heterogeneous human and non-human actors that aim to make videogames mass-marketable and profitable. International relations scholarship has long emphasized that popular culture can impact public understandings and political realities.","International relations scholarship has long emphasized that popular culture can impact public understandings and political realities. In this article, we explore these potentials in the context of military-themed videogames and their portrayals of weaponized artificial intelligence (AI). Within paradoxical videogame representations of AI weapons both as insurmountable enemies that pose existential threats to humankind in narratives and as easy targets that human protagonists routinely overcome in gameplay, we identify distortions of human machine interaction that contradict real-world scenarios. These distortions revolve around videogames affording players enhanced human agency to dominate AI weapons to offer enjoyable gameplay, contradicting the same weapons being intended to diminish human agency on real-world battlefields. By leveraging the Actor-Network Theory concept of translation, we explain how these distorted portrayals of AI weapons are produced by entanglements between heterogeneous human and non-human actors that aim to make videogames mass-marketable and profitable. In so doing, we echo game studies research that calls for greater attention to the commercial and ludic dimensions of videogames so that international relations scholarship can better account for pop cultures bounded abilities to impact public understandings and political realities.",2
"Accurately scientific disciplines, including biomechanics, genetics, ethology, and neurology, it is essential to accurately track the behavior of animals throughout studies, particularly without employing markers. However, it has proven difficult to extract precise stances from backgrounds that are always shifting. Recently, we unveiled an open-source toolset that makes use of a cutting-edge algorithm for estimating human position. With the help of this toolbox, users may train a deep neural network to accurately monitor user-defined features with tracking accuracy that rivals that of human labeling. We have added new features, including as graphical user interfaces (GUIs), efficiency improvements, and network refinement based on active learning, to this revised Python module. In order to help customers create a unique and repeatable analysis pipeline using a graphical processing unit (GPU).","Accurately scientific disciplines, including biomechanics, genetics, ethology, and neurology, it is essential to accurately track the behavior of animals throughout studies, particularly without employing markers. However, it has proven difficult to extract precise stances from backgrounds that are always shifting. Recently, we unveiled an open-source toolset that makes use of a cutting-edge algorithm for estimating human position. With the help of this toolbox, users may train a deep neural network to accurately monitor user-defined features with tracking accuracy that rivals that of human labeling. We have added new features, including as graphical user interfaces (GUIs), efficiency improvements, and network refinement based on active learning, to this revised Python module. In order to help customers create a unique and repeatable analysis pipeline using a graphical processing unit (GPU).",2
"Providing an appropriate difficulty level in a game is critical for keeping players engaged. For this purpose, we examined DDA studies using employed machine-learning techniques, player modeling approaches, data types used to assess players states, testbed game genre, and application. This paper reviews literature addressing mechanisms for adjusting video game difficulties in response to players performance, emotions, or personality. Dynamic Difficulty Adjustment (DDA) is a common approach for optimizing player experience by automatically modifying game aspects. By conducting further research into players cognitive characteristics, such as visual attention, working memory, and response time, it will be possible to understand players preferences better. The findings reveal that most studies have shown significant effects of DDA on parameters such as enjoyment, flow, motivation, engagement, and immersion. In addition, machine-learning and player modeling techniques have recently received more attention in the DDA design. However, given the ever-increasing use of games in various domains, more research is needed to understand player preferences better to adjust game parameters efficiently. Journal and conference articles published up to September 2022 served as the data sources in this review.","Providing an appropriate difficulty level in a game is critical for keeping players engaged. Dynamic Difficulty Adjustment (DDA) is a common approach for optimizing player experience by automatically modifying game aspects. This paper reviews literature addressing mechanisms for adjusting video game difficulties in response to players performance, emotions, or personality. For this purpose, we examined DDA studies using employed machine-learning techniques, player modeling approaches, data types used to assess players states, testbed game genre, and application. Journal and conference articles published up to September 2022 served as the data sources in this review. The findings reveal that most studies have shown significant effects of DDA on parameters such as enjoyment, flow, motivation, engagement, and immersion. In addition, machine-learning and player modeling techniques have recently received more attention in the DDA design. However, given the ever-increasing use of games in various domains, more research is needed to understand player preferences better to adjust game parameters efficiently. By conducting further research into players cognitive characteristics, such as visual attention, working memory, and response time, it will be possible to understand players preferences better.",2
"Serious video games provide a immersive learning environment for agriculture by simulating real-life challenges scenarios. However, empirical evidence of their effectiveness is sparse. This scoping review follows PRISMA-ScR guidelines to summarize literature on serious video games for agricultural learning, highlighting research trends and identifying gaps. We systematically searched nine prominent research databases for papers on serious video games for agriculture learning published between January 2000 and July 2022. Two independent reviewers conducted screening, data extraction, and synthesized the collected data using a narrative approach. The initial search identified 3,297 articles, of which 0.58% ( n = 19) were included in the review. Rigorous research designs are vital for assessing game effectiveness across short, medium, and long terms. They commonly employed a simulation-based approach, featuring 2-D graphics and designed for single-player experiences. These games mainly target students, focusing on crop production and sustainable agriculture. Creating games for underrepresented players and specific agricultural challenges is essential, as is enhancing theoretical foundations and learning approaches. Evaluation protocols primarily consisted of pilot studies, emphasizing user experience and knowledge enhancement. Positive outcomes, such as improved user experiences, knowledge, and attitude and behavior changes, were commonly observed in these studies. Educational theories were often unspecified in the studies. However, it stresses the need for deeper exploration of game elements' impact on user experience and effectiveness. This study highlights advancements in using serious video games for agricultural learning over 20 years. Most reviewed games were released in the last five years, with a predominant presence in the mobile platform.","Serious video games provide a immersive learning environment for agriculture by simulating real-life challenges scenarios. However, empirical evidence of their effectiveness is sparse. This scoping review follows PRISMA-ScR guidelines to summarize literature on serious video games for agricultural learning, highlighting research trends and identifying gaps. We systematically searched nine prominent research databases for papers on serious video games for agriculture learning published between January 2000 and July 2022. Two independent reviewers conducted screening, data extraction, and synthesized the collected data using a narrative approach. The initial search identified 3,297 articles, of which 0.58% ( n = 19) were included in the review. Most reviewed games were released in the last five years, with a predominant presence in the mobile platform. They commonly employed a simulation-based approach, featuring 2-D graphics and designed for single-player experiences. These games mainly target students, focusing on crop production and sustainable agriculture. Educational theories were often unspecified in the studies. Evaluation protocols primarily consisted of pilot studies, emphasizing user experience and knowledge enhancement. Positive outcomes, such as improved user experiences, knowledge, and attitude and behavior changes, were commonly observed in these studies. This study highlights advancements in using serious video games for agricultural learning over 20 years. However, it stresses the need for deeper exploration of game elements' impact on user experience and effectiveness. Creating games for underrepresented players and specific agricultural challenges is essential, as is enhancing theoretical foundations and learning approaches. Rigorous research designs are vital for assessing game effectiveness across short, medium, and long terms.",2
"To achieve higher quality recommendations, a personalized recommendation model for educational video game resources based on knowledge graphs is proposed. Applying games to teaching resources can achieve better teaching outcomes. With the development of education and technology, teachers have gradually realized that games should not be just a way for students to entertain themselves. Firstly, feature extraction is performed alternately on the user side and the item side. The constructed model can achieve efficient and high-quality recommendation of educational video game resources, providing users with a more convenient and efficient online experience. Then a hidden Markov model is introduced on the basis of the dual end neighbor algorithm. Considering the temporal nature of the user, the model is optimized. The optimized model takes into account the long-term and short-term preferences of users and mines their potential preferences. Through experimental analysis, the hit rate index value of the designed model reaches 0.7989. The normalized cumulative gain value of the broken line is 0.6045. More than 89% of users are satisfied with the recommendation of this model. The running time is 0.2863s. However, related resources are constantly emerging on the internet.","With the development of education and technology, teachers have gradually realized that games should not be just a way for students to entertain themselves. Applying games to teaching resources can achieve better teaching outcomes. However, related resources are constantly emerging on the internet. To achieve higher quality recommendations, a personalized recommendation model for educational video game resources based on knowledge graphs is proposed. Firstly, feature extraction is performed alternately on the user side and the item side. Then a hidden Markov model is introduced on the basis of the dual end neighbor algorithm. Considering the temporal nature of the user, the model is optimized. The optimized model takes into account the long-term and short-term preferences of users and mines their potential preferences. Through experimental analysis, the hit rate index value of the designed model reaches 0.7989. The normalized cumulative gain value of the broken line is 0.6045. More than 89% of users are satisfied with the recommendation of this model. The running time is 0.2863s. The constructed model can achieve efficient and high-quality recommendation of educational video game resources, providing users with a more convenient and efficient online experience.",2
"The metaverse has emerged as an exciting new paradigm for human-computer interaction (HCI) and virtual collaboration. Based on this comprehensive analysis, we outline major open challenges and propose promising directions demanding further exploration and investigation. We first synthesize a definition of the metaverse from existing literature and delineate key affordances. By clarifying the vision for the metaverse and characterizing the building blocks required to realize it, this review provides essential insights and serves as an invaluable resource for metaverse developers and researchers working to advance this transformative new medium. The components within this framework are explained in depth, offering insights into the metaverses nature and the readiness level of current technologies. This paper presents a comprehensive review of the metaverse to address the gap in the existing literature where there is a lack of a survey that reviews the nature of the metaverse and its building blocks from a human-centric perspective. We then introduce a detailed framework encompassing the metaverses nature, infrastructure technologies, and input/output technologies that facilitate multi-sensory HCI, alongside applications across diverse domains.","The metaverse has emerged as an exciting new paradigm for human-computer interaction (HCI) and virtual collaboration. This paper presents a comprehensive review of the metaverse to address the gap in the existing literature where there is a lack of a survey that reviews the nature of the metaverse and its building blocks from a human-centric perspective. We first synthesize a definition of the metaverse from existing literature and delineate key affordances. We then introduce a detailed framework encompassing the metaverses nature, infrastructure technologies, and input/output technologies that facilitate multi-sensory HCI, alongside applications across diverse domains. The components within this framework are explained in depth, offering insights into the metaverses nature and the readiness level of current technologies. Based on this comprehensive analysis, we outline major open challenges and propose promising directions demanding further exploration and investigation. By clarifying the vision for the metaverse and characterizing the building blocks required to realize it, this review provides essential insights and serves as an invaluable resource for metaverse developers and researchers working to advance this transformative new medium.",2
"The lifestyle of modern society has changed significantly with the emergence of artificial intelligence (AI), machine learning (ML), and deep learning (DL) technologies in recent years. Artificial intelligence is a multidimensional technology with various components such as advanced algorithms, ML and DL. Together, AI, ML, and DL are expected to provide automated devices to ophthalmologists for early diagnosis and timely treatment of ocular disorders in the near future. Therefore, the detection and treatment of DR, AMD, glaucoma, and other ophthalmic disorders through unmanned automated applications system in the near future will be inevitable. Diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma are the 3 most common causes of irreversible blindness on a global scale. Consequently, given the current population growth trends, it is inevitable that analyzing such images is time-consuming, costly, and prone to human error. We provide an overview of the potential impact of the current AI, ML, and DL methods and their applications on the early detection and treatment of DR, AMD, glaucoma, and other ophthalmic diseases. Of note, OCT has become the most widely used imaging modality in ophthalmology settings in the developed world. Changes in population demographics and lifestyle, extension of average lifespan, and the changing pattern of chronic diseases such as obesity, diabetes, DR, AMD, and glaucoma create a rising demand for such images. In fact, AI, ML, and DL have been used in ophthalmic setting to validate the diagnosis of diseases, read images, perform corneal topographic mapping and intraocular lens calculations. Ophthalmic imaging provides a way to diagnose and objectively detect the progression of a number of pathologies including DR, AMD, glaucoma, and other ophthalmic disorders. Furthermore, the limitation of availability of retina specialists and trained human graders is a major problem in many countries. There are 2 methods of imaging used as diagnostic methods in ophthalmic practice: fundus digital photography and optical coherence tomography (OCT).","The lifestyle of modern society has changed significantly with the emergence of artificial intelligence (AI), machine learning (ML), and deep learning (DL) technologies in recent years. Artificial intelligence is a multidimensional technology with various components such as advanced algorithms, ML and DL. Together, AI, ML, and DL are expected to provide automated devices to ophthalmologists for early diagnosis and timely treatment of ocular disorders in the near future. In fact, AI, ML, and DL have been used in ophthalmic setting to validate the diagnosis of diseases, read images, perform corneal topographic mapping and intraocular lens calculations. Diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma are the 3 most common causes of irreversible blindness on a global scale. Ophthalmic imaging provides a way to diagnose and objectively detect the progression of a number of pathologies including DR, AMD, glaucoma, and other ophthalmic disorders. There are 2 methods of imaging used as diagnostic methods in ophthalmic practice: fundus digital photography and optical coherence tomography (OCT). Of note, OCT has become the most widely used imaging modality in ophthalmology settings in the developed world. Changes in population demographics and lifestyle, extension of average lifespan, and the changing pattern of chronic diseases such as obesity, diabetes, DR, AMD, and glaucoma create a rising demand for such images. Furthermore, the limitation of availability of retina specialists and trained human graders is a major problem in many countries. Consequently, given the current population growth trends, it is inevitable that analyzing such images is time-consuming, costly, and prone to human error. Therefore, the detection and treatment of DR, AMD, glaucoma, and other ophthalmic disorders through unmanned automated applications system in the near future will be inevitable. We provide an overview of the potential impact of the current AI, ML, and DL methods and their applications on the early detection and treatment of DR, AMD, glaucoma, and other ophthalmic diseases.",2
"With the unprecedented advancement of data aggregation and deep learning algorithms, artificial intelligence (AI) and machine learning (ML) are poised to transform the practice of medicine. The purpose of this review is to critically evaluate the recent and novel literature regarding ML in the field of orthopedics and to address its potential impact on the future of musculoskeletal care. The field of orthopedics, in particular, is uniquely suited to harness the power of big data, and in doing so provide critical insight into elevating the many facets of care provided by orthopedic surgeons.","With the unprecedented advancement of data aggregation and deep learning algorithms, artificial intelligence (AI) and machine learning (ML) are poised to transform the practice of medicine. The field of orthopedics, in particular, is uniquely suited to harness the power of big data, and in doing so provide critical insight into elevating the many facets of care provided by orthopedic surgeons. The purpose of this review is to critically evaluate the recent and novel literature regarding ML in the field of orthopedics and to address its potential impact on the future of musculoskeletal care.",2
"In this context, artificial intelligence is seen as one of the major enablers for Smart Logistics and Smart Production initiatives. Industry 4.0 concepts and technologies ensure the ongoing development of micro- and macro-economic entities by focusing on the principles of interconnectivity, digitalization, and automation. Furthermore, based on the results of the systematic literature review, the authors present a conceptual framework, which provides fruitful implications based on recent research findings and insights to be used for directing and starting future research initiatives in the field of artificial intelligence (AI), machine learning (ML), and deep learning (DL) in Smart Logistics. This paper systematically analyzes the scientific literature on artificial intelligence, machine learning, and deep learning in the context of Smart Logistics management in industrial enterprises.","Industry 4.0 concepts and technologies ensure the ongoing development of micro- and macro-economic entities by focusing on the principles of interconnectivity, digitalization, and automation. In this context, artificial intelligence is seen as one of the major enablers for Smart Logistics and Smart Production initiatives. This paper systematically analyzes the scientific literature on artificial intelligence, machine learning, and deep learning in the context of Smart Logistics management in industrial enterprises. Furthermore, based on the results of the systematic literature review, the authors present a conceptual framework, which provides fruitful implications based on recent research findings and insights to be used for directing and starting future research initiatives in the field of artificial intelligence (AI), machine learning (ML), and deep learning (DL) in Smart Logistics.",2
"Machine learning (ML) is a form of artificial intelligence which is placed to transform the twenty-first century. In particular, we showcase recent diagnostic performances, and caveats, in the fields of dermatology, radiology, pathology and general microscopy. These include driving a vehicle, language translation, chatbots and beyond human performance at complex board games such as Go. We then summarise the applications of ML to medicine. Here, we review the fundamentals and algorithms behind machine learning and highlight specific approaches to learning and optimisation. Rapid, recent progress in its underlying architecture and algorithms and growth in the size of datasets have led to increasing computer competence across a range of fields.","Machine learning (ML) is a form of artificial intelligence which is placed to transform the twenty-first century. Rapid, recent progress in its underlying architecture and algorithms and growth in the size of datasets have led to increasing computer competence across a range of fields. These include driving a vehicle, language translation, chatbots and beyond human performance at complex board games such as Go. Here, we review the fundamentals and algorithms behind machine learning and highlight specific approaches to learning and optimisation. We then summarise the applications of ML to medicine. In particular, we showcase recent diagnostic performances, and caveats, in the fields of dermatology, radiology, pathology and general microscopy.",2
"Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) have revolutionized the field of advanced robotics in recent years. AI, ML, and DL are transforming the field of advanced robotics, making robots more intelligent, efficient, and adaptable to complex tasks and environments. Furthermore, they have a wide range of applications in aviation management, helping airlines to improve efficiency, reduce costs, and improve customer satisfaction. These technologies are also being used in the development of collaborative robots (cobots) that can work alongside humans and adapt to changing environments and tasks. The AI, ML, and DL can be used in advanced transportation systems in order to provide safety, efficiency, and convenience to the passengers and transportation companies . Moreover, the AI, ML, and DL can help taxi companies in order to provide better, more efficient, and safer services to customers. Some of the applications of AI, ML, and DL in advanced robotics include autonomous navigation, object recognition and manipulation, natural language processing, and predictive maintenance. Also, the AI, ML, and DL are playing a critical role in the advancement of manufacturing assembly robots, enabling them to work more efficiently, safely, and intelligently. By reviewing the applications of AI, ML, and DL in advanced robotics systems, it is possible to investigate and modify the performances of advanced robots in various applications in order to enhance productivity in advanced robotic industries. Further research works regarding the applications of AI, ML, and DL in advanced robotics systems are also suggested in order to fill the gaps between the existing studies and published papers. The research presents an overview of current developments in AI, ML, and DL in advanced robotics systems and discusses various applications of the systems in robot modification.","Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) have revolutionized the field of advanced robotics in recent years. AI, ML, and DL are transforming the field of advanced robotics, making robots more intelligent, efficient, and adaptable to complex tasks and environments. Some of the applications of AI, ML, and DL in advanced robotics include autonomous navigation, object recognition and manipulation, natural language processing, and predictive maintenance. These technologies are also being used in the development of collaborative robots (cobots) that can work alongside humans and adapt to changing environments and tasks. The AI, ML, and DL can be used in advanced transportation systems in order to provide safety, efficiency, and convenience to the passengers and transportation companies . Also, the AI, ML, and DL are playing a critical role in the advancement of manufacturing assembly robots, enabling them to work more efficiently, safely, and intelligently. Furthermore, they have a wide range of applications in aviation management, helping airlines to improve efficiency, reduce costs, and improve customer satisfaction. Moreover, the AI, ML, and DL can help taxi companies in order to provide better, more efficient, and safer services to customers. The research presents an overview of current developments in AI, ML, and DL in advanced robotics systems and discusses various applications of the systems in robot modification. Further research works regarding the applications of AI, ML, and DL in advanced robotics systems are also suggested in order to fill the gaps between the existing studies and published papers. By reviewing the applications of AI, ML, and DL in advanced robotics systems, it is possible to investigate and modify the performances of advanced robots in various applications in order to enhance productivity in advanced robotic industries.",2
"Progress had historically languished in these areas, such that these skills had come to seem ineffably bound to intelligence. Commercial applications of artificial intelligence and machine learning have made remarkable progress recently, particularly in areas such as image recognition, natural speech processing, language translation, textual analysis, and self-learning. Relevant clinical questions are introduced to illustrate how machine learning might help solve them—perhaps bringing anesthesiology into an era of machine-assisted discovery. The practice of anesthesiology is different. It embodies a requirement for high reliability, and a pressured cycle of interpretation, physical action, and response rather than any single cognitive act. However, these commercial advances have performed best at single-task applications in which imperfect outputs and occasional frank errors can be tolerated. This review covers the basics of what is meant by artificial intelligence and machine learning for the practicing anesthesiologist, describing how decision-making behaviors can emerge from simple equations.","Commercial applications of artificial intelligence and machine learning have made remarkable progress recently, particularly in areas such as image recognition, natural speech processing, language translation, textual analysis, and self-learning. Progress had historically languished in these areas, such that these skills had come to seem ineffably bound to intelligence. However, these commercial advances have performed best at single-task applications in which imperfect outputs and occasional frank errors can be tolerated. The practice of anesthesiology is different. It embodies a requirement for high reliability, and a pressured cycle of interpretation, physical action, and response rather than any single cognitive act. This review covers the basics of what is meant by artificial intelligence and machine learning for the practicing anesthesiologist, describing how decision-making behaviors can emerge from simple equations. Relevant clinical questions are introduced to illustrate how machine learning might help solve them—perhaps bringing anesthesiology into an era of machine-assisted discovery.",2
"Adaptation and innovation are extremely important to the manufacturing industry. Eighty-two articles were reviewed and classified. In fact, with the introduction of the Industry 4.0, artificial intelligence and machine learning are considered the driving force of smart factory revolution. In this regard, thanks to intensive research efforts in the field of artificial intelligence (AI), a number of AI-based techniques, such as machine learning, have already been established in the industry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze, systematically, the scientific literature relating to the application of artificial intelligence and machine learning (ML) in industry. To promote sustainability, smart production requires global perspectives of smart production application technology. The purpose of this review was to classify the literature, including publication year, authors, scientific sector, country, institution, and keywords. The analysis was done using the Web of Science and SCOPUS database. A first interesting result is the greater number of works published by the USA and the increasing interest after the birth of Industry 4.0. A literature review on ML and AI empirical studies published in the last century was carried out to highlight the evolution of the topic before and after Industry 4.0 introduction, from 1999 to now. This development should lead to sustainable manufacturing using new technologies. Furthermore, UCINET and NVivo 12 software were used to complete them.","Adaptation and innovation are extremely important to the manufacturing industry. This development should lead to sustainable manufacturing using new technologies. To promote sustainability, smart production requires global perspectives of smart production application technology. In this regard, thanks to intensive research efforts in the field of artificial intelligence (AI), a number of AI-based techniques, such as machine learning, have already been established in the industry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze, systematically, the scientific literature relating to the application of artificial intelligence and machine learning (ML) in industry. In fact, with the introduction of the Industry 4.0, artificial intelligence and machine learning are considered the driving force of smart factory revolution. The purpose of this review was to classify the literature, including publication year, authors, scientific sector, country, institution, and keywords. The analysis was done using the Web of Science and SCOPUS database. Furthermore, UCINET and NVivo 12 software were used to complete them. A literature review on ML and AI empirical studies published in the last century was carried out to highlight the evolution of the topic before and after Industry 4.0 introduction, from 1999 to now. Eighty-two articles were reviewed and classified. A first interesting result is the greater number of works published by the USA and the increasing interest after the birth of Industry 4.0.",2
"Autoimmune diseases are chronic, multifactorial conditions. Through machine learning (ML), a branch of the wider field of artificial intelligence, it is possible to extract patterns within patient data, and exploit these patterns to predict patient outcomes for improved clinical management. Here, we surveyed the use of ML methods to address clinical problems in autoimmune disease. Relevant papers included “machine learning” or “artificial intelligence” and the autoimmune diseases search term(s) in their title, abstract or key words. A systematic review was conducted using MEDLINE, embase and computers and applied sciences complete databases. ML models using data on multiple sclerosis, rheumatoid arthritis and inflammatory bowel disease were most common. 169 (of 702) studies met the criteria for inclusion. A small proportion of studies (7.7% or 13/169) combined different data types in the modelling process. Cross-validation, combined with a separate testing set for more robust model evaluation occurred in 8.3% of papers (14/169). Support vector machines and random forests were the most popular ML methods used. Exclusion criteria: studies not written in English, no real human patient data included, publication prior to 2001, studies that were not peer reviewed, non-autoimmune disease comorbidity research and review papers. The field may benefit from adopting a best practice of validation, cross-validation and independent testing of ML models. Many models achieved good predictive results in simple scenarios (e.g. classification of cases and controls). Progression to more complex predictive models may be achievable in future through integration of multiple data types.","Autoimmune diseases are chronic, multifactorial conditions. Through machine learning (ML), a branch of the wider field of artificial intelligence, it is possible to extract patterns within patient data, and exploit these patterns to predict patient outcomes for improved clinical management. Here, we surveyed the use of ML methods to address clinical problems in autoimmune disease. A systematic review was conducted using MEDLINE, embase and computers and applied sciences complete databases. Relevant papers included “machine learning” or “artificial intelligence” and the autoimmune diseases search term(s) in their title, abstract or key words. Exclusion criteria: studies not written in English, no real human patient data included, publication prior to 2001, studies that were not peer reviewed, non-autoimmune disease comorbidity research and review papers. 169 (of 702) studies met the criteria for inclusion. Support vector machines and random forests were the most popular ML methods used. ML models using data on multiple sclerosis, rheumatoid arthritis and inflammatory bowel disease were most common. A small proportion of studies (7.7% or 13/169) combined different data types in the modelling process. Cross-validation, combined with a separate testing set for more robust model evaluation occurred in 8.3% of papers (14/169). The field may benefit from adopting a best practice of validation, cross-validation and independent testing of ML models. Many models achieved good predictive results in simple scenarios (e.g. classification of cases and controls). Progression to more complex predictive models may be achievable in future through integration of multiple data types.",2
"Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In other words, artificial neural networks and deep learning algorithms have modernized the area.","Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind.",2
"Artificial intelligence (AI) has recently become a very popular buzzword, as a consequence of disruptive technical advances and impressive experimental results, notably in the field of image analysis and processing. In medicine, specialties where images are central, like radiology, pathology or oncology, have seized the opportunity and considerable efforts in research and development have been deployed to transfer the potential of AI to clinical applications. With AI becoming a more mainstream tool for typical medical imaging analysis tasks, such as diagnosis, segmentation, or classification, the key for a safe and efficient use of clinical AI applications relies, in part, on informed practitioners. The aim of this review is to present the basic technological pillars of AI, together with the state-of-the-art machine learning methods and their application to medical imaging. In addition, we discuss the new trends and future research directions. This will help the reader to understand how AI methods are now becoming an ubiquitous tool in any medical image analysis workflow and pave the way for the clinical implementation of AI-based solutions.","Artificial intelligence (AI) has recently become a very popular buzzword, as a consequence of disruptive technical advances and impressive experimental results, notably in the field of image analysis and processing. In medicine, specialties where images are central, like radiology, pathology or oncology, have seized the opportunity and considerable efforts in research and development have been deployed to transfer the potential of AI to clinical applications. With AI becoming a more mainstream tool for typical medical imaging analysis tasks, such as diagnosis, segmentation, or classification, the key for a safe and efficient use of clinical AI applications relies, in part, on informed practitioners. The aim of this review is to present the basic technological pillars of AI, together with the state-of-the-art machine learning methods and their application to medical imaging. In addition, we discuss the new trends and future research directions. This will help the reader to understand how AI methods are now becoming an ubiquitous tool in any medical image analysis workflow and pave the way for the clinical implementation of AI-based solutions.",2
